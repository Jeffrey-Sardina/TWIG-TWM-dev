loading NN
done loading NN
loading dataset
training TWIG with:
dataset_to_run_ids
{'DBpedia50': ['2.1', '2.2', '2.3', '2.4'], 'UMLS': ['2.1', '2.2', '2.3', '2.4'], 'CoDExSmall': ['2.1', '2.2', '2.3', '2.4'], 'OpenEA': ['2.1', '2.2', '2.3', '2.4'], 'Countries': ['2.1', '2.2', '2.3', '2.4'], 'Nations': ['2.1', '2.2', '2.3', '2.4'], 'Kinships': ['2.1', '2.2', '2.3', '2.4']}

num_exps_to_select
122

Loading data for Kinships
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
block_randomisation_tensor
[1123, 1182, 236, 701, 936, 689, 585, 593, 713, 482, 116, 852, 257, 60, 122, 63, 487, 757, 913, 805, 591, 935, 271, 302, 446, 448, 514, 728, 1120, 437, 263, 830, 1196, 235, 910, 436, 980, 208, 698, 464, 784, 991, 285, 579, 98, 653, 727, 883, 876, 874, 549, 649, 930, 1002, 650, 524, 253, 647, 798, 721, 127, 372, 646, 346, 1136, 636, 1195, 843, 1102, 258, 515, 543, 16, 242, 343, 369, 481, 64, 173, 245, 791, 528, 85, 71, 162, 862, 748, 512, 990, 452, 17, 612, 614, 617, 278, 1103, 897, 77, 501, 170, 786, 982, 199, 220, 19, 620, 775, 405, 872, 422, 342, 81, 333, 810, 750, 832, 616, 128, 572, 960, 570, 478, 658, 696, 1032, 191, 909, 321, 860, 718, 38, 416, 824, 552, 133, 212, 404, 341, 746, 10, 510, 541, 509, 957, 968, 866, 943, 826, 704, 294, 351, 70, 12, 508, 622, 742, 1192, 204, 751, 1059, 542, 37, 787, 630, 1075, 314, 624, 159, 361, 1005, 1040, 604, 625, 733, 554, 1105, 45, 965, 837, 950, 705, 188, 83, 638, 665, 11, 375, 958, 419, 1131, 730, 1106, 929, 398, 1093, 927, 513, 296, 894, 467, 389, 1021, 551, 1162, 503, 335, 1065, 580, 1077, 865, 592, 1135, 590, 424, 868, 477, 1076, 328, 884, 539, 377, 1042, 368, 1079, 104, 20, 193, 76, 1138, 632, 110, 438, 229, 898, 425, 226, 1188, 350, 1152, 318, 135, 765, 1139, 295, 719, 972, 948, 1114, 1149, 90, 256, 46, 740, 79, 217, 86, 62, 708, 430, 451, 287, 1147, 816, 922, 800, 164, 564, 613, 1190, 688, 568, 657, 557, 578, 663, 995, 352, 1133, 50, 556, 1029, 15, 399, 339, 427, 233, 259, 1036, 219, 367, 681, 1056, 88, 360, 492, 941, 998, 1044, 1052, 1084, 869, 772, 118, 1010, 1183, 945, 724, 345, 202, 167, 240, 873, 732, 629, 384, 223, 137, 639, 91, 870, 228, 29, 690, 900, 734, 99, 589, 35, 838, 576, 396, 763, 550, 1187, 69, 246, 959, 108, 1058, 970, 472, 961, 546, 985, 834, 888, 423, 174, 1082, 363, 992, 911, 184, 687, 488, 306, 186, 215, 139, 216, 799, 260, 1001, 1026, 1030, 937, 1097, 662, 270, 736, 338, 445, 652, 767, 807, 93, 916, 966, 731, 737, 582, 1007, 1046, 49, 468, 899, 631, 567, 856, 675, 454, 1101, 379, 1043, 923, 598, 993, 659, 1022, 21, 412, 606, 849, 879, 463, 210, 587, 1041, 33, 132, 274, 386, 1205, 686, 1006, 373, 917, 712, 1098, 818, 893, 753, 359, 51, 22, 490, 420, 23, 180, 252, 288, 605, 666, 555, 634, 886, 931, 670, 1031, 59, 1094, 42, 413, 1064, 878, 449, 759, 835, 565, 1206, 1038, 1184, 13, 205, 1048, 421, 476, 1080, 1054, 148, 364, 232, 796, 8, 298, 1169, 654, 254, 1129, 710, 536, 75, 147, 1118, 813, 1127, 234, 1155, 169, 707, 516, 433, 1143, 789, 48, 54, 322, 569, 5, 1203, 814, 87, 973, 563, 889, 519, 470, 165, 788, 680, 395, 547, 484, 812, 722, 926, 752, 34, 151, 279, 538, 540, 303, 206, 315, 534, 309, 231, 1156, 1153, 642, 725, 525, 907, 269, 439, 130, 597, 100, 871, 244, 1099, 310, 1057, 779, 833, 983, 955, 967, 443, 615, 1116, 1112, 1167, 963, 289, 175, 562, 474, 717, 1137, 25, 739, 176, 1028, 428, 601, 431, 720, 768, 121, 123, 1174, 1016, 89, 846, 273, 854, 1141, 460, 370, 1207, 891, 134, 280, 72, 627, 192, 989, 1066, 344, 103, 155, 371, 677, 249, 1119, 949, 697, 928, 106, 4, 197, 803, 55, 144, 817, 1121, 247, 1019, 1117, 429, 758, 559, 24, 952, 656, 264, 475, 655, 700, 880, 848, 857, 896, 378, 1090, 773, 633, 92, 827, 1208, 157, 669, 744, 334, 644, 1067, 575, 1091, 101, 1168, 842, 904, 455, 706, 156, 479, 469, 517, 610, 586, 699, 977, 115, 1, 1089, 493, 938, 1191, 994, 1211, 839, 924, 672, 491, 1018, 673, 711, 635, 895, 1015, 864, 129, 932, 331, 2, 65, 500, 453, 535, 385, 362, 1171, 912, 693, 96, 447, 112, 138, 218, 415, 1145, 523, 1008, 691, 465, 671, 498, 1177, 1214, 1113, 920, 505, 213, 347, 1061, 828, 529, 1100, 595, 714, 942, 109, 411, 282, 1148, 1037, 119, 14, 885, 577, 766, 141, 195, 861, 9, 804, 520, 623, 976, 694, 1068, 47, 1176, 561, 329, 185, 36, 152, 97, 573, 518, 105, 1062, 1166, 214, 166, 458, 626, 919, 381, 771, 1178, 1035, 299, 684, 1146, 1049, 221, 440, 1000, 1108, 532, 978, 153, 1163, 667, 594, 376, 327, 863, 26, 243, 1053, 969, 297, 820, 3, 678, 553, 1201, 301, 1151, 125, 390, 506, 58, 1071, 822, 1200, 794, 250, 142, 847, 1150, 178, 267, 637, 57, 581, 325, 1050, 194, 1173, 145, 641, 971, 915, 284, 311, 268, 102, 954, 1157, 1154, 628, 435, 382, 584, 27, 1078, 531, 406, 560, 544, 44, 84, 312, 337, 988, 1074, 383, 480, 126, 881, 790, 984, 1096, 1069, 651, 483, 40, 417, 761, 770, 336, 78, 224, 981, 607, 357, 735, 332, 921, 823, 340, 120, 1063, 313, 851, 286, 237, 1027, 729, 802, 808, 374, 1193, 1070, 326, 815, 1213, 154, 131, 1180, 608, 683, 1011, 304, 940, 901, 1210, 113, 611, 182, 1140, 1023, 905, 877, 434, 177, 1017, 290, 566, 366, 600, 819, 56, 902, 522, 979, 1009, 251, 0, 1107, 319, 825, 1083, 887, 853, 908, 307, 408, 892, 292, 1087, 32, 407, 496, 462, 1020, 227, 769, 324, 136, 1081, 320, 365, 709, 875, 316, 850, 450, 203, 1033, 776, 1109, 276, 939, 1144, 841, 1045, 457, 783, 94, 1039, 140, 277, 951, 209, 1199, 1111, 402, 356, 355, 619, 1110, 1186, 73, 1051, 934, 68, 387, 486, 533, 781, 444, 161, 947, 890, 858, 1128, 225, 741, 867, 596, 530, 602, 52, 836, 255, 1025, 583, 30, 1142, 1165, 358, 466, 146, 1122, 181, 588, 238, 442, 548, 603, 403, 41, 1134, 418, 6, 695, 964, 281, 388, 1185, 640, 760, 609, 330, 1158, 664, 305, 400, 248, 764, 394, 348, 262, 738, 674, 1164, 409, 53, 149, 1179, 801, 953, 643, 743, 944, 397, 114, 774, 1125, 1003, 117, 914, 39, 261, 222, 1132, 61, 1004, 521, 986, 537, 160, 1204, 1088, 1198, 168, 685, 882, 1175, 1172, 283, 95, 660, 903, 527, 755, 473, 163, 1115, 855, 574, 1024, 999, 1181, 456, 906, 275, 43, 1085, 504, 777, 1086, 198, 571, 780, 401, 143, 239, 1126, 111, 996, 1073, 207, 545, 747, 1160, 300, 809, 485, 497, 67, 183, 291, 745, 1072, 230, 80, 426, 754, 489, 1159, 495, 317, 459, 441, 308, 1161, 511, 974, 845, 676, 795, 1212, 526, 679, 661, 956, 150, 962, 1130, 471, 1197, 1092, 723, 494, 1104, 201, 1170, 31, 645, 189, 821, 1194, 187, 933, 172, 997, 782, 618, 749, 1013, 558, 797, 1209, 621, 716, 682, 507, 702, 179, 171, 859, 266, 7, 82, 987, 918, 715, 353, 66, 158, 391, 190, 432, 502, 461, 1034, 811, 293, 648, 844, 499, 74, 354, 1202, 762, 975, 1012, 265, 124, 946, 196, 28, 200, 726, 107, 1055, 18, 1189, 1047, 668, 703, 241, 392, 1060, 806, 692, 1124, 785, 925, 1014, 323, 1095, 272, 792, 831, 829, 778, 414, 380, 211, 840, 599, 410, 349, 793, 756, 393]

Kinships
2.1
2.2
2.3
2.4
training run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
training_data_x shape --> torch.Size([9338592, 33])
training_data_y shape --> torch.Size([9338592])
testing run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
testing_data_x shape --> torch.Size([1042368, 33])
testing_data_y shape --> torch.Size([1042368])
configuring batches; using training batch size 2136
configuring batches; using testing batch size 2136
done loading dataset
running training and eval
NeuralNetwork_HPs_v3(
  (linear_struct_1): Linear(in_features=23, out_features=10, bias=True)
  (relu_1): ReLU()
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (linear_hps_1): Linear(in_features=9, out_features=6, bias=True)
  (relu_3): ReLU()
  (linear_integrate_1): Linear(in_features=16, out_features=8, bias=True)
  (relu_4): ReLU()
  (linear_final): Linear(in_features=8, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for Kinships
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for Kinships
REC: Training with epochs in stages 1: 5 and 2: 10
Epoch 1 -- batch 0 / 4372 mrrl: 0.0; urll: 1.9220015019527636e-06; 
	rank: pred, true, means tensor(0.4271, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.0089, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.0075668797071557e-06; 
	rank: pred, true, means tensor(0.4605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0.0215, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 5.806485887660529e-07; 
	rank: pred, true, means tensor(0.4571, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0.0785, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.0927518445669193e-07; 
	rank: pred, true, means tensor(0.4655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2188, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.2814999195143173e-07; 
	rank: pred, true, means tensor(0.4738, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0.2350, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0240, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 6.576379405487387e-07; 
	rank: pred, true, means tensor(0.4483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0.2462, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.972121807142685e-08; 
	rank: pred, true, means tensor(0.4617, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2582, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 5.9356295878387755e-08; 
	rank: pred, true, means tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0.2534, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.195638834251895e-09; 
	rank: pred, true, means tensor(0.4667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0.2617, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 0.0; urll: 3.029903083984209e-08; 
	rank: pred, true, means tensor(0.4717, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.2648, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.5422702404066513e-07; 
	rank: pred, true, means tensor(0.4669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0.2474, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.9172829013314185e-07; 
	rank: pred, true, means tensor(0.4498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0.2439, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.5894572769070692e-08; 
	rank: pred, true, means tensor(0.4679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2587, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.5124679464406654e-07; 
	rank: pred, true, means tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0.2581, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 2.0712614912099525e-07; 
	rank: pred, true, means tensor(0.4604, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0.2619, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0269, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.10288716732066e-08; 
	rank: pred, true, means tensor(0.4623, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2638, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0268, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 5.587935802964239e-08; 
	rank: pred, true, means tensor(0.4626, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0.2606, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0266, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 1.1424224233280711e-08; 
	rank: pred, true, means tensor(0.4656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0.2635, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0264, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 0.0; urll: 1.3659398057086491e-08; 
	rank: pred, true, means tensor(0.4692, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.2664, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0262, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 6.606181557344826e-08; 
	rank: pred, true, means tensor(0.4713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0.2587, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 2.6325386315306787e-08; 
	rank: pred, true, means tensor(0.4596, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0.2543, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 6.208817460162663e-09; 
	rank: pred, true, means tensor(0.4705, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2635, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 4.693865918170559e-08; 
	rank: pred, true, means tensor(0.4775, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0.2653, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.768271289392942e-07; 
	rank: pred, true, means tensor(0.4619, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0.2627, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 2.756715034024637e-08; 
	rank: pred, true, means tensor(0.4662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2649, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 4.246831153409403e-08; 
	rank: pred, true, means tensor(0.4616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0.2633, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 1.862645326866641e-08; 
	rank: pred, true, means tensor(0.4687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0.2655, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 0.0; urll: 3.1044088188991736e-08; 
	rank: pred, true, means tensor(0.4722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.2694, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 8.394321326932186e-08; 
	rank: pred, true, means tensor(0.4704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0.2676, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.9123158168099508e-08; 
	rank: pred, true, means tensor(0.4608, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0.2590, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.1175871783564162e-08; 
	rank: pred, true, means tensor(0.4686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2647, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 9.685755486543712e-08; 
	rank: pred, true, means tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0.2685, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0250, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.2964011375515838e-07; 
	rank: pred, true, means tensor(0.4645, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0.2670, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 1.6887984344293727e-08; 
	rank: pred, true, means tensor(0.4683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2675, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 3.899137368534866e-08; 
	rank: pred, true, means tensor(0.4616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0.2661, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 7.202228147207279e-09; 
	rank: pred, true, means tensor(0.4647, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0.2648, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 0.0; urll: 4.395842623239332e-08; 
	rank: pred, true, means tensor(0.4736, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.2729, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.274049310495684e-07; 
	rank: pred, true, means tensor(0.4681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0.2683, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 7.698933934818797e-09; 
	rank: pred, true, means tensor(0.4631, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0.2623, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 3.253420288729103e-08; 
	rank: pred, true, means tensor(0.4664, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2675, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.534819631388018e-07; 
	rank: pred, true, means tensor(0.4722, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0.2703, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.3882916505281173e-07; 
	rank: pred, true, means tensor(0.4641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0.2676, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 9.18904952129651e-09; 
	rank: pred, true, means tensor(0.4702, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0.2705, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0252, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 3.327926023644068e-08; 
	rank: pred, true, means tensor(0.4615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0.2655, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0255, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 1.2914340707936844e-08; 
	rank: pred, true, means tensor(0.4644, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0.2658, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Saving checkpoint at [1] epoch 5
Done Training (dist)!
Epoch 1 -- batch 0 / 4372 mrrl: 0.00930437061470002; urll: 5.587935802964239e-08; 
	rank: pred, true, means tensor(0.4748, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0.2742, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 0.0015485954645555466; urll: 6.1009082855889574e-05; 
	rank: pred, true, means tensor(0.2150, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(4.2720e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0010265598393743858; urll: 6.208420381881297e-05; 
	rank: pred, true, means tensor(0.1969, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0001404831164109055; urll: 7.188568997662514e-05; 
	rank: pred, true, means tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0500, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 1.9197616438759724e-05; urll: 8.069798786891624e-05; 
	rank: pred, true, means tensor(0.1793, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(6.3250e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0514, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00019637838704511523; urll: 7.768224168103188e-05; 
	rank: pred, true, means tensor(0.1754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0524, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 4.096827069588471e-05; urll: 7.820701284799725e-05; 
	rank: pred, true, means tensor(0.1719, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0004416738374857232; urll: 6.958097219467163e-05; 
	rank: pred, true, means tensor(0.1715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 9.673508429841604e-06; urll: 7.554268086096272e-05; 
	rank: pred, true, means tensor(0.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 1.7794576478991075e-05; urll: 7.65147342463024e-05; 
	rank: pred, true, means tensor(0.1693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.1798985042332788e-05; urll: 8.454199269181117e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 7.999154149729293e-05; urll: 7.569442823296413e-05; 
	rank: pred, true, means tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 1.2461714504752308e-05; urll: 8.079757390078157e-05; 
	rank: pred, true, means tensor(0.1672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00019456565496511757; urll: 8.637408609502017e-05; 
	rank: pred, true, means tensor(0.1688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00042710915295174345; urll: 8.143211744027212e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 9.920160664478317e-05; urll: 8.018538937903941e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.00035285254853079095; urll: 7.074674067553133e-05; 
	rank: pred, true, means tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 2.353018999201595e-05; urll: 7.646357698831707e-05; 
	rank: pred, true, means tensor(0.1671, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 4.535255868631793e-06; urll: 7.763480243738741e-05; 
	rank: pred, true, means tensor(0.1672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.5870568859099876e-06; urll: 8.575643732910976e-05; 
	rank: pred, true, means tensor(0.1660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 5.6367821343883406e-05; urll: 7.646084122825414e-05; 
	rank: pred, true, means tensor(0.1676, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 0.000825110255391337; urll: 9.321223478764296e-05; 
	rank: pred, true, means tensor(0.1448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(9.6453e-08, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0628, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00024756429411354475; urll: 8.738687029108405e-05; 
	rank: pred, true, means tensor(0.1669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00043813910451717675; urll: 8.157690899679437e-05; 
	rank: pred, true, means tensor(0.1680, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 7.954039574542549e-05; urll: 7.961020310176536e-05; 
	rank: pred, true, means tensor(0.1693, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0003883124372805469; urll: 7.02701581758447e-05; 
	rank: pred, true, means tensor(0.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 2.0751874671987025e-05; urll: 7.630885374965146e-05; 
	rank: pred, true, means tensor(0.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 1.0495076594452257e-05; urll: 7.703925803070888e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.3481928817782318e-05; urll: 8.440837700618431e-05; 
	rank: pred, true, means tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 5.453324774862267e-05; urll: 7.652541535208002e-05; 
	rank: pred, true, means tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 2.2355372948368313e-05; urll: 8.144230378093198e-05; 
	rank: pred, true, means tensor(0.1660, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0553, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00020102963389945216; urll: 8.650422387290746e-05; 
	rank: pred, true, means tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0004244697265676223; urll: 8.139511191984639e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 6.347352154989494e-05; urll: 7.908593397587538e-05; 
	rank: pred, true, means tensor(0.1703, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0003760936306207441; urll: 7.043257937766612e-05; 
	rank: pred, true, means tensor(0.1698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 2.0084798961761408e-05; urll: 7.626861770404503e-05; 
	rank: pred, true, means tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 1.1454825425971649e-05; urll: 7.696598913753405e-05; 
	rank: pred, true, means tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.2518086123236571e-05; urll: 8.44836249598302e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 5.920931016589748e-05; urll: 7.635851943632588e-05; 
	rank: pred, true, means tensor(0.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 2.662224460436846e-05; urll: 8.167699706973508e-05; 
	rank: pred, true, means tensor(0.1656, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0002514331936254166; urll: 8.745268132770434e-05; 
	rank: pred, true, means tensor(0.1668, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00041985294956248254; urll: 8.133501250995323e-05; 
	rank: pred, true, means tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 6.691209819109645e-05; urll: 7.920314965303987e-05; 
	rank: pred, true, means tensor(0.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0004001777051598765; urll: 7.011170237092301e-05; 
	rank: pred, true, means tensor(0.1704, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0539, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 1.8142628732675803e-05; urll: 7.615188951604068e-05; 
	rank: pred, true, means tensor(0.1677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Saving checkpoint at [2] epoch 5
Epoch 6 -- batch 0 / 4372 mrrl: 1.9547189822333166e-05; urll: 7.640496187377721e-05; 
	rank: pred, true, means tensor(0.1696, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 7.337839065257867e-06; urll: 8.494903886457905e-05; 
	rank: pred, true, means tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 6.538068646477768e-05; urll: 7.61516421334818e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 2.73210343948449e-05; urll: 8.171002264134586e-05; 
	rank: pred, true, means tensor(0.1655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0002556887557148002; urll: 8.752867870498449e-05; 
	rank: pred, true, means tensor(0.1667, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0004478271148400381; urll: 8.170356886694208e-05; 
	rank: pred, true, means tensor(0.1678, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 8.489139872835949e-05; urll: 7.977734640007839e-05; 
	rank: pred, true, means tensor(0.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.00042212406697217375; urll: 6.982982449699193e-05; 
	rank: pred, true, means tensor(0.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 1.3909775589127094e-05; urll: 7.58732421672903e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 7 -- batch 0 / 4372 mrrl: 2.090359430440003e-05; urll: 7.632697816006839e-05; 
	rank: pred, true, means tensor(0.1697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.4029185422259616e-05; urll: 8.43661546241492e-05; 
	rank: pred, true, means tensor(0.1686, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 6.578423381142784e-05; urll: 7.613947673235089e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 3.031429514521733e-05; urll: 8.185853948816657e-05; 
	rank: pred, true, means tensor(0.1652, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0555, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0002480505463609006; urll: 8.739456825423986e-05; 
	rank: pred, true, means tensor(0.1669, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0550, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0004433361391420476; urll: 8.164595055859536e-05; 
	rank: pred, true, means tensor(0.1679, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 9.274657713831402e-05; urll: 8.000285015441477e-05; 
	rank: pred, true, means tensor(0.1685, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.00039043334254529327; urll: 7.024159276625142e-05; 
	rank: pred, true, means tensor(0.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 1.5239389767884859e-05; urll: 7.596637442475185e-05; 
	rank: pred, true, means tensor(0.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 8 -- batch 0 / 4372 mrrl: 1.821455384742876e-05; urll: 7.648766768397763e-05; 
	rank: pred, true, means tensor(0.1694, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0542, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.0836165529326536e-05; urll: 8.462270488962531e-05; 
	rank: pred, true, means tensor(0.1681, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 9.791398042580113e-05; urll: 7.518406346207485e-05; 
	rank: pred, true, means tensor(0.1701, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 2.0720547126984457e-05; urll: 8.135065581882372e-05; 
	rank: pred, true, means tensor(0.1662, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00023409353161696345; urll: 8.714025898370892e-05; 
	rank: pred, true, means tensor(0.1674, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00043025065679103136; urll: 8.147409243974835e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 8.44837813929189e-05; urll: 7.976169581525028e-05; 
	rank: pred, true, means tensor(0.1690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0004405322397360578; urll: 6.959761230973527e-05; 
	rank: pred, true, means tensor(0.1715, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 9.253658390662167e-06; urll: 7.550617738161236e-05; 
	rank: pred, true, means tensor(0.1690, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 9 -- batch 0 / 4372 mrrl: 3.366909822943853e-05; urll: 7.565767009509727e-05; 
	rank: pred, true, means tensor(0.1710, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 1.8113938722308376e-05; urll: 8.407881250604987e-05; 
	rank: pred, true, means tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00011418889698688872; urll: 7.475664460798725e-05; 
	rank: pred, true, means tensor(0.1709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 2.7024311748391483e-05; urll: 8.169710781658068e-05; 
	rank: pred, true, means tensor(0.1655, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00019752507796511054; urll: 8.643419278087094e-05; 
	rank: pred, true, means tensor(0.1687, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00045779750507790595; urll: 8.183121826732531e-05; 
	rank: pred, true, means tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 8.501083357259631e-05; urll: 7.977982750162482e-05; 
	rank: pred, true, means tensor(0.1689, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.00041993596823886037; urll: 6.985590152908117e-05; 
	rank: pred, true, means tensor(0.1709, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 8.774732691563258e-06; urll: 7.546321285190061e-05; 
	rank: pred, true, means tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Epoch 10 -- batch 0 / 4372 mrrl: 2.0341883555374807e-05; urll: 7.635901420144364e-05; 
	rank: pred, true, means tensor(0.1697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4641, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2693, device='cuda:0')
	pred, true, mrr tensor(0.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 500 / 4372 mrrl: 8.503485560140689e-06; urll: 8.483405690640211e-05; 
	rank: pred, true, means tensor(0.1677, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4771, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2727, device='cuda:0')
	pred, true, mrr tensor(0.0547, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0556, device='cuda:0')

batch 1000 / 4372 mrrl: 7.430526693497086e-05; urll: 7.58655442041345e-05; 
	rank: pred, true, means tensor(0.1688, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4621, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2635, device='cuda:0')
	pred, true, mrr tensor(0.0544, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0571, device='cuda:0')

batch 1500 / 4372 mrrl: 1.9318795239087194e-05; urll: 8.126746251946315e-05; 
	rank: pred, true, means tensor(0.1663, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2683, device='cuda:0')
	pred, true, mrr tensor(0.0551, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0538, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00021059457139926963; urll: 8.669421367812902e-05; 
	rank: pred, true, means tensor(0.1682, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4822, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2645, device='cuda:0')
	pred, true, mrr tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0500, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00042470470361877233; urll: 8.14013255876489e-05; 
	rank: pred, true, means tensor(0.1683, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4735, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2679, device='cuda:0')
	pred, true, mrr tensor(0.0545, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0480, device='cuda:0')

batch 3000 / 4372 mrrl: 7.236172677949071e-05; urll: 7.938320777611807e-05; 
	rank: pred, true, means tensor(0.1697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4691, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2651, device='cuda:0')
	pred, true, mrr tensor(0.0541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0514, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0004359270678833127; urll: 6.96537463227287e-05; 
	rank: pred, true, means tensor(0.1713, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4524, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0602, device='cuda:0')

batch 4000 / 4372 mrrl: 4.500900843140698e-06; urll: 7.501493382733315e-05; 
	rank: pred, true, means tensor(0.1700, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4627, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2643, device='cuda:0')
	pred, true, mrr tensor(0.0540, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0534, device='cuda:0')

Saving checkpoint at [2] epoch 10
Done Training (mrr)!
REC: Testing model with dataloader Kinships
Testing: batch 0 / 488


Testing data for dataloader(s) Kinships
==========================================

Predicted MRRs
------------------------------------------
0.27400442957878113
0.05381368473172188
0.2291514128446579
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.29628124833106995
0.29574820399284363
0.1947432905435562
0.23002001643180847
0.05381368473172188
0.05381368473172188
0.30709177255630493
0.37767714262008667
0.05381368473172188
0.05945073813199997
0.18648485839366913
0.05381368473172188
0.05381368473172188
0.3109044134616852
0.4507193863391876
0.31945720314979553
0.05381368473172188
0.05381368473172188
0.47766584157943726
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.29943540692329407
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.19558164477348328
0.05381368473172188
0.2910861074924469
0.31029775738716125
0.05381368473172188
0.05381368473172188
0.30647480487823486
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2897495925426483
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.33527299761772156
0.05381368473172188
0.3781203627586365
0.05381368473172188
0.22972393035888672
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.365553081035614
0.22972770035266876
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2119416445493698
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3124047815799713
0.5232546329498291
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.20507827401161194
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05795435234904289
0.05381368473172188
0.21123984456062317
0.05381368473172188
0.05381368473172188
0.32843533158302307
0.05381368473172188
0.27481529116630554
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28955140709877014
0.05381368473172188
0.5454736948013306
0.05381368473172188
0.3099656105041504
0.21903914213180542
0.05381368473172188
0.30839282274246216
0.44615763425827026
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.31051692366600037
0.05381368473172188
0.536535382270813
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.21787957847118378
0.3933951258659363
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.23436661064624786
0.06032663211226463
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28690654039382935
0.3124047815799713
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.4244542419910431
0.05381368473172188
0.05381368473172188
0.157497376203537
0.05381368473172188
0.05381368473172188
0.3120959997177124
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.43975138664245605
0.05381368473172188
0.28154176473617554
0.05381368473172188
0.05381368473172188
0.5344125032424927
0.30978721380233765
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.31113988161087036
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.1947432905435562
0.05381368473172188
0.05381368473172188
0.28341230750083923
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2314479500055313
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3892671465873718
0.19094634056091309
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2294025868177414
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.49106258153915405
0.29628124833106995
0.05381368473172188
0.05381368473172188
0.2996378242969513
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.7102892994880676
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3052958846092224
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.21052096784114838
0.19045093655586243
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2096320390701294
0.30469563603401184
0.5202345252037048
0.3177925646305084
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.4350772798061371
0.05381368473172188
0.37419000267982483
0.05381368473172188
0.05381368473172188
0.3093377649784088
0.05381368473172188
0.42581430077552795
0.05381368473172188
0.30748283863067627
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.31305480003356934
0.05381368473172188
0.05381368473172188
0.30709177255630493
0.05381368473172188
0.2895531952381134
0.18713705241680145
0.26922664046287537
0.05381368473172188
0.05381368473172188
0.28341230750083923
0.3378259837627411
0.05381368473172188
0.27575165033340454
0.5063942670822144
0.05381368473172188
0.20861856639385223
0.05381368473172188
0.3193926215171814
0.3206423223018646
0.05381368473172188
0.23405912518501282
0.3188280761241913
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2900775074958801
0.05381368473172188
0.21123984456062317
0.05381368473172188
0.19446074962615967
0.3111550509929657
0.05381368473172188
0.05381368473172188
0.18517765402793884
0.05381368473172188
0.05381368473172188
0.2842409610748291
0.4628903567790985
0.19625972211360931
0.05381368473172188
0.05381368473172188
0.3049124777317047
0.05381368473172188
0.05381368473172188
0.30678606033325195
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2266945242881775
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28063133358955383
0.37419000267982483
0.298037588596344
0.05381368473172188
0.18325194716453552
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.34314632415771484
0.05381368473172188
0.05381368473172188
0.3343600630760193
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.1958036720752716
0.3709349036216736
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05795435234904289
0.05381368473172188
0.05381368473172188
0.2826451361179352
0.20605963468551636
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.2901838421821594
0.05381368473172188
0.06032663211226463
0.05381368473172188
0.5097699761390686
0.05381368473172188
0.21372942626476288
0.05381368473172188
0.2053731083869934
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3769868314266205
0.28274962306022644
0.518105149269104
0.29181110858917236
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.30899688601493835
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.21683645248413086
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.058853086084127426
0.29943540692329407
0.05381368473172188
0.3392709195613861
0.6857624650001526
0.3153483271598816
0.05381368473172188
0.31146326661109924
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28211554884910583
0.05381368473172188
0.2893550992012024
0.05381368473172188
0.05381368473172188
0.27624157071113586
0.3017420470714569
0.05430217459797859
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.34025758504867554
0.05381368473172188
0.2291514128446579
0.05381368473172188
0.05381368473172188
0.3453195095062256
0.05381368473172188
0.05381368473172188
0.7008892297744751
0.05568329989910126
0.05381368473172188
0.3024478852748871
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3077889382839203
0.341917484998703
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28955140709877014
0.05381368473172188
0.28490588068962097
0.05381368473172188
0.05381368473172188
0.28173643350601196
0.27546578645706177
0.05381368473172188
0.2612687349319458
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.28370338678359985
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.3933951258659363
0.2759553790092468
0.4380415081977844
0.344863623380661
0.05381368473172188
0.05381368473172188
0.06186434626579285
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.291812926530838
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.31051692366600037
0.05381368473172188
0.05381368473172188
0.2916998267173767
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.30373719334602356
0.05381368473172188
0.30214494466781616
0.05381368473172188
0.2266945242881775
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.29823943972587585
0.28547143936157227
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.05381368473172188
0.23145171999931335
0.4170827269554138
0.05795435234904289
0.05381368473172188
0.282840371131897
0.05381368473172188
0.30283546447753906
0.05381368473172188
0.1641566902399063
0.1947432905435562
0.05381368473172188
0.3040026128292084
0.05381368473172188
0.05381368473172188
0.7058968544006348
0.2920103073120117
0.29648229479789734
0.05381368473172188
0.3093598783016205
0.05381368473172188

True MRRs
------------------------------------------
0.2631615400314331
0.05074847862124443
0.2346118539571762
0.05354120209813118
0.05637723207473755
0.05450981855392456
0.05456545948982239
0.050762977451086044
0.05156884342432022
0.3169124722480774
0.33295392990112305
0.2204274982213974
0.24232672154903412
0.05190429836511612
0.053695421665906906
0.3228604793548584
0.35833966732025146
0.060208410024642944
0.10392013937234879
0.19395874440670013
0.05272049456834793
0.05140216648578644
0.30597785115242004
0.43290573358535767
0.3246678113937378
0.05864600092172623
0.05887863039970398
0.4827907085418701
0.05055929720401764
0.047160957008600235
0.05475643649697304
0.05608825385570526
0.05124548450112343
0.0539155974984169
0.047215718775987625
0.29398322105407715
0.05127158388495445
0.05364730954170227
0.048659879714250565
0.227366641163826
0.05687323212623596
0.31651878356933594
0.3491555154323578
0.051257822662591934
0.052265066653490067
0.30090779066085815
0.05545032396912575
0.05118519067764282
0.05546925961971283
0.2963418960571289
0.05527821555733681
0.05091805011034012
0.05022701993584633
0.05339585244655609
0.05668104439973831
0.05816942825913429
0.054560139775276184
0.05107460543513298
0.345004141330719
0.055705852806568146
0.3713015019893646
0.052354659885168076
0.22722281515598297
0.05868427827954292
0.05185183137655258
0.05271413177251816
0.053358886390924454
0.3735000491142273
0.24005475640296936
0.051050230860710144
0.05186322331428528
0.052258431911468506
0.2320699691772461
0.06163119152188301
0.0535595640540123
0.048720650374889374
0.05437689647078514
0.04690001904964447
0.05713759362697601
0.3515979051589966
0.49382859468460083
0.05198301747441292
0.05000567436218262
0.05168747156858444
0.05427507683634758
0.053746748715639114
0.204473078250885
0.04814944416284561
0.0522734560072422
0.05364212393760681
0.05397453159093857
0.053755342960357666
0.2394697666168213
0.05437980964779854
0.047266941517591476
0.31687435507774353
0.05881041660904884
0.27694183588027954
0.05631871148943901
0.05037880688905716
0.052434395998716354
0.2977839708328247
0.05540357157588005
0.5147312879562378
0.04954071342945099
0.27991488575935364
0.22621560096740723
0.05146687477827072
0.2837027907371521
0.4250812530517578
0.051023680716753006
0.05401380732655525
0.057871025055646896
0.04946589469909668
0.05315094441175461
0.33281269669532776
0.05317020043730736
0.5281283855438232
0.05451226979494095
0.053518787026405334
0.05542812868952751
0.05509977042675018
0.2640477418899536
0.38808736205101013
0.054300375282764435
0.051520928740501404
0.053019557148218155
0.2544670104980469
0.053104985505342484
0.053220491856336594
0.053767021745443344
0.047356586903333664
0.2846571207046509
0.3279767632484436
0.05282742157578468
0.05391620099544525
0.05489888787269592
0.053031086921691895
0.4164903163909912
0.056844983249902725
0.06260952353477478
0.17359936237335205
0.049953024834394455
0.055905748158693314
0.357118159532547
0.05980711057782173
0.053486425429582596
0.049981892108917236
0.054909076541662216
0.39415431022644043
0.04857201129198074
0.2782049775123596
0.054330553859472275
0.051368940621614456
0.5041683316230774
0.3274680972099304
0.054831381887197495
0.05125197395682335
0.05479586496949196
0.04879211261868477
0.054574932903051376
0.0549306757748127
0.34469515085220337
0.05384576693177223
0.05385225638747215
0.058144453912973404
0.22828680276870728
0.04668620973825455
0.054744333028793335
0.26245009899139404
0.05032924562692642
0.04931304231286049
0.05286988988518715
0.05356254428625107
0.05644986778497696
0.22162942588329315
0.054438453167676926
0.048003990203142166
0.05004003643989563
0.375814825296402
0.18721526861190796
0.05769546702504158
0.05157678574323654
0.05039137601852417
0.23450614511966705
0.0528978556394577
0.0531083382666111
0.053316254168748856
0.0582888163626194
0.056366708129644394
0.4386333227157593
0.33486080169677734
0.046522993594408035
0.05422499403357506
0.29114001989364624
0.0551878996193409
0.056982193142175674
0.05620235577225685
0.6292730569839478
0.04900411143898964
0.06014464050531387
0.0533161424100399
0.27068352699279785
0.05755086615681648
0.05833197385072708
0.05187074840068817
0.05773216113448143
0.22918930649757385
0.20321343839168549
0.05337384343147278
0.050383616238832474
0.05420607700943947
0.05779455602169037
0.04910627007484436
0.24056978523731232
0.29764434695243835
0.5041767954826355
0.3296651542186737
0.050652798265218735
0.04885966330766678
0.052088480442762375
0.050050344318151474
0.055119968950748444
0.39098289608955383
0.05676353722810745
0.34940242767333984
0.054882898926734924
0.060626327991485596
0.3303053081035614
0.054153233766555786
0.4450523555278778
0.05649895593523979
0.31559523940086365
0.05246974527835846
0.04720468819141388
0.05031244456768036
0.047387562692165375
0.05157242342829704
0.0574239082634449
0.3162820339202881
0.05146851763129234
0.060276176780462265
0.3091539740562439
0.05757258087396622
0.304826945066452
0.23780131340026855
0.2784042954444885
0.05044105648994446
0.0502416156232357
0.27212390303611755
0.3553444445133209
0.05558132380247116
0.26651236414909363
0.4712376296520233
0.05088505521416664
0.22011806070804596
0.05710464343428612
0.3173128068447113
0.3312563896179199
0.051506638526916504
0.2376619279384613
0.32899942994117737
0.056046780198812485
0.06070966646075249
0.054641664028167725
0.2863672971725464
0.0545898973941803
0.24796703457832336
0.05070872977375984
0.2332225888967514
0.29951202869415283
0.05490102991461754
0.057026494294404984
0.19882315397262573
0.05295632779598236
0.055519554764032364
0.27140116691589355
0.4815765917301178
0.22784583270549774
0.05045067146420479
0.05472172051668167
0.2735188603401184
0.04989700764417648
0.05157002434134483
0.31333187222480774
0.04969146475195885
0.0540786050260067
0.05622425302863121
0.053659453988075256
0.04892357438802719
0.05736547335982323
0.2515101730823517
0.053706470876932144
0.05042492225766182
0.05408487841486931
0.052850086241960526
0.046781282871961594
0.2974551320075989
0.35607481002807617
0.3194785416126251
0.0542760044336319
0.20528051257133484
0.05287790670990944
0.05354166403412819
0.05290846526622772
0.05284598469734192
0.3448926508426666
0.05899816378951073
0.05248817801475525
0.3693373501300812
0.050139229744672775
0.052884187549352646
0.05404316261410713
0.05368312448263168
0.2092616856098175
0.36241573095321655
0.05345793813467026
0.048159126192331314
0.050975728780031204
0.057828180491924286
0.05010462552309036
0.0526772066950798
0.3204714357852936
0.18446213006973267
0.054964032024145126
0.05409802123904228
0.04961303621530533
0.05668988823890686
0.05955609679222107
0.2987736165523529
0.05558565631508827
0.055967092514038086
0.058004748076200485
0.4629978835582733
0.049494851380586624
0.22373130917549133
0.055493004620075226
0.20862819254398346
0.050777021795511246
0.05451101437211037
0.04887716472148895
0.3774505853652954
0.2872472405433655
0.45878133177757263
0.2867608964443207
0.052375901490449905
0.05595143139362335
0.04924960806965828
0.05411997064948082
0.050377242267131805
0.3450419008731842
0.05445749685168266
0.052350133657455444
0.04637951776385307
0.05666893720626831
0.2247782051563263
0.05323643609881401
0.048581480979919434
0.049803100526332855
0.05063946917653084
0.053609784692525864
0.054201532155275345
0.06166630983352661
0.10538265854120255
0.2941568195819855
0.0481838583946228
0.3525722920894623
0.6296741962432861
0.3199201822280884
0.053224094212055206
0.30160048604011536
0.05285754054784775
0.04536920413374901
0.04847194254398346
0.29565075039863586
0.05188214033842087
0.3027181625366211
0.052598584443330765
0.05450582504272461
0.2684294283390045
0.294761061668396
0.05025692284107208
0.05155343934893608
0.05074210464954376
0.04922045022249222
0.3677903711795807
0.04672513157129288
0.22334256768226624
0.04908844456076622
0.052526332437992096
0.3591393530368805
0.0549125112593174
0.055885665118694305
0.6154612898826599
0.04704366624355316
0.0564383864402771
0.31095170974731445
0.05369209870696068
0.05018080770969391
0.05528043583035469
0.045966483652591705
0.3035475015640259
0.3570306897163391
0.05021943897008896
0.06141020357608795
0.05478912964463234
0.279453843832016
0.0558706596493721
0.28893786668777466
0.05151354521512985
0.04857570677995682
0.28668758273124695
0.2711440622806549
0.047222550958395004
0.2748261094093323
0.052527353167533875
0.047845691442489624
0.05560862645506859
0.29449447989463806
0.0558089055120945
0.05171339958906174
0.05164289101958275
0.36590272188186646
0.27284345030784607
0.40876322984695435
0.3480973541736603
0.06098320707678795
0.04919584468007088
0.05738890543580055
0.052146926522254944
0.05336618795990944
0.05074501782655716
0.05688010901212692
0.051909465342760086
0.05578944459557533
0.05693668872117996
0.05002344772219658
0.3031412959098816
0.053040146827697754
0.05143223702907562
0.060435328632593155
0.05210879445075989
0.34406065940856934
0.05592526122927666
0.051352355629205704
0.2943950295448303
0.05591125413775444
0.058119941502809525
0.05237020179629326
0.05119225010275841
0.05098089575767517
0.05344539135694504
0.28725937008857727
0.051472123712301254
0.3049948513507843
0.04842153191566467
0.2605019807815552
0.04865100607275963
0.049142081290483475
0.05058693885803223
0.05288984999060631
0.05505423620343208
0.32464373111724854
0.2715182304382324
0.05898316949605942
0.053596753627061844
0.055029306560754776
0.05391736701130867
0.2297542691230774
0.4099713861942291
0.04536905884742737
0.05626169964671135
0.3056282699108124
0.0521780289709568
0.3048427104949951
0.052435193210840225
0.16776470839977264
0.2375948280096054
0.05635421723127365
0.2917700409889221
0.05765184387564659
0.052044693380594254
0.6133823990821838
0.3061482906341553
0.321515291929245
0.06013786047697067
0.3334234654903412
0.059731945395469666

r_mrr = tensor([[1.0000, 0.9942],
        [0.9942, 1.0000]])
r2_mrr = 0.9878985285758972
test_loss: 0.0022265738335110028
Done Testing!
done with training and eval
Experiments took 0 seconds
