loading NN
done loading NN
loading dataset
training TWIG with:
dataset_to_run_ids
{'DBpedia50': ['2.1', '2.2', '2.3', '2.4'], 'UMLS': ['2.1', '2.2', '2.3', '2.4'], 'CoDExSmall': ['2.1', '2.2', '2.3', '2.4'], 'OpenEA': ['2.1', '2.2', '2.3', '2.4'], 'Countries': ['2.1', '2.2', '2.3', '2.4'], 'Nations': ['2.1', '2.2', '2.3', '2.4'], 'Kinships': ['2.1', '2.2', '2.3', '2.4']}

num_exps_to_select
122

Loading data for DBpedia50
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
block_randomisation_tensor
[1123, 1182, 236, 701, 936, 689, 585, 593, 713, 482, 116, 852, 257, 60, 122, 63, 487, 757, 913, 805, 591, 935, 271, 302, 446, 448, 514, 728, 1120, 437, 263, 830, 1196, 235, 910, 436, 980, 208, 698, 464, 784, 991, 285, 579, 98, 653, 727, 883, 876, 874, 549, 649, 930, 1002, 650, 524, 253, 647, 798, 721, 127, 372, 646, 346, 1136, 636, 1195, 843, 1102, 258, 515, 543, 16, 242, 343, 369, 481, 64, 173, 245, 791, 528, 85, 71, 162, 862, 748, 512, 990, 452, 17, 612, 614, 617, 278, 1103, 897, 77, 501, 170, 786, 982, 199, 220, 19, 620, 775, 405, 872, 422, 342, 81, 333, 810, 750, 832, 616, 128, 572, 960, 570, 478, 658, 696, 1032, 191, 909, 321, 860, 718, 38, 416, 824, 552, 133, 212, 404, 341, 746, 10, 510, 541, 509, 957, 968, 866, 943, 826, 704, 294, 351, 70, 12, 508, 622, 742, 1192, 204, 751, 1059, 542, 37, 787, 630, 1075, 314, 624, 159, 361, 1005, 1040, 604, 625, 733, 554, 1105, 45, 965, 837, 950, 705, 188, 83, 638, 665, 11, 375, 958, 419, 1131, 730, 1106, 929, 398, 1093, 927, 513, 296, 894, 467, 389, 1021, 551, 1162, 503, 335, 1065, 580, 1077, 865, 592, 1135, 590, 424, 868, 477, 1076, 328, 884, 539, 377, 1042, 368, 1079, 104, 20, 193, 76, 1138, 632, 110, 438, 229, 898, 425, 226, 1188, 350, 1152, 318, 135, 765, 1139, 295, 719, 972, 948, 1114, 1149, 90, 256, 46, 740, 79, 217, 86, 62, 708, 430, 451, 287, 1147, 816, 922, 800, 164, 564, 613, 1190, 688, 568, 657, 557, 578, 663, 995, 352, 1133, 50, 556, 1029, 15, 399, 339, 427, 233, 259, 1036, 219, 367, 681, 1056, 88, 360, 492, 941, 998, 1044, 1052, 1084, 869, 772, 118, 1010, 1183, 945, 724, 345, 202, 167, 240, 873, 732, 629, 384, 223, 137, 639, 91, 870, 228, 29, 690, 900, 734, 99, 589, 35, 838, 576, 396, 763, 550, 1187, 69, 246, 959, 108, 1058, 970, 472, 961, 546, 985, 834, 888, 423, 174, 1082, 363, 992, 911, 184, 687, 488, 306, 186, 215, 139, 216, 799, 260, 1001, 1026, 1030, 937, 1097, 662, 270, 736, 338, 445, 652, 767, 807, 93, 916, 966, 731, 737, 582, 1007, 1046, 49, 468, 899, 631, 567, 856, 675, 454, 1101, 379, 1043, 923, 598, 993, 659, 1022, 21, 412, 606, 849, 879, 463, 210, 587, 1041, 33, 132, 274, 386, 1205, 686, 1006, 373, 917, 712, 1098, 818, 893, 753, 359, 51, 22, 490, 420, 23, 180, 252, 288, 605, 666, 555, 634, 886, 931, 670, 1031, 59, 1094, 42, 413, 1064, 878, 449, 759, 835, 565, 1206, 1038, 1184, 13, 205, 1048, 421, 476, 1080, 1054, 148, 364, 232, 796, 8, 298, 1169, 654, 254, 1129, 710, 536, 75, 147, 1118, 813, 1127, 234, 1155, 169, 707, 516, 433, 1143, 789, 48, 54, 322, 569, 5, 1203, 814, 87, 973, 563, 889, 519, 470, 165, 788, 680, 395, 547, 484, 812, 722, 926, 752, 34, 151, 279, 538, 540, 303, 206, 315, 534, 309, 231, 1156, 1153, 642, 725, 525, 907, 269, 439, 130, 597, 100, 871, 244, 1099, 310, 1057, 779, 833, 983, 955, 967, 443, 615, 1116, 1112, 1167, 963, 289, 175, 562, 474, 717, 1137, 25, 739, 176, 1028, 428, 601, 431, 720, 768, 121, 123, 1174, 1016, 89, 846, 273, 854, 1141, 460, 370, 1207, 891, 134, 280, 72, 627, 192, 989, 1066, 344, 103, 155, 371, 677, 249, 1119, 949, 697, 928, 106, 4, 197, 803, 55, 144, 817, 1121, 247, 1019, 1117, 429, 758, 559, 24, 952, 656, 264, 475, 655, 700, 880, 848, 857, 896, 378, 1090, 773, 633, 92, 827, 1208, 157, 669, 744, 334, 644, 1067, 575, 1091, 101, 1168, 842, 904, 455, 706, 156, 479, 469, 517, 610, 586, 699, 977, 115, 1, 1089, 493, 938, 1191, 994, 1211, 839, 924, 672, 491, 1018, 673, 711, 635, 895, 1015, 864, 129, 932, 331, 2, 65, 500, 453, 535, 385, 362, 1171, 912, 693, 96, 447, 112, 138, 218, 415, 1145, 523, 1008, 691, 465, 671, 498, 1177, 1214, 1113, 920, 505, 213, 347, 1061, 828, 529, 1100, 595, 714, 942, 109, 411, 282, 1148, 1037, 119, 14, 885, 577, 766, 141, 195, 861, 9, 804, 520, 623, 976, 694, 1068, 47, 1176, 561, 329, 185, 36, 152, 97, 573, 518, 105, 1062, 1166, 214, 166, 458, 626, 919, 381, 771, 1178, 1035, 299, 684, 1146, 1049, 221, 440, 1000, 1108, 532, 978, 153, 1163, 667, 594, 376, 327, 863, 26, 243, 1053, 969, 297, 820, 3, 678, 553, 1201, 301, 1151, 125, 390, 506, 58, 1071, 822, 1200, 794, 250, 142, 847, 1150, 178, 267, 637, 57, 581, 325, 1050, 194, 1173, 145, 641, 971, 915, 284, 311, 268, 102, 954, 1157, 1154, 628, 435, 382, 584, 27, 1078, 531, 406, 560, 544, 44, 84, 312, 337, 988, 1074, 383, 480, 126, 881, 790, 984, 1096, 1069, 651, 483, 40, 417, 761, 770, 336, 78, 224, 981, 607, 357, 735, 332, 921, 823, 340, 120, 1063, 313, 851, 286, 237, 1027, 729, 802, 808, 374, 1193, 1070, 326, 815, 1213, 154, 131, 1180, 608, 683, 1011, 304, 940, 901, 1210, 113, 611, 182, 1140, 1023, 905, 877, 434, 177, 1017, 290, 566, 366, 600, 819, 56, 902, 522, 979, 1009, 251, 0, 1107, 319, 825, 1083, 887, 853, 908, 307, 408, 892, 292, 1087, 32, 407, 496, 462, 1020, 227, 769, 324, 136, 1081, 320, 365, 709, 875, 316, 850, 450, 203, 1033, 776, 1109, 276, 939, 1144, 841, 1045, 457, 783, 94, 1039, 140, 277, 951, 209, 1199, 1111, 402, 356, 355, 619, 1110, 1186, 73, 1051, 934, 68, 387, 486, 533, 781, 444, 161, 947, 890, 858, 1128, 225, 741, 867, 596, 530, 602, 52, 836, 255, 1025, 583, 30, 1142, 1165, 358, 466, 146, 1122, 181, 588, 238, 442, 548, 603, 403, 41, 1134, 418, 6, 695, 964, 281, 388, 1185, 640, 760, 609, 330, 1158, 664, 305, 400, 248, 764, 394, 348, 262, 738, 674, 1164, 409, 53, 149, 1179, 801, 953, 643, 743, 944, 397, 114, 774, 1125, 1003, 117, 914, 39, 261, 222, 1132, 61, 1004, 521, 986, 537, 160, 1204, 1088, 1198, 168, 685, 882, 1175, 1172, 283, 95, 660, 903, 527, 755, 473, 163, 1115, 855, 574, 1024, 999, 1181, 456, 906, 275, 43, 1085, 504, 777, 1086, 198, 571, 780, 401, 143, 239, 1126, 111, 996, 1073, 207, 545, 747, 1160, 300, 809, 485, 497, 67, 183, 291, 745, 1072, 230, 80, 426, 754, 489, 1159, 495, 317, 459, 441, 308, 1161, 511, 974, 845, 676, 795, 1212, 526, 679, 661, 956, 150, 962, 1130, 471, 1197, 1092, 723, 494, 1104, 201, 1170, 31, 645, 189, 821, 1194, 187, 933, 172, 997, 782, 618, 749, 1013, 558, 797, 1209, 621, 716, 682, 507, 702, 179, 171, 859, 266, 7, 82, 987, 918, 715, 353, 66, 158, 391, 190, 432, 502, 461, 1034, 811, 293, 648, 844, 499, 74, 354, 1202, 762, 975, 1012, 265, 124, 946, 196, 28, 200, 726, 107, 1055, 18, 1189, 1047, 668, 703, 241, 392, 1060, 806, 692, 1124, 785, 925, 1014, 323, 1095, 272, 792, 831, 829, 778, 414, 380, 211, 840, 599, 410, 349, 793, 756, 393]

DBpedia50
2.1
2.2
2.3
2.4
training run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
training_data_x shape --> torch.Size([1075512, 33])
training_data_y shape --> torch.Size([1075512])
testing run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
testing_data_x shape --> torch.Size([120048, 33])
testing_data_y shape --> torch.Size([120048])
configuring batches; using training batch size 246
configuring batches; using testing batch size 246
done loading dataset
running training and eval
NeuralNetwork_HPs_v3(
  (linear_struct_1): Linear(in_features=23, out_features=10, bias=True)
  (relu_1): ReLU()
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (linear_hps_1): Linear(in_features=9, out_features=6, bias=True)
  (relu_3): ReLU()
  (linear_integrate_1): Linear(in_features=16, out_features=8, bias=True)
  (relu_4): ReLU()
  (linear_final): Linear(in_features=8, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for DBpedia50
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for DBpedia50
REC: Training with epochs in stages 1: 5 and 2: 10
Epoch 1 -- batch 0 / 4372 mrrl: 0.0; urll: 1.4881293282087427e-06; 
	rank: pred, true, means tensor(0.4158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0.0066, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(9.7692e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 2.7524929464561865e-06; 
	rank: pred, true, means tensor(0.2720, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0.0066, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.0199845519309747e-06; 
	rank: pred, true, means tensor(0.4849, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0.0061, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.3766e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.1455268577265088e-05; 
	rank: pred, true, means tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0.0007, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(7.4570e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.0934969623122015e-06; 
	rank: pred, true, means tensor(0.5010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0.0023, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.1058e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.3609727602670318e-06; 
	rank: pred, true, means tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0.0011, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.2288e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 2.0831823803746374e-06; 
	rank: pred, true, means tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0.0004, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(8.1100e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.5174349528024322e-06; 
	rank: pred, true, means tensor(0.5075, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(9.2466e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.0019e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.771817192609888e-07; 
	rank: pred, true, means tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(4.0481e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(8.0269e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 0.0; urll: 4.6129030124575365e-06; 
	rank: pred, true, means tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(3.1371e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.9900e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.1987984862571466e-06; 
	rank: pred, true, means tensor(0.3186, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(1.7864e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.0492901765246643e-06; 
	rank: pred, true, means tensor(0.4953, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(1.4760e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1994e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.373142026750429e-06; 
	rank: pred, true, means tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(2.8295e-06, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(6.3888e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.073132011697453e-06; 
	rank: pred, true, means tensor(0.5022, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.0866e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.4737248648089007e-06; 
	rank: pred, true, means tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.2791e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 2.0327668153186096e-06; 
	rank: pred, true, means tensor(0.4999, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(8.1232e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.3555090845329687e-06; 
	rank: pred, true, means tensor(0.5039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.0584e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.759399747759744e-07; 
	rank: pred, true, means tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(8.0327e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 0.0; urll: 3.985812327300664e-06; 
	rank: pred, true, means tensor(0.5024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(8.0836e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.3132890899214544e-06; 
	rank: pred, true, means tensor(0.3267, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.0458131782797864e-06; 
	rank: pred, true, means tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.2028e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.4809271533522406e-06; 
	rank: pred, true, means tensor(0.6771, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(5.9978e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.1019409384971368e-06; 
	rank: pred, true, means tensor(0.5006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.1119e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.5723209116913495e-06; 
	rank: pred, true, means tensor(0.4882, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.3177e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 2.0032127849844983e-06; 
	rank: pred, true, means tensor(0.4995, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(8.1299e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.20351717214362e-06; 
	rank: pred, true, means tensor(0.5001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.1206e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.861224500833487e-07; 
	rank: pred, true, means tensor(0.5076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(8.0010e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 0.0; urll: 3.7213169434835436e-06; 
	rank: pred, true, means tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(8.1260e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.34656829686719e-06; 
	rank: pred, true, means tensor(0.3282, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.0676682222765521e-06; 
	rank: pred, true, means tensor(0.4967, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1760e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.1863808140333276e-06; 
	rank: pred, true, means tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(6.0870e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.1282662626399542e-06; 
	rank: pred, true, means tensor(0.4992, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.1353e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.4471511349256616e-06; 
	rank: pred, true, means tensor(0.4912, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.2668e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 1.7732382957547088e-06; 
	rank: pred, true, means tensor(0.4957, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(8.1923e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.3006231256440515e-06; 
	rank: pred, true, means tensor(0.5026, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.0799e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 9.010236112771963e-07; 
	rank: pred, true, means tensor(0.5095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(7.9698e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 0.0; urll: 3.7215652355371276e-06; 
	rank: pred, true, means tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(8.1260e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 1.2226403214299353e-06; 
	rank: pred, true, means tensor(0.3211, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 1.0554989557931549e-06; 
	rank: pred, true, means tensor(0.4959, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1886e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.0664265346349566e-06; 
	rank: pred, true, means tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(6.1698e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.1133651014461066e-06; 
	rank: pred, true, means tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.1223e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 1.4786919564357959e-06; 
	rank: pred, true, means tensor(0.4905, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.2799e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 1.8812717144101043e-06; 
	rank: pred, true, means tensor(0.4975, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(8.1624e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.1662642691590008e-06; 
	rank: pred, true, means tensor(0.4990, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.1381e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.985400654637488e-07; 
	rank: pred, true, means tensor(0.5095, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(7.9697e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Saving checkpoint at [1] epoch 5
Done Training (dist)!
Epoch 1 -- batch 0 / 4372 mrrl: 3.5953121368947905e-07; urll: 3.7488839552679565e-06; 
	rank: pred, true, means tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(8.1214e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.048379478976130486; urll: 8.330419950652868e-05; 
	rank: pred, true, means tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00025225204808521084; urll: 5.211681582295569e-06; 
	rank: pred, true, means tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(7.2681e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 5.624353960342887e-07; urll: 0.00027117779245600104; 
	rank: pred, true, means tensor(0.0917, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.470723542951191e-07; urll: 4.118184278922854e-06; 
	rank: pred, true, means tensor(0.4512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(9.0005e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 3.6905881017901265e-07; urll: 1.3322632185008842e-05; 
	rank: pred, true, means tensor(0.3940, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 4.446399998414563e-05; urll: 0.00016756878176238388; 
	rank: pred, true, means tensor(0.0170, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.2361033085994677e-07; urll: 1.4439225424212054e-06; 
	rank: pred, true, means tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.0269e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 1.513439684686091e-07; urll: 4.957368219038472e-06; 
	rank: pred, true, means tensor(0.4348, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(9.3388e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 1.226337076332129e-07; urll: 3.1045827199704945e-05; 
	rank: pred, true, means tensor(0.2536, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.03020389936864376; urll: 8.687700028531253e-05; 
	rank: pred, true, means tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0193, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0002378048338869121; urll: 7.953669410198927e-05; 
	rank: pred, true, means tensor(0.1857, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0007137427746783942; urll: 0.00036169515806250274; 
	rank: pred, true, means tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 7.464085460817671e-09; urll: 7.29973180568777e-05; 
	rank: pred, true, means tensor(0.2207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 9.694423930284302e-08; urll: 8.192410314222798e-05; 
	rank: pred, true, means tensor(0.2064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 3.179519580953638e-06; urll: 0.00014466966968029737; 
	rank: pred, true, means tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.1732441684841888e-07; urll: 8.940697284742782e-07; 
	rank: pred, true, means tensor(0.4885, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(8.3132e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 1.262732229889707e-07; urll: 1.1902551705134101e-05; 
	rank: pred, true, means tensor(0.3903, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 1.6072473130179787e-07; urll: 2.2665164578938857e-05; 
	rank: pred, true, means tensor(0.2819, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.012518265284597874; urll: 8.746559615246952e-05; 
	rank: pred, true, means tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0389, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00024774779376457445; urll: 1.860534212028142e-05; 
	rank: pred, true, means tensor(0.3449, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00019568935385905206; urll: 0.000357153796358034; 
	rank: pred, true, means tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.5823662380398673e-07; urll: 2.1412970454548486e-06; 
	rank: pred, true, means tensor(0.4750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.5487e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.024431987659227e-07; urll: 7.132192877179477e-06; 
	rank: pred, true, means tensor(0.4294, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(9.4565e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 3.870678995099297e-06; urll: 0.00014688273950014263; 
	rank: pred, true, means tensor(0.0452, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.3793625797120512e-07; urll: 4.950414222548716e-06; 
	rank: pred, true, means tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(7.4003e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 1.3967770051692696e-07; urll: 7.876506060711108e-06; 
	rank: pred, true, means tensor(0.4134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(9.8224e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 4.0029846104516764e-07; urll: 1.561418321216479e-05; 
	rank: pred, true, means tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.0752e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.014101668493822217; urll: 8.743206853978336e-05; 
	rank: pred, true, means tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00025216177164111286; urll: 4.4370694922690745e-06; 
	rank: pred, true, means tensor(0.5519, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(7.3580e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0004702525620814413; urll: 0.0003605162200983614; 
	rank: pred, true, means tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.8356002939867722e-07; urll: 1.4757117696717614e-06; 
	rank: pred, true, means tensor(0.5358, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(7.5794e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 3.956832017593115e-07; urll: 8.269399586424697e-06; 
	rank: pred, true, means tensor(0.4219, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(9.6256e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 2.4634141482238192e-05; urll: 0.0001638099638512358; 
	rank: pred, true, means tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.4938487780113974e-07; urll: 1.0606150681269355e-05; 
	rank: pred, true, means tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.9226e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 1.2315847897070853e-07; urll: 1.2925515875394922e-05; 
	rank: pred, true, means tensor(0.3852, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 3.894998101827696e-07; urll: 1.1261553481745068e-05; 
	rank: pred, true, means tensor(0.5527, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.3470e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.005568419001065195; urll: 8.75989644555375e-05; 
	rank: pred, true, means tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0002519979352655355; urll: 3.2660864235367626e-06; 
	rank: pred, true, means tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(7.5212e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00025877785446937196; urll: 0.0003583759244065732; 
	rank: pred, true, means tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.8159706627329797e-07; urll: 1.2894472547486657e-06; 
	rank: pred, true, means tensor(0.5307, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(7.6521e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.6747480553221976e-07; urll: 9.89188833955268e-07; 
	rank: pred, true, means tensor(0.5143, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(7.8963e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 2.77242702395597e-05; urll: 0.00016462753410451114; 
	rank: pred, true, means tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.511466685144569e-07; urll: 1.1753043509088457e-05; 
	rank: pred, true, means tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.8507e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 2.299464796351458e-07; urll: 1.374433486489579e-05; 
	rank: pred, true, means tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(6.4770e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Saving checkpoint at [2] epoch 5
Epoch 6 -- batch 0 / 4372 mrrl: 3.691711825126731e-07; urll: 5.539258836506633e-06; 
	rank: pred, true, means tensor(0.5161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.8689e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0020289274107199162; urll: 8.767123654251918e-05; 
	rank: pred, true, means tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00025132174414466135; urll: 1.0525187690291204e-06; 
	rank: pred, true, means tensor(0.4955, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1951e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00010205793842033017; urll: 0.0003536455624271184; 
	rank: pred, true, means tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.184919007357621e-07; urll: 1.2282283023523632e-05; 
	rank: pred, true, means tensor(0.3965, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 3.948935400899245e-07; urll: 8.40798020362854e-06; 
	rank: pred, true, means tensor(0.4210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(9.6455e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 5.587143192542499e-07; urll: 0.00012378618703223765; 
	rank: pred, true, means tensor(0.0792, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.645830316476804e-07; urll: 2.346684595977422e-05; 
	rank: pred, true, means tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.3159e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 2.2083852968535211e-07; urll: 8.537868779967539e-06; 
	rank: pred, true, means tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(6.7803e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 7 -- batch 0 / 4372 mrrl: 3.747965848788226e-07; urll: 6.840378318884177e-06; 
	rank: pred, true, means tensor(0.5258, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.7230e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.001647608441999182; urll: 8.767670078668743e-05; 
	rank: pred, true, means tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0614, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00024980174202937633; urll: 5.244712156127207e-06; 
	rank: pred, true, means tensor(0.4181, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(9.7134e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 3.0219891868910054e-05; urll: 0.000343839346896857; 
	rank: pred, true, means tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.718454178956108e-07; urll: 1.0189911563429632e-06; 
	rank: pred, true, means tensor(0.5064, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.0189e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.573005440988709e-07; urll: 1.1816621281468542e-06; 
	rank: pred, true, means tensor(0.4993, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.1329e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 1.3062479986558628e-07; urll: 0.00010825495701283216; 
	rank: pred, true, means tensor(0.1039, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.6977210748336802e-07; urll: 2.965405656141229e-05; 
	rank: pred, true, means tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.1152e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 1.4859885766327352e-07; urll: 5.590170985669829e-06; 
	rank: pred, true, means tensor(0.4297, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(9.4509e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 8 -- batch 0 / 4372 mrrl: 4.303596412569277e-07; urll: 3.427664705668576e-05; 
	rank: pred, true, means tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(6.3376e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 0.0016379290900658816; urll: 8.768017869442701e-05; 
	rank: pred, true, means tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0615, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0002515810228942428; urll: 1.4672677934868261e-06; 
	rank: pred, true, means tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(7.9366e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 5.0726089284580667e-05; urll: 0.0003486077184788883; 
	rank: pred, true, means tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.7570718213733016e-07; urll: 1.0040899951491156e-06; 
	rank: pred, true, means tensor(0.5158, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(7.8724e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.356790839210589e-07; urll: 2.6829541184270056e-06; 
	rank: pred, true, means tensor(0.4698, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.6445e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 4.085677218768069e-07; urll: 0.00012013441300950944; 
	rank: pred, true, means tensor(0.0848, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.6616025888538388e-07; urll: 2.5237353838747367e-05; 
	rank: pred, true, means tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.2546e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 2.2764595541957533e-07; urll: 1.2265146324352827e-05; 
	rank: pred, true, means tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(6.5530e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 9 -- batch 0 / 4372 mrrl: 3.98164878845364e-07; urll: 1.4670442396891303e-05; 
	rank: pred, true, means tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(7.1286e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 1.323607420999906e-05; urll: 8.774524030741304e-05; 
	rank: pred, true, means tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0754, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0002513895924494136; urll: 1.1165936939505627e-06; 
	rank: pred, true, means tensor(0.4997, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1275e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 2.5302588255726732e-05; urll: 0.00034197495551779866; 
	rank: pred, true, means tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.6511622291659478e-07; urll: 1.3778608263237402e-06; 
	rank: pred, true, means tensor(0.4906, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.2781e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.1868908340347843e-07; urll: 4.689147317549214e-06; 
	rank: pred, true, means tensor(0.4484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(9.0555e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 7.738448459804204e-07; urll: 0.0001276972470805049; 
	rank: pred, true, means tensor(0.0732, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.5470897452019017e-07; urll: 1.4323245522973593e-05; 
	rank: pred, true, means tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.7067e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 2.2289304624223405e-07; urll: 9.564062565914355e-06; 
	rank: pred, true, means tensor(0.6051, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(6.7114e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Epoch 10 -- batch 0 / 4372 mrrl: 3.1070310768654963e-07; urll: 1.041094492393313e-06; 
	rank: pred, true, means tensor(0.4295, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4430, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2868, device='cuda:0')
	pred, true, mrr tensor(9.4559e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 500 / 4372 mrrl: 9.132665468314372e-07; urll: 8.774400339461863e-05; 
	rank: pred, true, means tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.3157, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.3064, device='cuda:0')
	pred, true, mrr tensor(0.0746, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0743, device='cuda:0')

batch 1000 / 4372 mrrl: 0.000251406727329595; urll: 1.1369586445653113e-06; 
	rank: pred, true, means tensor(0.5007, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4886, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2947, device='cuda:0')
	pred, true, mrr tensor(8.1104e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0051, device='cuda:0')

batch 1500 / 4372 mrrl: 9.649136245570844e-06; urll: 0.00032952381297945976; 
	rank: pred, true, means tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.6540, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2978, device='cuda:0')
	pred, true, mrr tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2000 / 4372 mrrl: 1.6455054208108777e-07; urll: 1.4272829957917565e-06; 
	rank: pred, true, means tensor(0.4893, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5124, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2933, device='cuda:0')
	pred, true, mrr tensor(8.3002e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 2500 / 4372 mrrl: 4.440868295318978e-07; urll: 1.940131369337905e-06; 
	rank: pred, true, means tensor(0.4809, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5142, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2929, device='cuda:0')
	pred, true, mrr tensor(8.4441e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3000 / 4372 mrrl: 8.73038572990481e-06; urll: 0.0001552703615743667; 
	rank: pred, true, means tensor(0.0335, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4611, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2769, device='cuda:0')
	pred, true, mrr tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0003, device='cuda:0')

batch 3500 / 4372 mrrl: 1.56856767574709e-07; urll: 1.6050042177084833e-05; 
	rank: pred, true, means tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4783, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2791, device='cuda:0')
	pred, true, mrr tensor(6.6206e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

batch 4000 / 4372 mrrl: 2.1252128945548066e-07; urll: 5.153070105734514e-06; 
	rank: pred, true, means tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5045, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2841, device='cuda:0')
	pred, true, mrr tensor(7.0629e-05, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0002, device='cuda:0')

Saving checkpoint at [2] epoch 10
Done Training (mrr)!
REC: Testing model with dataloader DBpedia50
Testing: batch 0 / 488


Testing data for dataloader(s) DBpedia50
==========================================

Predicted MRRs
------------------------------------------
0.3422714173793793
0.010724802501499653
0.11786814033985138
6.282794493017718e-05
0.00034694583155214787
9.432216756977141e-05
0.0003395075327716768
0.1283007562160492
0.18347260355949402
6.871408550068736e-05
0.1678815633058548
0.0001004251025733538
0.00012434560630936176
0.0009624098311178386
7.961887604324147e-05
0.08180603384971619
0.1308438777923584
7.961887604324147e-05
0.0024165890645235777
0.07665818929672241
0.00010423149797134101
0.0001127828290918842
0.00030931219225749373
8.910482574719936e-05
0.0015448951162397861
0.021408282220363617
0.11385777592658997
7.961887604324147e-05
7.961887604324147e-05
7.108927093213424e-05
0.07843098044395447
9.84140278887935e-05
8.432929462287575e-05
9.01961320778355e-05
7.961887604324147e-05
7.961887604324147e-05
0.20794367790222168
7.961887604324147e-05
8.885880379239097e-05
7.961887604324147e-05
8.697547309566289e-05
5.4890275350771844e-05
0.307574987411499
7.961887604324147e-05
0.00010175167699344456
7.961887604324147e-05
0.10213570296764374
0.08614104986190796
0.09026943147182465
7.961887604324147e-05
0.11576609313488007
7.961887604324147e-05
6.114648567745462e-05
7.961887604324147e-05
7.961887604324147e-05
7.961887604324147e-05
0.09284266829490662
0.08057796210050583
0.12476644665002823
0.12284209579229355
0.16701821982860565
0.09245471656322479
7.961887604324147e-05
0.3158933222293854
0.07672353088855743
6.15175231359899e-05
0.00025072559947147965
0.07868560403585434
0.22478224337100983
7.728021591901779e-05
0.07249926775693893
0.09254328906536102
0.2085953950881958
0.18776626884937286
0.1214161142706871
0.0012691061710938811
7.961887604324147e-05
0.0002975280222017318
0.10832485556602478
0.1445227563381195
0.00018699231441132724
9.338793461211026e-05
6.324251444311813e-05
6.728381413267925e-05
0.00010218946408713236
0.20801527798175812
6.104199565015733e-05
0.00013292489165905863
7.970893784658983e-05
0.00031682749977335334
7.961887604324147e-05
0.09662266820669174
0.07917943596839905
0.00031709991162642837
0.0013703025178983808
6.887507333885878e-05
0.22237418591976166
6.393781222868711e-05
9.68743406701833e-05
7.961887604324147e-05
0.0019657276570796967
7.813103729858994e-05
7.961887604324147e-05
8.669611997902393e-05
7.961887604324147e-05
0.00010180006211157888
7.961887604324147e-05
7.961887604324147e-05
0.00011722872295649722
6.189237319631502e-05
7.961887604324147e-05
0.0012679725186899304
7.961887604324147e-05
7.961887604324147e-05
7.961887604324147e-05
0.08019665628671646
7.961887604324147e-05
6.15808239672333e-05
0.1400449573993683
5.730927296099253e-05
7.961887604324147e-05
7.961887604324147e-05
0.000354493735358119
7.961887604324147e-05
0.12428230792284012
0.1217079684138298
0.0005251740803942084
7.961887604324147e-05
8.925689326133579e-05
6.2694882217329e-05
7.961887604324147e-05
0.1428549438714981
9.172276622848585e-05
7.813417323632166e-05
0.0963161438703537
8.645753405289724e-05
0.0016552014276385307
0.00010175167699344456
5.730927296099253e-05
7.034943701000884e-05
0.00025306869065389037
0.0813450962305069
0.09114301949739456
0.10296237468719482
0.09595556557178497
0.0003612889559008181
7.961887604324147e-05
0.16890837252140045
7.961887604324147e-05
0.1573745608329773
0.10392583161592484
8.82257882039994e-05
7.961887604324147e-05
8.88935464899987e-05
8.512216300005093e-05
0.28884080052375793
0.14408327639102936
7.961887604324147e-05
9.629598935134709e-05
7.961887604324147e-05
0.2360970675945282
8.669227099744603e-05
0.12115374207496643
0.29995837807655334
0.003417668864130974
0.00012990389950573444
7.961887604324147e-05
0.38994377851486206
0.3149924874305725
0.3140270411968231
0.00030931219225749373
7.961887604324147e-05
6.259029032662511e-05
9.038317512022331e-05
6.193501030793414e-05
0.087603859603405
7.961887604324147e-05
0.00010802753968164325
0.1214161142706871
0.1601942628622055
7.961887604324147e-05
0.0003180248604621738
0.0005226544453762472
0.0002894533972721547
0.0003532929113134742
0.14364993572235107
0.00018983353220392019
6.118839519331232e-05
0.09077594429254532
0.16701821982860565
7.961887604324147e-05
0.08817111700773239
7.961887604324147e-05
0.18645088374614716
0.0017994199879467487
0.13409695029258728
0.08187535405158997
6.83518810546957e-05
0.002627228619530797
7.961887604324147e-05
7.961887604324147e-05
0.0003025141195394099
0.00041912871529348195
0.12190929800271988
0.00010063118679681793
0.07714036107063293
7.961887604324147e-05
6.227938865777105e-05
8.200130105251446e-05
7.961887604324147e-05
0.40461108088493347
7.961887604324147e-05
7.961887604324147e-05
8.021209941944107e-05
0.08882548660039902
6.17118421359919e-05
0.0002990488428622484
7.961887604324147e-05
8.160208381013945e-05
0.14495818316936493
6.102113547967747e-05
0.11385777592658997
0.00017390563152730465
0.08697858452796936
0.015591847710311413
0.000274085410637781
0.001935402164235711
6.140361801953986e-05
0.12399567663669586
0.002479792572557926
0.21812358498573303
0.32017868757247925
6.142947677290067e-05
6.180338095873594e-05
7.961887604324147e-05
0.0021376246586441994
0.001906616147607565
8.711523696547374e-05
0.0018275728216394782
9.722520189825445e-05
7.961887604324147e-05
6.266098353080451e-05
7.961887604324147e-05
0.16875463724136353
6.151994602987543e-05
6.116963777458295e-05
0.10392583161592484
0.0013410430401563644
6.099890379118733e-05
0.09077594429254532
0.0001000030679279007
7.961887604324147e-05
9.907493949867785e-05
7.961887604324147e-05
6.196723552420735e-05
7.961887604324147e-05
5.859069642610848e-05
0.00032427647965960205
0.11385777592658997
0.11891147494316101
7.961887604324147e-05
6.106063665356487e-05
8.325366070494056e-05
8.805262041278183e-05
8.016231731744483e-05
7.961887604324147e-05
0.0002047327725449577
0.003417668864130974
6.81747478665784e-05
0.1308438777923584
0.223551407456398
0.0002757855399977416
6.065522029530257e-05
0.16990424692630768
9.915726695908234e-05
0.1062530055642128
7.961887604324147e-05
7.961887604324147e-05
6.118839519331232e-05
6.0514827055158094e-05
7.961887604324147e-05
0.07943621277809143
6.114724965300411e-05
0.10020524263381958
6.184585799928755e-05
0.40461108088493347
0.02196558751165867
0.07474265992641449
7.961887604324147e-05
6.800690607633442e-05
0.0003812619543168694
9.310331370215863e-05
8.918701496440917e-05
7.961887604324147e-05
0.0013493450824171305
7.961887604324147e-05
0.015591847710311413
0.00033351164893247187
0.08641829341650009
0.0002901471743825823
6.08208792982623e-05
6.166887760628015e-05
6.489378574769944e-05
6.751576438546181e-05
7.961887604324147e-05
7.961887604324147e-05
0.00012990389950573444
7.961887604324147e-05
0.11806197464466095
9.248614514945075e-05
0.03260793536901474
0.11068622767925262
0.0004511367005761713
0.10263800621032715
8.360355423064902e-05
6.193579611135647e-05
0.0012679725186899304
0.08395727723836899
0.13271880149841309
0.0002975280222017318
0.017906254157423973
6.114648567745462e-05
7.961887604324147e-05
0.00029014216852374375
6.205181853147224e-05
0.11372922360897064
0.00029497125069610775
7.961887604324147e-05
0.0001254222443094477
6.050724914530292e-05
8.895387145457789e-05
7.961887604324147e-05
0.00032216726685874164
7.961887604324147e-05
0.27455535531044006
0.07622380554676056
0.0005226544453762472
0.0001002610006253235
7.961887604324147e-05
0.0003422390727791935
7.961887604324147e-05
0.0001545454579172656
0.0002460661926306784
0.30942007899284363
0.09039585292339325
0.07418356090784073
6.594017759198323e-05
7.961887604324147e-05
7.961887604324147e-05
0.00031350532663054764
0.12029050290584564
0.08528555929660797
0.00025306869065389037
0.00019094256276730448
0.00020828639389947057
7.529654976679012e-05
0.001679278677329421
7.961887604324147e-05
0.10954248905181885
6.643187953159213e-05
0.08723579347133636
5.8388242905493826e-05
0.0009624098311178386
0.00018019770504906774
0.0001004251025733538
0.16899777948856354
0.11361059546470642
6.08208792982623e-05
7.961887604324147e-05
6.683491665171459e-05
8.39306230773218e-05
7.961887604324147e-05
0.13150015473365784
7.961887604324147e-05
0.00032403095974586904
7.491879659937695e-05
6.70034351060167e-05
0.10425379127264023
7.961887604324147e-05
0.3052530586719513
5.420799789135344e-05
0.1273960918188095
6.057509745005518e-05
7.961887604324147e-05
0.08083893358707428
9.629598935134709e-05
0.00010289129568263888
7.961887604324147e-05
7.961887604324147e-05
0.3850972056388855
6.948873487999663e-05
8.080121915554628e-05
0.18027786910533905
0.00044243832235224545
7.961887604324147e-05
0.07369906455278397
0.09077594429254532
7.961887604324147e-05
0.07442541420459747
0.11786814033985138
0.00029331003315746784
9.844367014011368e-05
7.961887604324147e-05
7.961887604324147e-05
0.0026830960996448994
0.09662266820669174
0.0003025141195394099
7.961887604324147e-05
9.9696044344455e-05
0.002479792572557926
0.0012093842960894108
0.10715189576148987
0.00018880231073126197
7.597731746500358e-05
0.0002047327725449577
6.931626558071002e-05
0.12586194276809692
0.16262376308441162
6.13416705164127e-05
0.00011888783774338663
7.961887604324147e-05
7.961887604324147e-05
0.10866503417491913
8.47305782372132e-05
7.961887604324147e-05
0.00018983353220392019
0.08564616739749908
6.324251444311813e-05
6.0699821915477514e-05
6.263433897402138e-05
0.0002990488428622484
0.00040105762309394777
0.0003422390727791935
0.15070730447769165
0.00169010937679559
7.961887604324147e-05
0.29322224855422974
0.08160826563835144
0.13642482459545135
7.961887604324147e-05
0.17065931856632233
0.0014891100581735373
9.2442256573122e-05
0.14148470759391785
0.00018019770504906774
0.00012434560630936176
0.17391233146190643
7.961887604324147e-05
0.08556021749973297
7.961887604324147e-05
7.961887604324147e-05
0.0012029913486912847
0.0013990594306960702
7.961887604324147e-05
0.27455535531044006
8.016231731744483e-05
7.961887604324147e-05
0.0018176556332036853
0.0001118829459301196
7.961887604324147e-05
7.961887604324147e-05
0.07672353088855743
5.658153531840071e-05
6.189237319631502e-05
0.0003391958889551461
7.961887604324147e-05
0.11350330710411072
0.0015448951162397861
0.2253957837820053
7.37462833058089e-05
7.032128632999957e-05
0.0004511367005761713
7.961887604324147e-05
0.1031726524233818
7.961887604324147e-05
7.961887604324147e-05
0.001954503823071718
7.961887604324147e-05
0.0002731920394580811
7.961887604324147e-05
0.08614104986190796
0.00019906704255845398
7.961887604324147e-05
0.08817111700773239
6.205181853147224e-05
6.644258974120021e-05
7.961887604324147e-05
0.07892031222581863

True MRRs
------------------------------------------
0.3403540253639221
0.0006592695717699826
0.0626697912812233
0.00019974750466644764
0.00018763395200949162
0.0005632748361676931
0.0001647083117859438
0.13904738426208496
0.28218477964401245
0.0001942867529578507
0.11636991053819656
0.00048800642252899706
0.00027689256239682436
0.0001937803317559883
0.0003906715428456664
0.11883270740509033
0.05840856954455376
0.00018027624173555523
0.00021306867711246014
0.11213765293359756
0.0004136643838137388
0.00030345437698997557
0.00024765048874542117
0.0005300845368765295
0.0002072537608910352
0.0011001594830304384
0.09460091590881348
0.00021010666387155652
0.00016810408851597458
0.000255975523032248
0.08992549777030945
0.0002536386309657246
0.0002220240276074037
0.0005258690798655152
0.00018341041868552566
0.0003378406981937587
0.18915051221847534
0.0001895991590572521
0.0001540997182019055
0.00033083069138228893
0.0003925963246729225
0.0003717112704180181
0.31644147634506226
0.00018756416102405638
0.00028128776466473937
0.00016006233636289835
0.08653312921524048
0.09373410046100616
0.08872959017753601
0.00017803213268052787
0.07139813899993896
0.00030800874810665846
0.0002033751952694729
0.000547452422324568
0.00036946305772289634
0.0004104692197870463
0.0886678472161293
0.10855128616094589
0.104544997215271
0.12469464540481567
0.11562944948673248
0.13902819156646729
0.00016411601973231882
0.3421948254108429
0.08609068393707275
0.00032544753048568964
0.0003625195531640202
0.1049068346619606
0.15377599000930786
0.00016826821956783533
0.09439417719841003
0.09773650020360947
0.16873817145824432
0.29426124691963196
0.08161527663469315
0.00019529148994479328
0.00016843105549924076
0.00021283543901517987
0.13471874594688416
0.15446463227272034
0.00017783374642021954
0.0008609134238213301
0.0002788352721836418
0.0002584480680525303
0.00039169154479168355
0.175756573677063
0.0002258880267618224
0.00028752931393682957
0.0002644203486852348
0.0002475570945534855
0.00014379365893546492
0.06448911875486374
0.11012983322143555
0.0003239568031858653
0.0002066546876449138
0.0011804674286395311
0.22657105326652527
0.00024298821517731994
0.0006346747977659106
0.0002449425228405744
0.0003781054401770234
0.00034906811197288334
0.0009302489925175905
0.00019033117860089988
0.0010279945563524961
0.00022123400412965566
0.0002707413805183023
0.00019250485638622195
0.0003264355182182044
0.0002855482744053006
0.00017221635789610445
0.00019890390103682876
0.00021677036420442164
0.00021703680977225304
0.00020444620167836547
0.09149134904146194
0.00029158368124626577
0.00028268774622119963
0.1491166055202484
0.00013590783055406064
0.0002296908205607906
0.0029390109702944756
0.0002692411362659186
0.00042734359158203006
0.1122690960764885
0.1095530316233635
0.00018641659698914737
0.00022913054272066802
0.0008954581571742892
0.0003338560927659273
0.00021468244085554034
0.14399802684783936
0.00026383274234831333
0.0005238116718828678
0.07431610673666
0.00031420279992744327
0.000440690026152879
0.0002828367578331381
0.0008096987730823457
0.00028306912281550467
0.0004736343980766833
0.09131556749343872
0.09968171268701553
0.13074536621570587
0.07873577624559402
0.00045435642823576927
0.00035900124930776656
0.1542327105998993
0.00020344975928310305
0.10322032123804092
0.10125619173049927
0.002334674121811986
0.00031958575709722936
0.000555225124116987
0.0001455481833545491
0.2563108801841736
0.1480463147163391
0.00030498835258185863
0.0006382752326317132
0.0006316648214124143
0.24322493374347687
0.0012178232427686453
0.06074605882167816
0.22153164446353912
0.024570083245635033
0.00027918725390918553
0.0004231022612657398
0.4019079804420471
0.3093523383140564
0.31234458088874817
0.00035527697764337063
0.00030996062560006976
0.0002201391034759581
0.00021286595438141376
0.00017688261868897825
0.09250698238611221
0.000217176420846954
0.00016985699767246842
0.10947252810001373
0.0733816847205162
0.0002284339425386861
0.0006192091386765242
0.00010226784070255235
0.0007705821772105992
0.00026745072682388127
0.15484990179538727
0.0005873027257621288
0.00015555557911284268
0.07839455455541611
0.11870948225259781
0.00029058268410153687
0.10143578797578812
0.0003754924691747874
0.31738969683647156
0.00018884566088672727
0.09303831309080124
0.0961189717054367
0.0002732926222961396
0.0012308574514463544
0.00033551096566952765
0.00023550167679786682
0.00032225140603259206
0.00034281882108189166
0.08117426931858063
0.00026517469086684287
0.10547231137752533
0.00029026108677498996
0.00018384226132184267
0.000583011656999588
0.00020665265037678182
0.36600926518440247
0.0003374307125341147
0.00037018413422629237
0.0011955058434978127
0.0924823060631752
0.00037553810398094356
0.0003604289668146521
0.00017019297229126096
0.00016200267418753356
0.17408640682697296
0.00033906192402355373
0.11758903414011002
0.00022771915246266872
0.09213852137327194
0.004880256485193968
0.00030657893512398005
0.0011517290258780122
0.00019398346194066107
0.11833052337169647
0.00010916514293057844
0.21371474862098694
0.33449187874794006
0.0001638641842873767
0.00039475865196436644
0.00021674686286132783
0.00027947878697887063
0.00023764841898810118
0.0003893153043463826
0.0002717562310863286
0.0002693832793738693
0.00024712030426599085
0.0002978444390464574
0.00026726810028776526
0.2700037956237793
0.00022065317898523062
0.00016033746942412108
0.10410170257091522
0.0003874992544297129
0.00019624149717856199
0.09275007992982864
0.0002695814473554492
0.00017279086750932038
0.00019354841788299382
0.0002096622047247365
0.00026815335149876773
0.001549475360661745
0.00034381781006231904
0.00013879813195671886
0.09145840257406235
0.046528130769729614
0.0002571621735114604
0.0003053164400625974
0.0003819130652118474
0.0003421043511480093
0.0001580677053425461
0.00020680033776443452
0.0002528810000512749
0.03523152321577072
0.0001861114869825542
0.0988781601190567
0.16675986349582672
0.0003566662489902228
0.00027188804233446717
0.1465083211660385
0.00035275748814456165
0.08132167905569077
0.0003118352615274489
0.0003539827303029597
0.00021319616644177586
0.00020806369138881564
0.0004400421166792512
0.08470606058835983
0.00032444557291455567
0.09872468560934067
0.00027637032326310873
0.3772662878036499
0.0038443715311586857
0.10099450498819351
0.0004932010779157281
0.0009751499746926129
0.0004370971000753343
0.00038514388143084943
0.00039234894211404026
0.00022106214601080865
0.0002662616898305714
0.0002376834163442254
0.007862815633416176
0.0004625506408046931
0.08605920523405075
0.00030973413959145546
0.00026407401310279965
0.0008814408211037517
0.00018565365462563932
0.00044774942216463387
0.00029560457915067673
0.0003394621890038252
0.00029073740006424487
0.00030863971915096045
0.11175532639026642
0.0003050306986551732
0.0028923999052494764
0.09133493900299072
0.0009500718442723155
0.07294531166553497
0.0002879717212636024
0.00036762916715815663
0.00022267777239903808
0.1005563959479332
0.17668560147285461
0.000502595619764179
0.0014304985525086522
0.0003457319689914584
0.00019217387307435274
0.00021831478807143867
0.0004896470345556736
0.10736669600009918
0.00027867458993569016
0.0003306633443571627
0.0002471348852850497
0.0003455373807810247
0.0002768983831629157
0.00022648034791927785
0.0002604207838885486
0.00034238974330946803
0.24189890921115875
0.0962601751089096
7.119085057638586e-05
0.0003558255557436496
0.0003544759238138795
0.00023964706633705646
0.0007446216186508536
0.00017608159396331757
0.0004883545334450901
0.341468870639801
0.10135354846715927
0.08189202845096588
0.0002490185433998704
0.00023030095326248556
0.0005255744908936322
0.00019406060164328665
0.12828175723552704
0.08724978566169739
0.00019164431432727724
0.00016968432464636862
0.00033576658461242914
0.00025455179275013506
0.00031949079129844904
0.00040402260492555797
0.1458437144756317
0.00020880646479781717
0.08360912650823593
0.000253426464041695
0.0002444386191200465
0.0001787518704077229
0.0002074045332847163
0.28248298168182373
0.1130961999297142
0.000670193403493613
0.0005558046977967024
0.00016607010911684483
0.00030565736233256757
0.00031318276887759566
0.12745490670204163
0.00020820485951844603
0.0005410402081906796
0.0001966004492715001
0.00016440042236354202
0.09788306802511215
0.00023485541169065982
0.31795984506607056
0.0002995317045133561
0.12514427304267883
0.0002332911972189322
0.0003132850397378206
0.08618518710136414
0.00017578348342794925
0.0007290288922376931
0.000476091488962993
0.00023898814106360078
0.3839627206325531
0.00013824606139678508
0.00016132430755533278
0.2975161373615265
0.000959529192186892
0.0014837580965831876
0.07461291551589966
0.09793148934841156
0.0002094386873068288
0.09126187860965729
0.08001317083835602
0.000331878662109375
0.00023809332924429327
0.00011717824236257002
0.00024130330712068826
0.00041799855534918606
0.05862240493297577
0.00043540276237763464
0.0002670574467629194
0.00045595710980705917
0.00013992840831633657
0.00018514384282752872
0.11834176629781723
0.0006192474975250661
0.00020510719332378358
0.0002561831788625568
0.00032820430351421237
0.09329261630773544
0.14241954684257507
0.00017011904856190085
0.0002597447601146996
0.00021187202946748585
0.00023963597777765244
0.15007634460926056
0.00047721940791234374
0.00022059024195186794
0.0006242123781703413
0.07030460238456726
0.0002466742880642414
0.0002946557942777872
0.0002435562200844288
0.00040713115595281124
0.00030288996640592813
0.0002047219022642821
0.06505776941776276
0.00020325856166891754
0.0006444037426263094
0.26097366213798523
0.1006443202495575
0.10500338673591614
0.0004274082602933049
0.08076781779527664
0.0003327779413666576
0.0027566279750317335
0.13267116248607635
0.00026071100728586316
0.00021570292301476002
0.26196566224098206
0.00021728023421019316
0.08141856640577316
0.00020269448577892035
0.00018542665929999202
0.00032145524164661765
0.00024637009482830763
0.00027982337633147836
0.24464376270771027
0.0003899778821505606
0.00023302507179323584
0.0002598034043330699
0.00031274082721211016
0.00030023077852092683
0.00023793285072315484
0.06266796588897705
0.0002539804845582694
0.0005166413029655814
0.00017640551959630102
0.0004282925510779023
0.11346668004989624
0.00019705692830029875
0.17011307179927826
0.0018558665178716183
0.0002806514094118029
0.00020005075202789158
0.0002801169757731259
0.08947863429784775
0.00027001084527000785
0.00033273029839619994
0.02114587463438511
0.00048540663556195796
0.0003047025529667735
0.0002457943046465516
0.10122252255678177
0.00025489265681244433
0.0006435977411456406
0.0852261409163475
0.00019080603669863194
0.0002600841980893165
0.0004028298717457801
0.08623157441616058

r_mrr = tensor([[1.0000, 0.9653],
        [0.9653, 1.0000]])
r2_mrr = 0.9309217929840088
test_loss: 0.004314845080513664
Done Testing!
done with training and eval
Experiments took 0 seconds
