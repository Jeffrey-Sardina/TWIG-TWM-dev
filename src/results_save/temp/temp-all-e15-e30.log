Using random seed: 17
Starting TWIG!
Loading datasets
Loading UMLS...
- loading run 2.1...
Loading Kinships...
- loading run 2.1...
Loading CoDExSmall...
- loading run 2.1...
Loading DBpedia50...
- loading run 2.1...
Loading OpenEA...
- loading run 2.1...
Creating the train-test split
using splits:
test_ids (121): [905, 1053, 769, 496, 369, 66, 731, 534, 827, 350, 409, 1078, 129, 642, 215, 868, 637, 245, 578, 38, 257, 418, 710, 900, 797, 619, 481, 358, 522, 842, 289, 178, 1135, 273, 860, 719, 708, 614, 435, 181, 222, 1129, 695, 1173, 40, 462, 591, 1151, 1082, 656, 683, 1107, 97, 523, 313, 1043, 142, 746, 1, 939, 733, 1166, 372, 1154, 260, 246, 443, 1084, 1060, 50, 752, 340, 916, 1208, 882, 294, 77, 883, 136, 511, 988, 845, 537, 206, 717, 184, 1115, 35, 25, 742, 623, 118, 151, 93, 428, 517, 577, 96, 407, 696, 1017, 22, 722, 238, 546, 586, 223, 1029, 240, 815, 1200, 743, 279, 133, 789, 747, 1021, 1117, 1013, 1165, 1164]
valid_ids (0): []
train_ids (1094): [954, 559, 685, 385, 210, 477, 924, 909, 991, 1074, 1103, 814, 729, 580, 292, 843, 284, 319, 579, 182, 874, 312, 515, 1111, 71, 687, 94, 829, 1171, 321, 904, 364, 711, 379, 13, 946, 354, 14, 1143, 296, 121, 1010, 1160, 54, 285, 1187, 412, 562, 20, 524, 532, 23, 847, 148, 542, 180, 832, 1066, 64, 204, 958, 1081, 545, 468, 851, 194, 183, 959, 327, 264, 892, 1210, 525, 502, 718, 974, 1051, 788, 123, 404, 984, 948, 60, 903, 1134, 383, 895, 341, 654, 1014, 951, 1006, 1002, 70, 863, 931, 871, 675, 344, 1168, 173, 684, 199, 828, 658, 236, 639, 398, 821, 335, 485, 138, 499, 536, 373, 49, 1126, 985, 99, 555, 76, 439, 63, 367, 723, 1209, 229, 422, 971, 840, 715, 1163, 563, 1035, 995, 693, 583, 810, 458, 305, 896, 1125, 442, 377, 299, 486, 613, 849, 197, 581, 92, 425, 530, 137, 975, 59, 431, 787, 445, 1184, 866, 1190, 271, 1076, 1026, 942, 459, 766, 1131, 1018, 220, 913, 0, 1097, 353, 763, 915, 798, 456, 1138, 26, 47, 84, 655, 589, 802, 961, 1068, 28, 702, 79, 436, 652, 277, 1055, 351, 258, 282, 699, 816, 807, 706, 636, 449, 389, 608, 823, 287, 348, 774, 612, 1114, 689, 1123, 671, 1213, 45, 161, 880, 228, 936, 893, 114, 1088, 6, 187, 474, 594, 548, 30, 561, 750, 879, 259, 139, 550, 605, 1012, 714, 566, 999, 759, 929, 1207, 872, 772, 254, 853, 126, 1046, 1048, 1016, 930, 741, 186, 979, 643, 567, 326, 601, 314, 62, 145, 247, 29, 734, 491, 597, 396, 933, 345, 855, 1003, 1153, 552, 4, 1072, 198, 1177, 405, 441, 368, 32, 1185, 135, 399, 164, 336, 785, 230, 175, 1001, 1049, 149, 660, 592, 869, 771, 297, 211, 37, 328, 1019, 471, 700, 421, 1124, 645, 1023, 838, 610, 611, 410, 115, 311, 111, 444, 628, 740, 976, 1033, 69, 162, 243, 952, 570, 1186, 864, 189, 1159, 1009, 1158, 1121, 914, 521, 1015, 185, 43, 51, 1193, 964, 730, 2, 1139, 1182, 68, 169, 382, 779, 963, 1162, 488, 1214, 854, 478, 278, 873, 1085, 575, 1147, 465, 632, 306, 967, 86, 657, 212, 361, 320, 1047, 332, 875, 1080, 492, 234, 938, 1024, 250, 163, 676, 475, 899, 644, 765, 467, 83, 735, 427, 170, 844, 1062, 293, 159, 811, 584, 982, 171, 65, 1044, 27, 1188, 476, 907, 834, 420, 678, 541, 500, 9, 1178, 179, 518, 214, 232, 574, 362, 1022, 716, 725, 603, 33, 682, 833, 739, 1145, 165, 704, 463, 727, 1119, 520, 568, 461, 1108, 870, 758, 713, 104, 1065, 670, 510, 253, 107, 668, 91, 480, 1000, 953, 1034, 1042, 1116, 698, 889, 681, 935, 703, 144, 207, 196, 1194, 1130, 408, 861, 721, 791, 587, 910, 1089, 156, 519, 464, 140, 609, 1045, 113, 732, 707, 760, 887, 824, 943, 599, 1058, 176, 846, 606, 1087, 554, 1050, 15, 533, 573, 820, 46, 793, 438, 370, 267, 52, 1102, 5, 978, 124, 1030, 1031, 1176, 1150, 805, 450, 831, 672, 1096, 209, 783, 635, 1061, 322, 482, 325, 237, 339, 227, 777, 616, 987, 817, 756, 795, 590, 757, 423, 419, 881, 501, 57, 390, 737, 87, 429, 302, 1052, 965, 667, 1136, 891, 898, 950, 1094, 908, 622, 304, 479, 764, 749, 95, 498, 1077, 470, 331, 751, 794, 877, 1152, 649, 3, 1059, 90, 1083, 17, 565, 338, 620, 310, 307, 659, 316, 1206, 487, 143, 98, 108, 607, 18, 274, 694, 48, 922, 926, 1039, 664, 147, 472, 692, 112, 401, 41, 81, 571, 625, 117, 391, 890, 531, 356, 116, 615, 8, 224, 1120, 1025, 337, 457, 490, 1086, 380, 44, 1132, 1057, 217, 784, 359, 630, 301, 1197, 1037, 720, 941, 626, 944, 994, 549, 1172, 780, 663, 1011, 576, 269, 529, 955, 856, 318, 544, 266, 809, 627, 897, 808, 1205, 451, 298, 980, 852, 150, 262, 160, 203, 132, 483, 270, 1181, 508, 188, 1109, 493, 666, 937, 1093, 484, 11, 906, 177, 219, 395, 1095, 244, 709, 990, 497, 901, 411, 973, 233, 403, 1203, 862, 928, 134, 89, 661, 452, 755, 1113, 598, 128, 800, 1148, 738, 363, 1054, 674, 466, 73, 388, 648, 782, 235, 200, 724, 754, 371, 213, 193, 867, 424, 770, 166, 790, 1098, 1192, 705, 1149, 1112, 433, 413, 503, 665, 691, 360, 1028, 596, 582, 1175, 12, 323, 208, 662, 414, 1174, 80, 276, 384, 878, 744, 1202, 378, 557, 968, 221, 242, 263, 812, 792, 640, 669, 773, 837, 1041, 960, 947, 1110, 526, 588, 1122, 884, 392, 315, 272, 761, 1101, 152, 925, 1071, 781, 1004, 917, 74, 303, 72, 1100, 986, 387, 527, 88, 440, 78, 504, 343, 125, 1199, 1007, 381, 195, 1118, 256, 507, 248, 295, 969, 818, 1104, 1005, 981, 776, 553, 992, 560, 1161, 1008, 796, 154, 1064, 923, 172, 241, 631, 67, 416, 288, 902, 894, 1198, 505, 324, 1040, 600, 168, 146, 572, 679, 157, 921, 778, 618, 535, 799, 397, 918, 540, 448, 446, 85, 300, 803, 155, 585, 806, 1201, 218, 1155, 374, 494, 205, 701, 317, 1189, 697, 75, 255, 261, 1195, 453, 1179, 841, 506, 945, 249, 857, 1020, 130, 342, 120, 329, 333, 291, 885, 1211, 1070, 34, 813, 850, 1167, 775, 82, 347, 768, 538, 7, 934, 415, 426, 998, 1183, 595, 556, 962, 355, 365, 275, 268, 551, 997, 1142, 122, 1157, 876, 251, 819, 61, 454, 932, 53, 202, 417, 617, 966, 231, 56, 31, 201, 1156, 106, 1067, 1073, 690, 957, 16, 376, 539, 602, 24, 927, 972, 280, 1032, 912, 949, 920, 366, 393, 21, 216, 191, 919, 728, 888, 1212, 432, 352, 753, 641, 473, 346, 673, 109, 865, 1063, 58, 745, 386, 651, 989, 469, 447, 940, 158, 911, 1056, 835, 455, 1092, 804, 996, 100, 604, 334, 543, 1090, 460, 495, 174, 1196, 983, 826, 513, 638, 190, 858, 330, 101, 647, 646, 624, 1099, 102, 434, 226, 308, 514, 400, 375, 801, 1127, 825, 283, 1075, 42, 993, 153, 528, 634, 406, 110, 1180, 1141, 956, 39, 1146, 1169, 19, 686, 558, 192, 680, 349, 653, 712, 629, 512, 265, 1133, 1191, 1137, 394, 564, 131, 547, 119, 736, 1079, 1204, 437, 1140, 239, 489, 830, 10, 767, 977, 103, 726, 105, 1170, 762, 886, 36, 688, 1036, 836, 290, 970, 1038, 167, 839, 633, 141, 252, 1105, 677, 430, 1144, 1091, 309, 402, 286, 127, 1128, 281, 822, 650, 1027, 516, 859, 786, 509, 55, 225, 569, 1106, 357, 593, 748, 621, 848, 1069]
Converting data to tensors
Normalising data
Finalising data preprocessing
the checkpoint ID for this run is:  8606280476482954
the save name prefix for this run is:  chkpt-ID_8606280476482954_tag_TWIG-job_UMLS-Kinships-CoDExSmall-DBpedia50-OpenEA
running TWIG with settings:
kge_model_name: ComplEx
test_ratio: 0.1
valid_ratio: 0.0
normalisation: zscore
n_bins: 30
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 0
)
optimizer_args: {'lr': 0.005}
mrr_loss_coeffs: [0, 10]
rank_dist_loss_coeffs: [1, 1]
rescale_mrr_loss: False
rescale_rank_dist_loss: False
RUnning with TWIG model:
TWIG_Base(
  (linear_struct_1): Linear(in_features=23, out_features=10, bias=True)
  (relu_1): ReLU()
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (linear_hps_1): Linear(in_features=9, out_features=6, bias=True)
  (relu_3): ReLU()
  (linear_integrate_1): Linear(in_features=16, out_features=8, bias=True)
  (relu_4): ReLU()
  (linear_final): Linear(in_features=8, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
Training with epochs in stages 1: 15 and 2: 30
Epoch 1 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 702
rank avg (pred): 0.427 +- 0.005
mrr vals (pred, true): 0.017, 0.046
batch losses (mrrl, rdl): 0.0, 8.00222e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 27
rank avg (pred): 0.196 +- 0.027
mrr vals (pred, true): 0.037, 0.244
batch losses (mrrl, rdl): 0.0, 4.89255e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 135
rank avg (pred): 0.465 +- 0.017
mrr vals (pred, true): 0.016, 0.045
batch losses (mrrl, rdl): 0.0, 8.19922e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 163
rank avg (pred): 0.446 +- 0.067
mrr vals (pred, true): 0.017, 0.048
batch losses (mrrl, rdl): 0.0, 7.07636e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 192
rank avg (pred): 0.454 +- 0.262
mrr vals (pred, true): 0.097, 0.047
batch losses (mrrl, rdl): 0.0, 2.64513e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1140
rank avg (pred): 0.377 +- 0.230
mrr vals (pred, true): 0.117, 0.026
batch losses (mrrl, rdl): 0.0, 0.0001985572

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 626
rank avg (pred): 0.404 +- 0.264
mrr vals (pred, true): 0.125, 0.046
batch losses (mrrl, rdl): 0.0, 1.19654e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1197
rank avg (pred): 0.434 +- 0.246
mrr vals (pred, true): 0.079, 0.045
batch losses (mrrl, rdl): 0.0, 6.178e-06

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 992
rank avg (pred): 0.193 +- 0.195
mrr vals (pred, true): 0.105, 0.285
batch losses (mrrl, rdl): 0.0, 5.40593e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1199
rank avg (pred): 0.457 +- 0.260
mrr vals (pred, true): 0.093, 0.046
batch losses (mrrl, rdl): 0.0, 1.6697e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 403
rank avg (pred): 0.413 +- 0.262
mrr vals (pred, true): 0.100, 0.050
batch losses (mrrl, rdl): 0.0, 9.9684e-06

Epoch over!
epoch time: 74.646

Epoch 2 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 403
rank avg (pred): 0.431 +- 0.264
mrr vals (pred, true): 0.094, 0.050
batch losses (mrrl, rdl): 0.0, 1.3103e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 901
rank avg (pred): 0.590 +- 0.215
mrr vals (pred, true): 0.059, 0.020
batch losses (mrrl, rdl): 0.0, 9.5e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 417
rank avg (pred): 0.416 +- 0.242
mrr vals (pred, true): 0.098, 0.064
batch losses (mrrl, rdl): 0.0, 6.8997e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 992
rank avg (pred): 0.129 +- 0.134
mrr vals (pred, true): 0.108, 0.285
batch losses (mrrl, rdl): 0.0, 9.4118e-06

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1079
rank avg (pred): 0.168 +- 0.136
mrr vals (pred, true): 0.089, 0.258
batch losses (mrrl, rdl): 0.0, 3.31176e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 112
rank avg (pred): 0.451 +- 0.251
mrr vals (pred, true): 0.094, 0.043
batch losses (mrrl, rdl): 0.0, 2.17771e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 476
rank avg (pred): 0.409 +- 0.262
mrr vals (pred, true): 0.109, 0.044
batch losses (mrrl, rdl): 0.0, 7.879e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 121
rank avg (pred): 0.425 +- 0.271
mrr vals (pred, true): 0.098, 0.041
batch losses (mrrl, rdl): 0.0, 1.43598e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 884
rank avg (pred): 0.432 +- 0.243
mrr vals (pred, true): 0.096, 0.045
batch losses (mrrl, rdl): 0.0, 2.9698e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 512
rank avg (pred): 0.492 +- 0.240
mrr vals (pred, true): 0.072, 0.026
batch losses (mrrl, rdl): 0.0, 1.58618e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1089
rank avg (pred): 0.444 +- 0.266
mrr vals (pred, true): 0.088, 0.053
batch losses (mrrl, rdl): 0.0, 3.6098e-06

Epoch over!
epoch time: 74.96

Epoch 3 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1113
rank avg (pred): 0.436 +- 0.260
mrr vals (pred, true): 0.081, 0.054
batch losses (mrrl, rdl): 0.0, 1.6466e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 234
rank avg (pred): 0.435 +- 0.271
mrr vals (pred, true): 0.086, 0.044
batch losses (mrrl, rdl): 0.0, 4.484e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 824
rank avg (pred): 0.161 +- 0.165
mrr vals (pred, true): 0.101, 0.302
batch losses (mrrl, rdl): 0.0, 1.28047e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 477
rank avg (pred): 0.464 +- 0.280
mrr vals (pred, true): 0.081, 0.048
batch losses (mrrl, rdl): 0.0, 1.48979e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 573
rank avg (pred): 0.458 +- 0.251
mrr vals (pred, true): 0.064, 0.043
batch losses (mrrl, rdl): 0.0, 1.3125e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 145
rank avg (pred): 0.440 +- 0.300
mrr vals (pred, true): 0.081, 0.044
batch losses (mrrl, rdl): 0.0, 9.4982e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 236
rank avg (pred): 0.414 +- 0.246
mrr vals (pred, true): 0.053, 0.049
batch losses (mrrl, rdl): 0.0, 1.07527e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 923
rank avg (pred): 0.445 +- 0.248
mrr vals (pred, true): 0.062, 0.037
batch losses (mrrl, rdl): 0.0, 8.1681e-06

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1056
rank avg (pred): 0.090 +- 0.146
mrr vals (pred, true): 0.222, 0.290
batch losses (mrrl, rdl): 0.0, 6.68188e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 421
rank avg (pred): 0.423 +- 0.252
mrr vals (pred, true): 0.059, 0.047
batch losses (mrrl, rdl): 0.0, 2.0586e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 914
rank avg (pred): 0.619 +- 0.222
mrr vals (pred, true): 0.029, 0.021
batch losses (mrrl, rdl): 0.0, 2.20964e-05

Epoch over!
epoch time: 75.635

Epoch 4 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 157
rank avg (pred): 0.422 +- 0.254
mrr vals (pred, true): 0.053, 0.041
batch losses (mrrl, rdl): 0.0, 1.72474e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 152
rank avg (pred): 0.456 +- 0.277
mrr vals (pred, true): 0.059, 0.055
batch losses (mrrl, rdl): 0.0, 1.61558e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 799
rank avg (pred): 0.449 +- 0.237
mrr vals (pred, true): 0.037, 0.041
batch losses (mrrl, rdl): 0.0, 5.7821e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 715
rank avg (pred): 0.413 +- 0.243
mrr vals (pred, true): 0.052, 0.046
batch losses (mrrl, rdl): 0.0, 1.66473e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 81
rank avg (pred): 0.437 +- 0.246
mrr vals (pred, true): 0.043, 0.048
batch losses (mrrl, rdl): 0.0, 5.1163e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1071
rank avg (pred): 0.202 +- 0.239
mrr vals (pred, true): 0.102, 0.282
batch losses (mrrl, rdl): 0.0, 0.0001086629

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1089
rank avg (pred): 0.448 +- 0.273
mrr vals (pred, true): 0.036, 0.053
batch losses (mrrl, rdl): 0.0, 3.8614e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 60
rank avg (pred): 0.171 +- 0.205
mrr vals (pred, true): 0.128, 0.219
batch losses (mrrl, rdl): 0.0, 1.36373e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 901
rank avg (pred): 0.626 +- 0.193
mrr vals (pred, true): 0.013, 0.020
batch losses (mrrl, rdl): 0.0, 3.02061e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 995
rank avg (pred): 0.177 +- 0.235
mrr vals (pred, true): 0.175, 0.289
batch losses (mrrl, rdl): 0.0, 1.96551e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 405
rank avg (pred): 0.423 +- 0.221
mrr vals (pred, true): 0.030, 0.045
batch losses (mrrl, rdl): 0.0, 2.30228e-05

Epoch over!
epoch time: 74.45

Epoch 5 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 110
rank avg (pred): 0.456 +- 0.246
mrr vals (pred, true): 0.027, 0.050
batch losses (mrrl, rdl): 0.0, 1.14076e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 725
rank avg (pred): 0.465 +- 0.246
mrr vals (pred, true): 0.025, 0.045
batch losses (mrrl, rdl): 0.0, 7.505e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 572
rank avg (pred): 0.443 +- 0.255
mrr vals (pred, true): 0.034, 0.041
batch losses (mrrl, rdl): 0.0, 1.1429e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 985
rank avg (pred): 0.185 +- 0.233
mrr vals (pred, true): 0.141, 0.285
batch losses (mrrl, rdl): 0.0, 1.56328e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 727
rank avg (pred): 0.462 +- 0.254
mrr vals (pred, true): 0.027, 0.044
batch losses (mrrl, rdl): 0.0, 1.49613e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 675
rank avg (pred): 0.458 +- 0.249
mrr vals (pred, true): 0.028, 0.049
batch losses (mrrl, rdl): 0.0, 2.5709e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 609
rank avg (pred): 0.451 +- 0.256
mrr vals (pred, true): 0.031, 0.039
batch losses (mrrl, rdl): 0.0, 9.775e-07

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 514
rank avg (pred): 0.457 +- 0.208
mrr vals (pred, true): 0.023, 0.024
batch losses (mrrl, rdl): 0.0, 7.37685e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 166
rank avg (pred): 0.426 +- 0.230
mrr vals (pred, true): 0.027, 0.052
batch losses (mrrl, rdl): 0.0, 3.7871e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 416
rank avg (pred): 0.434 +- 0.245
mrr vals (pred, true): 0.027, 0.045
batch losses (mrrl, rdl): 0.0, 1.325e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 272
rank avg (pred): 0.189 +- 0.245
mrr vals (pred, true): 0.154, 0.252
batch losses (mrrl, rdl): 0.0, 5.43803e-05

Epoch over!
epoch time: 78.739

Saving checkpoint at [1] epoch 5
Epoch 6 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 909
rank avg (pred): 0.649 +- 0.214
mrr vals (pred, true): 0.014, 0.023
batch losses (mrrl, rdl): 0.0, 0.0001018646

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1169
rank avg (pred): 0.461 +- 0.258
mrr vals (pred, true): 0.025, 0.031
batch losses (mrrl, rdl): 0.0, 6.706e-07

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 502
rank avg (pred): 0.487 +- 0.239
mrr vals (pred, true): 0.021, 0.022
batch losses (mrrl, rdl): 0.0, 3.22456e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1167
rank avg (pred): 0.446 +- 0.244
mrr vals (pred, true): 0.025, 0.032
batch losses (mrrl, rdl): 0.0, 2.28e-07

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1085
rank avg (pred): 0.443 +- 0.248
mrr vals (pred, true): 0.028, 0.054
batch losses (mrrl, rdl): 0.0, 1.9833e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 871
rank avg (pred): 0.465 +- 0.258
mrr vals (pred, true): 0.029, 0.048
batch losses (mrrl, rdl): 0.0, 1.26804e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1136
rank avg (pred): 0.412 +- 0.206
mrr vals (pred, true): 0.033, 0.026
batch losses (mrrl, rdl): 0.0, 7.59984e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 566
rank avg (pred): 0.500 +- 0.222
mrr vals (pred, true): 0.022, 0.023
batch losses (mrrl, rdl): 0.0, 6.6899e-06

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 965
rank avg (pred): 0.471 +- 0.263
mrr vals (pred, true): 0.027, 0.051
batch losses (mrrl, rdl): 0.0, 2.09043e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 303
rank avg (pred): 0.223 +- 0.251
mrr vals (pred, true): 0.141, 0.236
batch losses (mrrl, rdl): 0.0, 8.76479e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 692
rank avg (pred): 0.385 +- 0.268
mrr vals (pred, true): 0.064, 0.052
batch losses (mrrl, rdl): 0.0, 4.1538e-05

Epoch over!
epoch time: 82.452

Epoch 7 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 760
rank avg (pred): 0.454 +- 0.248
mrr vals (pred, true): 0.027, 0.043
batch losses (mrrl, rdl): 0.0, 2.3638e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 220
rank avg (pred): 0.470 +- 0.273
mrr vals (pred, true): 0.026, 0.048
batch losses (mrrl, rdl): 0.0, 2.2692e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 159
rank avg (pred): 0.446 +- 0.269
mrr vals (pred, true): 0.031, 0.048
batch losses (mrrl, rdl): 0.0, 1.9034e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 476
rank avg (pred): 0.444 +- 0.251
mrr vals (pred, true): 0.029, 0.044
batch losses (mrrl, rdl): 0.0, 9.008e-07

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 794
rank avg (pred): 0.447 +- 0.239
mrr vals (pred, true): 0.027, 0.050
batch losses (mrrl, rdl): 0.0, 5.9562e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 840
rank avg (pred): 0.463 +- 0.231
mrr vals (pred, true): 0.025, 0.053
batch losses (mrrl, rdl): 0.0, 9.6194e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 835
rank avg (pred): 0.133 +- 0.222
mrr vals (pred, true): 0.614, 0.285
batch losses (mrrl, rdl): 0.0, 6.1954e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 16
rank avg (pred): 0.097 +- 0.163
mrr vals (pred, true): 0.686, 0.184
batch losses (mrrl, rdl): 0.0, 0.0001324644

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 420
rank avg (pred): 0.410 +- 0.265
mrr vals (pred, true): 0.039, 0.051
batch losses (mrrl, rdl): 0.0, 2.1627e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 89
rank avg (pred): 0.434 +- 0.250
mrr vals (pred, true): 0.027, 0.045
batch losses (mrrl, rdl): 0.0, 5.489e-07

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 690
rank avg (pred): 0.445 +- 0.248
mrr vals (pred, true): 0.026, 0.043
batch losses (mrrl, rdl): 0.0, 1.0756e-06

Epoch over!
epoch time: 80.053

Epoch 8 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 569
rank avg (pred): 0.440 +- 0.267
mrr vals (pred, true): 0.031, 0.038
batch losses (mrrl, rdl): 0.0, 3.4357e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1088
rank avg (pred): 0.416 +- 0.278
mrr vals (pred, true): 0.039, 0.041
batch losses (mrrl, rdl): 0.0, 2.11038e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 572
rank avg (pred): 0.438 +- 0.251
mrr vals (pred, true): 0.031, 0.041
batch losses (mrrl, rdl): 0.0, 3.79e-07

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 783
rank avg (pred): 0.448 +- 0.231
mrr vals (pred, true): 0.025, 0.055
batch losses (mrrl, rdl): 0.0, 1.69103e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 841
rank avg (pred): 0.420 +- 0.245
mrr vals (pred, true): 0.036, 0.047
batch losses (mrrl, rdl): 0.0, 4.107e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 127
rank avg (pred): 0.435 +- 0.259
mrr vals (pred, true): 0.031, 0.045
batch losses (mrrl, rdl): 0.0, 1.4834e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 137
rank avg (pred): 0.439 +- 0.248
mrr vals (pred, true): 0.029, 0.048
batch losses (mrrl, rdl): 0.0, 7.0331e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 266
rank avg (pred): 0.112 +- 0.186
mrr vals (pred, true): 0.695, 0.218
batch losses (mrrl, rdl): 0.0, 6.347e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 291
rank avg (pred): 0.136 +- 0.216
mrr vals (pred, true): 0.498, 0.209
batch losses (mrrl, rdl): 0.0, 4.45711e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 69
rank avg (pred): 0.224 +- 0.255
mrr vals (pred, true): 0.193, 0.209
batch losses (mrrl, rdl): 0.0, 4.72128e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 888
rank avg (pred): 0.476 +- 0.259
mrr vals (pred, true): 0.023, 0.055
batch losses (mrrl, rdl): 0.0, 3.9495e-05

Epoch over!
epoch time: 75.321

Epoch 9 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 649
rank avg (pred): 0.437 +- 0.249
mrr vals (pred, true): 0.028, 0.045
batch losses (mrrl, rdl): 0.0, 1.3143e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 104
rank avg (pred): 0.424 +- 0.269
mrr vals (pred, true): 0.034, 0.055
batch losses (mrrl, rdl): 0.0, 2.1406e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1138
rank avg (pred): 0.515 +- 0.185
mrr vals (pred, true): 0.018, 0.026
batch losses (mrrl, rdl): 0.0, 2.03627e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1187
rank avg (pred): 0.435 +- 0.220
mrr vals (pred, true): 0.027, 0.032
batch losses (mrrl, rdl): 0.0, 1.94639e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 34
rank avg (pred): 0.203 +- 0.233
mrr vals (pred, true): 0.223, 0.237
batch losses (mrrl, rdl): 0.0, 6.32837e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 531
rank avg (pred): 0.509 +- 0.210
mrr vals (pred, true): 0.019, 0.026
batch losses (mrrl, rdl): 0.0, 1.4635e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 545
rank avg (pred): 0.474 +- 0.201
mrr vals (pred, true): 0.021, 0.025
batch losses (mrrl, rdl): 0.0, 2.89033e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 755
rank avg (pred): 0.111 +- 0.168
mrr vals (pred, true): 0.596, 0.211
batch losses (mrrl, rdl): 0.0, 8.76315e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 941
rank avg (pred): 0.490 +- 0.256
mrr vals (pred, true): 0.022, 0.028
batch losses (mrrl, rdl): 0.0, 4.8049e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1056
rank avg (pred): 0.128 +- 0.198
mrr vals (pred, true): 0.626, 0.290
batch losses (mrrl, rdl): 0.0, 3.8728e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1086
rank avg (pred): 0.414 +- 0.257
mrr vals (pred, true): 0.037, 0.039
batch losses (mrrl, rdl): 0.0, 1.60622e-05

Epoch over!
epoch time: 73.967

Epoch 10 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 954
rank avg (pred): 0.461 +- 0.276
mrr vals (pred, true): 0.030, 0.058
batch losses (mrrl, rdl): 0.0, 1.26327e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 664
rank avg (pred): 0.450 +- 0.260
mrr vals (pred, true): 0.029, 0.050
batch losses (mrrl, rdl): 0.0, 7.7186e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 23
rank avg (pred): 0.115 +- 0.181
mrr vals (pred, true): 0.686, 0.211
batch losses (mrrl, rdl): 0.0, 5.32419e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 549
rank avg (pred): 0.479 +- 0.217
mrr vals (pred, true): 0.023, 0.023
batch losses (mrrl, rdl): 0.0, 2.35652e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 194
rank avg (pred): 0.435 +- 0.249
mrr vals (pred, true): 0.031, 0.045
batch losses (mrrl, rdl): 0.0, 8.807e-07

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1140
rank avg (pred): 0.435 +- 0.233
mrr vals (pred, true): 0.029, 0.026
batch losses (mrrl, rdl): 0.0, 5.11204e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 877
rank avg (pred): 0.457 +- 0.252
mrr vals (pred, true): 0.027, 0.046
batch losses (mrrl, rdl): 0.0, 1.3416e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 863
rank avg (pred): 0.422 +- 0.262
mrr vals (pred, true): 0.040, 0.048
batch losses (mrrl, rdl): 0.0, 1.7328e-06

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 513
rank avg (pred): 0.504 +- 0.234
mrr vals (pred, true): 0.022, 0.028
batch losses (mrrl, rdl): 0.0, 4.3531e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 432
rank avg (pred): 0.444 +- 0.238
mrr vals (pred, true): 0.026, 0.046
batch losses (mrrl, rdl): 0.0, 5.8564e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 48
rank avg (pred): 0.142 +- 0.214
mrr vals (pred, true): 0.541, 0.208
batch losses (mrrl, rdl): 0.0, 3.9345e-05

Epoch over!
epoch time: 77.562

Saving checkpoint at [1] epoch 10
Epoch 11 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 452
rank avg (pred): 0.408 +- 0.257
mrr vals (pred, true): 0.040, 0.038
batch losses (mrrl, rdl): 0.0, 2.40989e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 321
rank avg (pred): 0.165 +- 0.221
mrr vals (pred, true): 0.506, 0.176
batch losses (mrrl, rdl): 0.0, 9.2829e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 764
rank avg (pred): 0.478 +- 0.264
mrr vals (pred, true): 0.025, 0.043
batch losses (mrrl, rdl): 0.0, 7.432e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 790
rank avg (pred): 0.456 +- 0.290
mrr vals (pred, true): 0.035, 0.041
batch losses (mrrl, rdl): 0.0, 9.0127e-06

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1126
rank avg (pred): 0.425 +- 0.247
mrr vals (pred, true): 0.027, 0.051
batch losses (mrrl, rdl): 0.0, 8.2547e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 940
rank avg (pred): 0.467 +- 0.244
mrr vals (pred, true): 0.023, 0.040
batch losses (mrrl, rdl): 0.0, 1.7313e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 823
rank avg (pred): 0.131 +- 0.201
mrr vals (pred, true): 0.663, 0.321
batch losses (mrrl, rdl): 0.0, 5.5159e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1061
rank avg (pred): 0.097 +- 0.156
mrr vals (pred, true): 0.684, 0.266
batch losses (mrrl, rdl): 0.0, 0.0001225405

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1000
rank avg (pred): 0.456 +- 0.251
mrr vals (pred, true): 0.024, 0.038
batch losses (mrrl, rdl): 0.0, 4.6102e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 665
rank avg (pred): 0.404 +- 0.263
mrr vals (pred, true): 0.036, 0.050
batch losses (mrrl, rdl): 0.0, 2.8258e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 203
rank avg (pred): 0.438 +- 0.265
mrr vals (pred, true): 0.028, 0.049
batch losses (mrrl, rdl): 0.0, 4.053e-07

Epoch over!
epoch time: 80.534

Epoch 12 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 318
rank avg (pred): 0.152 +- 0.221
mrr vals (pred, true): 0.597, 0.201
batch losses (mrrl, rdl): 0.0, 2.93409e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 283
rank avg (pred): 0.141 +- 0.195
mrr vals (pred, true): 0.453, 0.237
batch losses (mrrl, rdl): 0.0, 5.575e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 892
rank avg (pred): 0.549 +- 0.221
mrr vals (pred, true): 0.016, 0.020
batch losses (mrrl, rdl): 0.0, 5.92632e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 148
rank avg (pred): 0.436 +- 0.246
mrr vals (pred, true): 0.027, 0.045
batch losses (mrrl, rdl): 0.0, 1.49357e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 561
rank avg (pred): 0.505 +- 0.224
mrr vals (pred, true): 0.020, 0.024
batch losses (mrrl, rdl): 0.0, 1.9759e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 866
rank avg (pred): 0.454 +- 0.286
mrr vals (pred, true): 0.029, 0.049
batch losses (mrrl, rdl): 0.0, 3.3592e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1205
rank avg (pred): 0.481 +- 0.259
mrr vals (pred, true): 0.023, 0.057
batch losses (mrrl, rdl): 0.0, 4.88751e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 608
rank avg (pred): 0.445 +- 0.257
mrr vals (pred, true): 0.026, 0.037
batch losses (mrrl, rdl): 0.0, 1.67102e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1131
rank avg (pred): 0.463 +- 0.269
mrr vals (pred, true): 0.025, 0.043
batch losses (mrrl, rdl): 0.0, 6.598e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1145
rank avg (pred): 0.481 +- 0.237
mrr vals (pred, true): 0.023, 0.025
batch losses (mrrl, rdl): 0.0, 7.3803e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 103
rank avg (pred): 0.432 +- 0.263
mrr vals (pred, true): 0.035, 0.047
batch losses (mrrl, rdl): 0.0, 4.244e-07

Epoch over!
epoch time: 74.457

Epoch 13 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 338
rank avg (pred): 0.434 +- 0.256
mrr vals (pred, true): 0.033, 0.053
batch losses (mrrl, rdl): 0.0, 1.008e-07

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 204
rank avg (pred): 0.478 +- 0.263
mrr vals (pred, true): 0.026, 0.047
batch losses (mrrl, rdl): 0.0, 5.8497e-06

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 515
rank avg (pred): 0.542 +- 0.229
mrr vals (pred, true): 0.019, 0.025
batch losses (mrrl, rdl): 0.0, 3.1166e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 419
rank avg (pred): 0.432 +- 0.262
mrr vals (pred, true): 0.033, 0.040
batch losses (mrrl, rdl): 0.0, 9.7851e-06

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 589
rank avg (pred): 0.447 +- 0.230
mrr vals (pred, true): 0.025, 0.040
batch losses (mrrl, rdl): 0.0, 5.3262e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 604
rank avg (pred): 0.447 +- 0.261
mrr vals (pred, true): 0.032, 0.047
batch losses (mrrl, rdl): 0.0, 1.5159e-06

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1047
rank avg (pred): 0.452 +- 0.268
mrr vals (pred, true): 0.037, 0.051
batch losses (mrrl, rdl): 0.0, 1.60448e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 737
rank avg (pred): 0.109 +- 0.162
mrr vals (pred, true): 0.671, 0.293
batch losses (mrrl, rdl): 0.0, 2.50918e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 901
rank avg (pred): 0.606 +- 0.227
mrr vals (pred, true): 0.016, 0.020
batch losses (mrrl, rdl): 0.0, 1.48679e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 278
rank avg (pred): 0.179 +- 0.193
mrr vals (pred, true): 0.411, 0.227
batch losses (mrrl, rdl): 0.0, 3.35575e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 62
rank avg (pred): 0.150 +- 0.177
mrr vals (pred, true): 0.525, 0.225
batch losses (mrrl, rdl): 0.0, 2.1751e-06

Epoch over!
epoch time: 77.257

Epoch 14 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 306
rank avg (pred): 0.157 +- 0.186
mrr vals (pred, true): 0.537, 0.192
batch losses (mrrl, rdl): 0.0, 8.3834e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 583
rank avg (pred): 0.445 +- 0.263
mrr vals (pred, true): 0.030, 0.041
batch losses (mrrl, rdl): 0.0, 1.30785e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 936
rank avg (pred): 0.478 +- 0.253
mrr vals (pred, true): 0.024, 0.040
batch losses (mrrl, rdl): 0.0, 1.018e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 917
rank avg (pred): 0.641 +- 0.247
mrr vals (pred, true): 0.016, 0.019
batch losses (mrrl, rdl): 0.0, 3.80869e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 230
rank avg (pred): 0.450 +- 0.247
mrr vals (pred, true): 0.027, 0.047
batch losses (mrrl, rdl): 0.0, 1.5214e-06

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 958
rank avg (pred): 0.455 +- 0.248
mrr vals (pred, true): 0.031, 0.046
batch losses (mrrl, rdl): 0.0, 3.921e-07

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 856
rank avg (pred): 0.463 +- 0.253
mrr vals (pred, true): 0.024, 0.040
batch losses (mrrl, rdl): 0.0, 5.1568e-06

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 440
rank avg (pred): 0.449 +- 0.257
mrr vals (pred, true): 0.029, 0.056
batch losses (mrrl, rdl): 0.0, 1.4876e-06

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 932
rank avg (pred): 0.455 +- 0.225
mrr vals (pred, true): 0.024, 0.036
batch losses (mrrl, rdl): 0.0, 2.4488e-06

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 644
rank avg (pred): 0.445 +- 0.227
mrr vals (pred, true): 0.029, 0.044
batch losses (mrrl, rdl): 0.0, 6.14e-06

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 98
rank avg (pred): 0.419 +- 0.264
mrr vals (pred, true): 0.050, 0.040
batch losses (mrrl, rdl): 0.0, 1.07867e-05

Epoch over!
epoch time: 76.356

Epoch 15 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 588
rank avg (pred): 0.453 +- 0.231
mrr vals (pred, true): 0.029, 0.041
batch losses (mrrl, rdl): 0.0, 2.4674e-06

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 527
rank avg (pred): 0.495 +- 0.220
mrr vals (pred, true): 0.031, 0.025
batch losses (mrrl, rdl): 0.0, 2.18307e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 510
rank avg (pred): 0.516 +- 0.216
mrr vals (pred, true): 0.026, 0.028
batch losses (mrrl, rdl): 0.0, 2.1512e-06

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 128
rank avg (pred): 0.424 +- 0.267
mrr vals (pred, true): 0.048, 0.046
batch losses (mrrl, rdl): 0.0, 1.67365e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 959
rank avg (pred): 0.451 +- 0.244
mrr vals (pred, true): 0.031, 0.042
batch losses (mrrl, rdl): 0.0, 9.189e-07

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 823
rank avg (pred): 0.148 +- 0.192
mrr vals (pred, true): 0.612, 0.321
batch losses (mrrl, rdl): 0.0, 2.32436e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 343
rank avg (pred): 0.434 +- 0.258
mrr vals (pred, true): 0.041, 0.055
batch losses (mrrl, rdl): 0.0, 1.59e-08

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1064
rank avg (pred): 0.153 +- 0.197
mrr vals (pred, true): 0.566, 0.289
batch losses (mrrl, rdl): 0.0, 2.39561e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 917
rank avg (pred): 0.622 +- 0.263
mrr vals (pred, true): 0.018, 0.019
batch losses (mrrl, rdl): 0.0, 2.65472e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 596
rank avg (pred): 0.454 +- 0.264
mrr vals (pred, true): 0.037, 0.041
batch losses (mrrl, rdl): 0.0, 5.951e-07

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 293
rank avg (pred): 0.169 +- 0.197
mrr vals (pred, true): 0.540, 0.214
batch losses (mrrl, rdl): 0.0, 1.9943e-06

Epoch over!
epoch time: 75.012

Saving checkpoint at [1] epoch 15
Done training phase:  0
Epoch 1 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1065
rank avg (pred): 0.167 +- 0.219
mrr vals (pred, true): 0.575, 0.277
batch losses (mrrl, rdl): 0.889539659, 1.95503e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 549
rank avg (pred): 0.401 +- 0.142
mrr vals (pred, true): 0.055, 0.023
batch losses (mrrl, rdl): 0.0002192581, 0.0002795279

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 69
rank avg (pred): 0.255 +- 0.133
mrr vals (pred, true): 0.209, 0.209
batch losses (mrrl, rdl): 4.0197e-06, 0.0001218398

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1047
rank avg (pred): 0.364 +- 0.163
mrr vals (pred, true): 0.048, 0.051
batch losses (mrrl, rdl): 3.53015e-05, 0.0001269842

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 16
rank avg (pred): 0.226 +- 0.140
mrr vals (pred, true): 0.281, 0.184
batch losses (mrrl, rdl): 0.0951868966, 5.01692e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 491
rank avg (pred): 0.379 +- 0.187
mrr vals (pred, true): 0.042, 0.024
batch losses (mrrl, rdl): 0.0006815734, 0.0004262927

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 638
rank avg (pred): 0.418 +- 0.268
mrr vals (pred, true): 0.052, 0.043
batch losses (mrrl, rdl): 3.54802e-05, 0.0001120411

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 765
rank avg (pred): 0.395 +- 0.270
mrr vals (pred, true): 0.054, 0.043
batch losses (mrrl, rdl): 0.0001925936, 0.0001626474

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 195
rank avg (pred): 0.389 +- 0.279
mrr vals (pred, true): 0.054, 0.052
batch losses (mrrl, rdl): 0.0001833257, 0.0001451425

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1189
rank avg (pred): 0.379 +- 0.266
mrr vals (pred, true): 0.046, 0.054
batch losses (mrrl, rdl): 0.0001427446, 0.0001273496

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 212
rank avg (pred): 0.381 +- 0.272
mrr vals (pred, true): 0.056, 0.047
batch losses (mrrl, rdl): 0.0003379706, 0.000120728

Epoch over!
epoch time: 72.178

Epoch 2 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1026
rank avg (pred): 0.370 +- 0.236
mrr vals (pred, true): 0.038, 0.048
batch losses (mrrl, rdl): 0.0015382969, 0.0001724117

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 197
rank avg (pred): 0.356 +- 0.256
mrr vals (pred, true): 0.048, 0.050
batch losses (mrrl, rdl): 3.00217e-05, 0.0002399037

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 961
rank avg (pred): 0.395 +- 0.290
mrr vals (pred, true): 0.046, 0.045
batch losses (mrrl, rdl): 0.0001550048, 0.0001648632

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 995
rank avg (pred): 0.189 +- 0.116
mrr vals (pred, true): 0.255, 0.289
batch losses (mrrl, rdl): 0.0115602501, 3.27093e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1068
rank avg (pred): 0.192 +- 0.102
mrr vals (pred, true): 0.235, 0.279
batch losses (mrrl, rdl): 0.0189995915, 2.39829e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 558
rank avg (pred): 0.350 +- 0.267
mrr vals (pred, true): 0.054, 0.025
batch losses (mrrl, rdl): 0.00018996, 0.0005933459

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 730
rank avg (pred): 0.183 +- 0.110
mrr vals (pred, true): 0.276, 0.386
batch losses (mrrl, rdl): 0.1213241369, 0.0001519925

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 560
rank avg (pred): 0.326 +- 0.228
mrr vals (pred, true): 0.055, 0.025
batch losses (mrrl, rdl): 0.0002093352, 0.0007679197

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 209
rank avg (pred): 0.378 +- 0.293
mrr vals (pred, true): 0.043, 0.049
batch losses (mrrl, rdl): 0.0004344334, 0.0001541523

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 691
rank avg (pred): 0.374 +- 0.295
mrr vals (pred, true): 0.049, 0.047
batch losses (mrrl, rdl): 8.117e-06, 0.0002311267

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 8
rank avg (pred): 0.194 +- 0.106
mrr vals (pred, true): 0.244, 0.245
batch losses (mrrl, rdl): 2.49941e-05, 4.60165e-05

Epoch over!
epoch time: 71.736

Epoch 3 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1047
rank avg (pred): 0.369 +- 0.281
mrr vals (pred, true): 0.046, 0.051
batch losses (mrrl, rdl): 0.0001375972, 0.0001491249

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 547
rank avg (pred): 0.265 +- 0.124
mrr vals (pred, true): 0.056, 0.023
batch losses (mrrl, rdl): 0.0003845253, 0.0012086335

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 415
rank avg (pred): 0.354 +- 0.288
mrr vals (pred, true): 0.046, 0.044
batch losses (mrrl, rdl): 0.0001308463, 0.0002508241

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 889
rank avg (pred): 0.375 +- 0.309
mrr vals (pred, true): 0.050, 0.047
batch losses (mrrl, rdl): 3.746e-07, 0.0002251444

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1119
rank avg (pred): 0.353 +- 0.287
mrr vals (pred, true): 0.046, 0.060
batch losses (mrrl, rdl): 0.0001656995, 0.0002116737

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 111
rank avg (pred): 0.365 +- 0.298
mrr vals (pred, true): 0.045, 0.045
batch losses (mrrl, rdl): 0.0002362198, 0.0002771266

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 865
rank avg (pred): 0.382 +- 0.311
mrr vals (pred, true): 0.040, 0.049
batch losses (mrrl, rdl): 0.0009192438, 0.0002638176

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 452
rank avg (pred): 0.370 +- 0.291
mrr vals (pred, true): 0.045, 0.038
batch losses (mrrl, rdl): 0.0002155718, 0.0002616525

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 529
rank avg (pred): 0.315 +- 0.185
mrr vals (pred, true): 0.066, 0.025
batch losses (mrrl, rdl): 0.0025928344, 0.0007013607

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 212
rank avg (pred): 0.363 +- 0.289
mrr vals (pred, true): 0.042, 0.047
batch losses (mrrl, rdl): 0.0005648371, 0.000204546

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 266
rank avg (pred): 0.182 +- 0.102
mrr vals (pred, true): 0.256, 0.218
batch losses (mrrl, rdl): 0.0149123818, 2.40969e-05

Epoch over!
epoch time: 73.029

Epoch 4 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 705
rank avg (pred): 0.375 +- 0.296
mrr vals (pred, true): 0.052, 0.043
batch losses (mrrl, rdl): 4.04679e-05, 0.000191323

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 467
rank avg (pred): 0.388 +- 0.304
mrr vals (pred, true): 0.045, 0.048
batch losses (mrrl, rdl): 0.0002974303, 0.0001738322

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 617
rank avg (pred): 0.385 +- 0.300
mrr vals (pred, true): 0.046, 0.035
batch losses (mrrl, rdl): 0.000148752, 0.0002468641

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1183
rank avg (pred): 0.373 +- 0.300
mrr vals (pred, true): 0.051, 0.035
batch losses (mrrl, rdl): 1.58366e-05, 0.0001836268

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 833
rank avg (pred): 0.189 +- 0.121
mrr vals (pred, true): 0.281, 0.321
batch losses (mrrl, rdl): 0.016520163, 6.81146e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 235
rank avg (pred): 0.397 +- 0.304
mrr vals (pred, true): 0.053, 0.046
batch losses (mrrl, rdl): 0.0001057962, 0.0001172478

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 943
rank avg (pred): 0.395 +- 0.286
mrr vals (pred, true): 0.041, 0.031
batch losses (mrrl, rdl): 0.0007606126, 0.0003140171

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 500
rank avg (pred): 0.270 +- 0.103
mrr vals (pred, true): 0.070, 0.025
batch losses (mrrl, rdl): 0.0040563294, 0.0012033883

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 697
rank avg (pred): 0.407 +- 0.293
mrr vals (pred, true): 0.043, 0.048
batch losses (mrrl, rdl): 0.0005226653, 0.0001130206

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 715
rank avg (pred): 0.413 +- 0.293
mrr vals (pred, true): 0.042, 0.046
batch losses (mrrl, rdl): 0.0005725345, 0.0001020745

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 189
rank avg (pred): 0.402 +- 0.288
mrr vals (pred, true): 0.040, 0.043
batch losses (mrrl, rdl): 0.0009044554, 0.000142284

Epoch over!
epoch time: 72.274

Epoch 5 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 573
rank avg (pred): 0.395 +- 0.283
mrr vals (pred, true): 0.044, 0.043
batch losses (mrrl, rdl): 0.0003756021, 0.0001725376

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 851
rank avg (pred): 0.387 +- 0.291
mrr vals (pred, true): 0.052, 0.042
batch losses (mrrl, rdl): 2.73895e-05, 0.0001491405

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1132
rank avg (pred): 0.389 +- 0.296
mrr vals (pred, true): 0.050, 0.053
batch losses (mrrl, rdl): 1.0944e-06, 0.0001271404

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 843
rank avg (pred): 0.388 +- 0.280
mrr vals (pred, true): 0.038, 0.050
batch losses (mrrl, rdl): 0.0014796471, 0.0002301422

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1119
rank avg (pred): 0.386 +- 0.270
mrr vals (pred, true): 0.051, 0.060
batch losses (mrrl, rdl): 8.8213e-06, 8.65581e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 736
rank avg (pred): 0.203 +- 0.123
mrr vals (pred, true): 0.230, 0.292
batch losses (mrrl, rdl): 0.0388628021, 5.32337e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 274
rank avg (pred): 0.203 +- 0.122
mrr vals (pred, true): 0.242, 0.225
batch losses (mrrl, rdl): 0.0030326205, 4.09427e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 363
rank avg (pred): 0.397 +- 0.296
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 4.78883e-05, 0.0001144938

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 852
rank avg (pred): 0.399 +- 0.300
mrr vals (pred, true): 0.046, 0.044
batch losses (mrrl, rdl): 0.0001555771, 0.0001332839

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 144
rank avg (pred): 0.427 +- 0.314
mrr vals (pred, true): 0.043, 0.047
batch losses (mrrl, rdl): 0.0004530681, 6.79853e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 120
rank avg (pred): 0.410 +- 0.294
mrr vals (pred, true): 0.048, 0.044
batch losses (mrrl, rdl): 3.9315e-05, 0.0001109955

Epoch over!
epoch time: 73.346

Saving checkpoint at [1] epoch 5
Epoch 6 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 186
rank avg (pred): 0.426 +- 0.312
mrr vals (pred, true): 0.048, 0.059
batch losses (mrrl, rdl): 3.16226e-05, 4.40997e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 233
rank avg (pred): 0.400 +- 0.296
mrr vals (pred, true): 0.049, 0.051
batch losses (mrrl, rdl): 2.17537e-05, 0.0001098611

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1007
rank avg (pred): 0.426 +- 0.310
mrr vals (pred, true): 0.050, 0.037
batch losses (mrrl, rdl): 2.8e-09, 7.39008e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 176
rank avg (pred): 0.404 +- 0.294
mrr vals (pred, true): 0.049, 0.047
batch losses (mrrl, rdl): 1.50512e-05, 0.0001388254

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 127
rank avg (pred): 0.408 +- 0.295
mrr vals (pred, true): 0.043, 0.045
batch losses (mrrl, rdl): 0.0004270653, 8.24089e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1083
rank avg (pred): 0.400 +- 0.293
mrr vals (pred, true): 0.053, 0.044
batch losses (mrrl, rdl): 7.08947e-05, 0.0001337831

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 478
rank avg (pred): 0.410 +- 0.300
mrr vals (pred, true): 0.054, 0.052
batch losses (mrrl, rdl): 0.0001941758, 9.54866e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 493
rank avg (pred): 0.270 +- 0.070
mrr vals (pred, true): 0.059, 0.024
batch losses (mrrl, rdl): 0.0007322013, 0.0012948168

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 357
rank avg (pred): 0.429 +- 0.289
mrr vals (pred, true): 0.022, 0.050
batch losses (mrrl, rdl): 0.0076246345, 2.90533e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1054
rank avg (pred): 0.190 +- 0.139
mrr vals (pred, true): 0.306, 0.275
batch losses (mrrl, rdl): 0.0095298393, 6.94347e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 948
rank avg (pred): 0.365 +- 0.273
mrr vals (pred, true): 0.046, 0.053
batch losses (mrrl, rdl): 0.0001997759, 0.0002393045

Epoch over!
epoch time: 72.406

Epoch 7 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 924
rank avg (pred): 0.388 +- 0.297
mrr vals (pred, true): 0.058, 0.030
batch losses (mrrl, rdl): 0.0005786812, 0.0003695776

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 218
rank avg (pred): 0.425 +- 0.308
mrr vals (pred, true): 0.050, 0.044
batch losses (mrrl, rdl): 7.8e-09, 6.9657e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1168
rank avg (pred): 0.432 +- 0.301
mrr vals (pred, true): 0.055, 0.036
batch losses (mrrl, rdl): 0.0002229225, 3.01806e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 564
rank avg (pred): 0.415 +- 0.281
mrr vals (pred, true): 0.043, 0.024
batch losses (mrrl, rdl): 0.0004654498, 0.0003250316

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 87
rank avg (pred): 0.415 +- 0.294
mrr vals (pred, true): 0.050, 0.050
batch losses (mrrl, rdl): 3.6e-09, 3.80859e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 441
rank avg (pred): 0.424 +- 0.299
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 3.40215e-05, 5.29634e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 884
rank avg (pred): 0.431 +- 0.304
mrr vals (pred, true): 0.054, 0.045
batch losses (mrrl, rdl): 0.0001582365, 4.81412e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 727
rank avg (pred): 0.392 +- 0.276
mrr vals (pred, true): 0.044, 0.044
batch losses (mrrl, rdl): 0.0003339191, 0.0001017702

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 629
rank avg (pred): 0.430 +- 0.322
mrr vals (pred, true): 0.057, 0.038
batch losses (mrrl, rdl): 0.0005032583, 0.0001104442

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 277
rank avg (pred): 0.231 +- 0.133
mrr vals (pred, true): 0.223, 0.260
batch losses (mrrl, rdl): 0.013666247, 0.0001734592

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 632
rank avg (pred): 0.409 +- 0.288
mrr vals (pred, true): 0.047, 0.037
batch losses (mrrl, rdl): 9.99563e-05, 0.0001855826

Epoch over!
epoch time: 72.806

Epoch 8 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 256
rank avg (pred): 0.214 +- 0.141
mrr vals (pred, true): 0.275, 0.195
batch losses (mrrl, rdl): 0.0638506189, 2.4759e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1024
rank avg (pred): 0.423 +- 0.298
mrr vals (pred, true): 0.049, 0.044
batch losses (mrrl, rdl): 1.82692e-05, 7.73785e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 844
rank avg (pred): 0.423 +- 0.305
mrr vals (pred, true): 0.061, 0.052
batch losses (mrrl, rdl): 0.0011165729, 8.84928e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1088
rank avg (pred): 0.434 +- 0.305
mrr vals (pred, true): 0.055, 0.041
batch losses (mrrl, rdl): 0.0002761893, 7.66933e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 748
rank avg (pred): 0.230 +- 0.146
mrr vals (pred, true): 0.265, 0.312
batch losses (mrrl, rdl): 0.0221505426, 0.0002608714

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 109
rank avg (pred): 0.429 +- 0.294
mrr vals (pred, true): 0.051, 0.044
batch losses (mrrl, rdl): 1.38879e-05, 3.56297e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 561
rank avg (pred): 0.410 +- 0.265
mrr vals (pred, true): 0.050, 0.024
batch losses (mrrl, rdl): 1.579e-07, 0.0002406706

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 978
rank avg (pred): 0.233 +- 0.150
mrr vals (pred, true): 0.274, 0.305
batch losses (mrrl, rdl): 0.0092168329, 0.000104439

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 706
rank avg (pred): 0.442 +- 0.294
mrr vals (pred, true): 0.046, 0.044
batch losses (mrrl, rdl): 0.0001596843, 3.58957e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 863
rank avg (pred): 0.450 +- 0.305
mrr vals (pred, true): 0.055, 0.048
batch losses (mrrl, rdl): 0.0002757654, 2.50484e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 833
rank avg (pred): 0.229 +- 0.150
mrr vals (pred, true): 0.286, 0.321
batch losses (mrrl, rdl): 0.0123294834, 0.0001991127

Epoch over!
epoch time: 72.865

Epoch 9 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1204
rank avg (pred): 0.419 +- 0.275
mrr vals (pred, true): 0.051, 0.050
batch losses (mrrl, rdl): 1.1795e-05, 5.36963e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 176
rank avg (pred): 0.435 +- 0.279
mrr vals (pred, true): 0.051, 0.047
batch losses (mrrl, rdl): 6.0043e-06, 5.13879e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 548
rank avg (pred): 0.408 +- 0.217
mrr vals (pred, true): 0.045, 0.024
batch losses (mrrl, rdl): 0.0002727676, 0.0002929894

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1049
rank avg (pred): 0.442 +- 0.297
mrr vals (pred, true): 0.052, 0.044
batch losses (mrrl, rdl): 3.29349e-05, 5.65022e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 664
rank avg (pred): 0.420 +- 0.283
mrr vals (pred, true): 0.045, 0.050
batch losses (mrrl, rdl): 0.000210025, 4.86699e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 33
rank avg (pred): 0.250 +- 0.141
mrr vals (pred, true): 0.215, 0.212
batch losses (mrrl, rdl): 0.0001145202, 0.0001797197

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 134
rank avg (pred): 0.442 +- 0.296
mrr vals (pred, true): 0.048, 0.052
batch losses (mrrl, rdl): 4.12269e-05, 3.05486e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 309
rank avg (pred): 0.248 +- 0.136
mrr vals (pred, true): 0.217, 0.212
batch losses (mrrl, rdl): 0.0002218371, 0.0001146672

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 718
rank avg (pred): 0.431 +- 0.297
mrr vals (pred, true): 0.055, 0.039
batch losses (mrrl, rdl): 0.0002462803, 9.63668e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1001
rank avg (pred): 0.452 +- 0.294
mrr vals (pred, true): 0.040, 0.050
batch losses (mrrl, rdl): 0.0009218952, 1.93723e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 337
rank avg (pred): 0.447 +- 0.292
mrr vals (pred, true): 0.051, 0.045
batch losses (mrrl, rdl): 2.16032e-05, 1.9789e-05

Epoch over!
epoch time: 81.885

Epoch 10 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 892
rank avg (pred): 0.292 +- 0.091
mrr vals (pred, true): 0.050, 0.020
batch losses (mrrl, rdl): 8.857e-07, 0.0019312222

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 225
rank avg (pred): 0.440 +- 0.281
mrr vals (pred, true): 0.046, 0.045
batch losses (mrrl, rdl): 0.0001357767, 2.06942e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 469
rank avg (pred): 0.435 +- 0.293
mrr vals (pred, true): 0.058, 0.053
batch losses (mrrl, rdl): 0.0005756908, 2.66905e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 258
rank avg (pred): 0.240 +- 0.142
mrr vals (pred, true): 0.257, 0.183
batch losses (mrrl, rdl): 0.0551051982, 5.79712e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1022
rank avg (pred): 0.458 +- 0.293
mrr vals (pred, true): 0.049, 0.039
batch losses (mrrl, rdl): 1.05649e-05, 1.38452e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 911
rank avg (pred): 0.442 +- 0.278
mrr vals (pred, true): 0.042, 0.020
batch losses (mrrl, rdl): 0.0006083788, 0.0004980883

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 837
rank avg (pred): 0.443 +- 0.273
mrr vals (pred, true): 0.042, 0.044
batch losses (mrrl, rdl): 0.0006816103, 4.09948e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 550
rank avg (pred): 0.351 +- 0.139
mrr vals (pred, true): 0.051, 0.026
batch losses (mrrl, rdl): 1.29934e-05, 0.0005720881

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 356
rank avg (pred): 0.437 +- 0.285
mrr vals (pred, true): 0.044, 0.045
batch losses (mrrl, rdl): 0.0004004247, 3.35644e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 689
rank avg (pred): 0.438 +- 0.293
mrr vals (pred, true): 0.043, 0.055
batch losses (mrrl, rdl): 0.0004613068, 3.42983e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 987
rank avg (pred): 0.229 +- 0.135
mrr vals (pred, true): 0.252, 0.322
batch losses (mrrl, rdl): 0.0481036976, 0.0001131614

Epoch over!
epoch time: 84.348

Saving checkpoint at [1] epoch 10
Epoch 11 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 799
rank avg (pred): 0.442 +- 0.305
mrr vals (pred, true): 0.051, 0.041
batch losses (mrrl, rdl): 5.5086e-06, 7.90062e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 755
rank avg (pred): 0.230 +- 0.136
mrr vals (pred, true): 0.265, 0.211
batch losses (mrrl, rdl): 0.0282280166, 6.18403e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 171
rank avg (pred): 0.439 +- 0.287
mrr vals (pred, true): 0.045, 0.050
batch losses (mrrl, rdl): 0.0002197066, 3.01371e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1040
rank avg (pred): 0.447 +- 0.299
mrr vals (pred, true): 0.052, 0.050
batch losses (mrrl, rdl): 3.65566e-05, 2.01076e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1141
rank avg (pred): 0.239 +- 0.149
mrr vals (pred, true): 0.235, 0.023
batch losses (mrrl, rdl): 0.3411405683, 0.001219829

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 346
rank avg (pred): 0.437 +- 0.306
mrr vals (pred, true): 0.053, 0.051
batch losses (mrrl, rdl): 6.5184e-05, 6.23042e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1201
rank avg (pred): 0.436 +- 0.302
mrr vals (pred, true): 0.051, 0.052
batch losses (mrrl, rdl): 4.1271e-06, 3.43879e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 453
rank avg (pred): 0.424 +- 0.288
mrr vals (pred, true): 0.050, 0.052
batch losses (mrrl, rdl): 6.43e-08, 6.30622e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 429
rank avg (pred): 0.466 +- 0.327
mrr vals (pred, true): 0.055, 0.050
batch losses (mrrl, rdl): 0.0002464586, 2.61071e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 55
rank avg (pred): 0.228 +- 0.134
mrr vals (pred, true): 0.237, 0.247
batch losses (mrrl, rdl): 0.0009108823, 0.0001126903

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1123
rank avg (pred): 0.459 +- 0.303
mrr vals (pred, true): 0.038, 0.048
batch losses (mrrl, rdl): 0.001421232, 1.80672e-05

Epoch over!
epoch time: 73.103

Epoch 12 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 732
rank avg (pred): 0.199 +- 0.144
mrr vals (pred, true): 0.338, 0.524
batch losses (mrrl, rdl): 0.3481230736, 0.0004552648

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 794
rank avg (pred): 0.417 +- 0.298
mrr vals (pred, true): 0.063, 0.050
batch losses (mrrl, rdl): 0.0015901604, 5.70116e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 349
rank avg (pred): 0.443 +- 0.300
mrr vals (pred, true): 0.050, 0.051
batch losses (mrrl, rdl): 4.046e-07, 2.9857e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1178
rank avg (pred): 0.404 +- 0.266
mrr vals (pred, true): 0.051, 0.034
batch losses (mrrl, rdl): 4.0161e-06, 8.15729e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 832
rank avg (pred): 0.245 +- 0.140
mrr vals (pred, true): 0.228, 0.302
batch losses (mrrl, rdl): 0.0548204705, 0.0002550775

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 660
rank avg (pred): 0.421 +- 0.293
mrr vals (pred, true): 0.056, 0.052
batch losses (mrrl, rdl): 0.0003589727, 8.36852e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1207
rank avg (pred): 0.442 +- 0.302
mrr vals (pred, true): 0.052, 0.043
batch losses (mrrl, rdl): 5.21818e-05, 5.15411e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 392
rank avg (pred): 0.447 +- 0.298
mrr vals (pred, true): 0.044, 0.043
batch losses (mrrl, rdl): 0.0003292821, 3.62746e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 992
rank avg (pred): 0.238 +- 0.157
mrr vals (pred, true): 0.257, 0.285
batch losses (mrrl, rdl): 0.007918248, 0.0001966531

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 231
rank avg (pred): 0.430 +- 0.298
mrr vals (pred, true): 0.057, 0.049
batch losses (mrrl, rdl): 0.00045247, 4.65681e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 43
rank avg (pred): 0.242 +- 0.144
mrr vals (pred, true): 0.227, 0.199
batch losses (mrrl, rdl): 0.0078871492, 5.75021e-05

Epoch over!
epoch time: 73.448

Epoch 13 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 931
rank avg (pred): 0.410 +- 0.272
mrr vals (pred, true): 0.052, 0.029
batch losses (mrrl, rdl): 5.0403e-05, 0.0002003027

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1195
rank avg (pred): 0.458 +- 0.312
mrr vals (pred, true): 0.055, 0.041
batch losses (mrrl, rdl): 0.0002758585, 3.1208e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 442
rank avg (pred): 0.433 +- 0.298
mrr vals (pred, true): 0.051, 0.047
batch losses (mrrl, rdl): 1.23603e-05, 3.41311e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 444
rank avg (pred): 0.435 +- 0.285
mrr vals (pred, true): 0.038, 0.053
batch losses (mrrl, rdl): 0.0015497046, 2.83256e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1032
rank avg (pred): 0.468 +- 0.318
mrr vals (pred, true): 0.055, 0.050
batch losses (mrrl, rdl): 0.0002165924, 2.56198e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 599
rank avg (pred): 0.431 +- 0.282
mrr vals (pred, true): 0.052, 0.039
batch losses (mrrl, rdl): 3.48861e-05, 0.0001041576

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 55
rank avg (pred): 0.262 +- 0.149
mrr vals (pred, true): 0.209, 0.247
batch losses (mrrl, rdl): 0.0139112035, 0.0002334938

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 130
rank avg (pred): 0.474 +- 0.288
mrr vals (pred, true): 0.041, 0.047
batch losses (mrrl, rdl): 0.0007724657, 1.13681e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 310
rank avg (pred): 0.253 +- 0.147
mrr vals (pred, true): 0.240, 0.220
batch losses (mrrl, rdl): 0.0036304167, 0.0001293418

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1189
rank avg (pred): 0.488 +- 0.295
mrr vals (pred, true): 0.037, 0.054
batch losses (mrrl, rdl): 0.0016073501, 2.18386e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1203
rank avg (pred): 0.452 +- 0.291
mrr vals (pred, true): 0.046, 0.048
batch losses (mrrl, rdl): 0.0001416043, 2.61652e-05

Epoch over!
epoch time: 75.264

Epoch 14 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 866
rank avg (pred): 0.459 +- 0.300
mrr vals (pred, true): 0.055, 0.049
batch losses (mrrl, rdl): 0.0002121185, 2.19519e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 465
rank avg (pred): 0.470 +- 0.305
mrr vals (pred, true): 0.046, 0.050
batch losses (mrrl, rdl): 0.0001883037, 1.54883e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 116
rank avg (pred): 0.474 +- 0.304
mrr vals (pred, true): 0.050, 0.047
batch losses (mrrl, rdl): 3.084e-07, 1.72498e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1162
rank avg (pred): 0.550 +- 0.334
mrr vals (pred, true): 0.045, 0.036
batch losses (mrrl, rdl): 0.000286635, 0.0001042001

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 255
rank avg (pred): 0.258 +- 0.149
mrr vals (pred, true): 0.249, 0.205
batch losses (mrrl, rdl): 0.0190488175, 0.0001057404

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 528
rank avg (pred): 0.324 +- 0.091
mrr vals (pred, true): 0.051, 0.025
batch losses (mrrl, rdl): 5.7079e-06, 0.0007210034

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 530
rank avg (pred): 0.319 +- 0.091
mrr vals (pred, true): 0.056, 0.027
batch losses (mrrl, rdl): 0.0003709083, 0.0008329909

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 531
rank avg (pred): 0.313 +- 0.086
mrr vals (pred, true): 0.045, 0.026
batch losses (mrrl, rdl): 0.0002328224, 0.000906392

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 633
rank avg (pred): 0.444 +- 0.272
mrr vals (pred, true): 0.044, 0.040
batch losses (mrrl, rdl): 0.0003374545, 7.73236e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 143
rank avg (pred): 0.461 +- 0.298
mrr vals (pred, true): 0.053, 0.061
batch losses (mrrl, rdl): 8.20277e-05, 1.45721e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 830
rank avg (pred): 0.233 +- 0.155
mrr vals (pred, true): 0.260, 0.315
batch losses (mrrl, rdl): 0.0298993699, 0.0002626485

Epoch over!
epoch time: 72.83

Epoch 15 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 601
rank avg (pred): 0.427 +- 0.296
mrr vals (pred, true): 0.047, 0.039
batch losses (mrrl, rdl): 7.89136e-05, 0.0001037235

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 374
rank avg (pred): 0.417 +- 0.282
mrr vals (pred, true): 0.050, 0.045
batch losses (mrrl, rdl): 1.3443e-06, 7.11704e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 712
rank avg (pred): 0.448 +- 0.291
mrr vals (pred, true): 0.047, 0.051
batch losses (mrrl, rdl): 0.0001055605, 1.97224e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 173
rank avg (pred): 0.440 +- 0.299
mrr vals (pred, true): 0.052, 0.045
batch losses (mrrl, rdl): 4.80023e-05, 3.61932e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 41
rank avg (pred): 0.258 +- 0.162
mrr vals (pred, true): 0.218, 0.244
batch losses (mrrl, rdl): 0.0064984574, 0.0001511177

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 0
rank avg (pred): 0.253 +- 0.157
mrr vals (pred, true): 0.221, 0.244
batch losses (mrrl, rdl): 0.0053090937, 0.0001444332

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 100
rank avg (pred): 0.456 +- 0.310
mrr vals (pred, true): 0.052, 0.040
batch losses (mrrl, rdl): 3.3661e-05, 4.08103e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 248
rank avg (pred): 0.243 +- 0.145
mrr vals (pred, true): 0.235, 0.274
batch losses (mrrl, rdl): 0.0149407061, 0.0002701926

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1159
rank avg (pred): 0.447 +- 0.312
mrr vals (pred, true): 0.068, 0.025
batch losses (mrrl, rdl): 0.0032450187, 0.0001595323

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 666
rank avg (pred): 0.464 +- 0.323
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 5.70751e-05, 4.61072e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1206
rank avg (pred): 0.477 +- 0.319
mrr vals (pred, true): 0.041, 0.046
batch losses (mrrl, rdl): 0.0008026987, 2.31894e-05

Epoch over!
epoch time: 71.766

Saving checkpoint at [1] epoch 15
Epoch 16 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1118
rank avg (pred): 0.513 +- 0.341
mrr vals (pred, true): 0.047, 0.043
batch losses (mrrl, rdl): 0.0001084088, 4.28334e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 778
rank avg (pred): 0.428 +- 0.304
mrr vals (pred, true): 0.050, 0.040
batch losses (mrrl, rdl): 2.1116e-06, 8.54507e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 356
rank avg (pred): 0.506 +- 0.337
mrr vals (pred, true): 0.046, 0.045
batch losses (mrrl, rdl): 0.0001452995, 4.47447e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 596
rank avg (pred): 0.469 +- 0.318
mrr vals (pred, true): 0.050, 0.041
batch losses (mrrl, rdl): 9.329e-07, 3.08653e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1198
rank avg (pred): 0.523 +- 0.340
mrr vals (pred, true): 0.049, 0.045
batch losses (mrrl, rdl): 8.2888e-06, 6.35728e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 704
rank avg (pred): 0.468 +- 0.317
mrr vals (pred, true): 0.054, 0.048
batch losses (mrrl, rdl): 0.0001758569, 2.04203e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 490
rank avg (pred): 0.355 +- 0.171
mrr vals (pred, true): 0.047, 0.025
batch losses (mrrl, rdl): 0.0001185052, 0.0004837238

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 982
rank avg (pred): 0.301 +- 0.265
mrr vals (pred, true): 0.256, 0.295
batch losses (mrrl, rdl): 0.0152082369, 0.0004869143

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 39
rank avg (pred): 0.246 +- 0.177
mrr vals (pred, true): 0.229, 0.218
batch losses (mrrl, rdl): 0.0010955732, 8.09128e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1140
rank avg (pred): 0.318 +- 0.240
mrr vals (pred, true): 0.101, 0.026
batch losses (mrrl, rdl): 0.0256347544, 0.0006908489

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 280
rank avg (pred): 0.240 +- 0.175
mrr vals (pred, true): 0.224, 0.223
batch losses (mrrl, rdl): 1.02574e-05, 7.71222e-05

Epoch over!
epoch time: 70.709

Epoch 17 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 701
rank avg (pred): 0.429 +- 0.320
mrr vals (pred, true): 0.046, 0.044
batch losses (mrrl, rdl): 0.0001634243, 6.65354e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1018
rank avg (pred): 0.450 +- 0.330
mrr vals (pred, true): 0.048, 0.047
batch losses (mrrl, rdl): 4.41705e-05, 6.18505e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 912
rank avg (pred): 0.423 +- 0.317
mrr vals (pred, true): 0.058, 0.020
batch losses (mrrl, rdl): 0.0006454357, 0.0008141128

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 668
rank avg (pred): 0.480 +- 0.338
mrr vals (pred, true): 0.050, 0.060
batch losses (mrrl, rdl): 1.3531e-06, 3.25933e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 32
rank avg (pred): 0.233 +- 0.135
mrr vals (pred, true): 0.211, 0.232
batch losses (mrrl, rdl): 0.0042580483, 0.0001094202

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 741
rank avg (pred): 0.211 +- 0.139
mrr vals (pred, true): 0.255, 0.278
batch losses (mrrl, rdl): 0.0052738092, 7.50989e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1064
rank avg (pred): 0.237 +- 0.205
mrr vals (pred, true): 0.284, 0.289
batch losses (mrrl, rdl): 0.00023649, 0.0001935994

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 909
rank avg (pred): 0.430 +- 0.318
mrr vals (pred, true): 0.071, 0.023
batch losses (mrrl, rdl): 0.0042172736, 0.0005940736

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 422
rank avg (pred): 0.398 +- 0.293
mrr vals (pred, true): 0.049, 0.052
batch losses (mrrl, rdl): 1.34726e-05, 0.0001158305

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 28
rank avg (pred): 0.230 +- 0.180
mrr vals (pred, true): 0.228, 0.231
batch losses (mrrl, rdl): 9.15998e-05, 9.16074e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 901
rank avg (pred): 0.428 +- 0.325
mrr vals (pred, true): 0.053, 0.020
batch losses (mrrl, rdl): 9.54763e-05, 0.0006975666

Epoch over!
epoch time: 72.577

Epoch 18 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 230
rank avg (pred): 0.449 +- 0.326
mrr vals (pred, true): 0.041, 0.047
batch losses (mrrl, rdl): 0.0008026112, 5.28033e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1090
rank avg (pred): 0.443 +- 0.325
mrr vals (pred, true): 0.042, 0.045
batch losses (mrrl, rdl): 0.0005978221, 7.17257e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1020
rank avg (pred): 0.479 +- 0.349
mrr vals (pred, true): 0.050, 0.041
batch losses (mrrl, rdl): 3.729e-07, 6.31422e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 690
rank avg (pred): 0.479 +- 0.342
mrr vals (pred, true): 0.044, 0.043
batch losses (mrrl, rdl): 0.0003776341, 4.45341e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 307
rank avg (pred): 0.222 +- 0.141
mrr vals (pred, true): 0.227, 0.219
batch losses (mrrl, rdl): 0.0006054905, 4.97215e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 613
rank avg (pred): 0.425 +- 0.312
mrr vals (pred, true): 0.050, 0.038
batch losses (mrrl, rdl): 1.1951e-06, 0.000108477

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 400
rank avg (pred): 0.428 +- 0.309
mrr vals (pred, true): 0.044, 0.052
batch losses (mrrl, rdl): 0.0003443324, 4.92858e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1104
rank avg (pred): 0.465 +- 0.326
mrr vals (pred, true): 0.045, 0.046
batch losses (mrrl, rdl): 0.0002551315, 2.81851e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 399
rank avg (pred): 0.458 +- 0.328
mrr vals (pred, true): 0.051, 0.054
batch losses (mrrl, rdl): 3.4028e-06, 2.71998e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 563
rank avg (pred): 0.407 +- 0.285
mrr vals (pred, true): 0.049, 0.021
batch losses (mrrl, rdl): 1.66848e-05, 0.000503218

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 584
rank avg (pred): 0.452 +- 0.320
mrr vals (pred, true): 0.047, 0.044
batch losses (mrrl, rdl): 9.55297e-05, 5.38066e-05

Epoch over!
epoch time: 74.141

Epoch 19 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 310
rank avg (pred): 0.238 +- 0.157
mrr vals (pred, true): 0.218, 0.220
batch losses (mrrl, rdl): 6.58119e-05, 7.49491e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 607
rank avg (pred): 0.449 +- 0.316
mrr vals (pred, true): 0.050, 0.044
batch losses (mrrl, rdl): 9.231e-07, 7.15827e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 780
rank avg (pred): 0.456 +- 0.325
mrr vals (pred, true): 0.050, 0.038
batch losses (mrrl, rdl): 6.57e-07, 5.0506e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 255
rank avg (pred): 0.220 +- 0.128
mrr vals (pred, true): 0.244, 0.205
batch losses (mrrl, rdl): 0.01541261, 3.50423e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 28
rank avg (pred): 0.237 +- 0.162
mrr vals (pred, true): 0.228, 0.231
batch losses (mrrl, rdl): 0.0001206824, 0.000129654

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 306
rank avg (pred): 0.241 +- 0.153
mrr vals (pred, true): 0.221, 0.192
batch losses (mrrl, rdl): 0.0088093327, 6.71243e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 258
rank avg (pred): 0.237 +- 0.142
mrr vals (pred, true): 0.230, 0.183
batch losses (mrrl, rdl): 0.022593243, 4.72451e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 104
rank avg (pred): 0.453 +- 0.312
mrr vals (pred, true): 0.047, 0.055
batch losses (mrrl, rdl): 9.68517e-05, 3.02133e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1163
rank avg (pred): 0.515 +- 0.344
mrr vals (pred, true): 0.045, 0.040
batch losses (mrrl, rdl): 0.0002983424, 5.81056e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 636
rank avg (pred): 0.421 +- 0.303
mrr vals (pred, true): 0.049, 0.046
batch losses (mrrl, rdl): 2.23538e-05, 0.0001295999

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 201
rank avg (pred): 0.431 +- 0.305
mrr vals (pred, true): 0.050, 0.043
batch losses (mrrl, rdl): 9.5e-09, 7.73725e-05

Epoch over!
epoch time: 77.163

Epoch 20 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 141
rank avg (pred): 0.438 +- 0.303
mrr vals (pred, true): 0.046, 0.041
batch losses (mrrl, rdl): 0.0001275984, 2.5396e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1123
rank avg (pred): 0.443 +- 0.311
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 3.99333e-05, 3.43266e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 477
rank avg (pred): 0.427 +- 0.304
mrr vals (pred, true): 0.056, 0.048
batch losses (mrrl, rdl): 0.000342278, 6.71556e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 471
rank avg (pred): 0.440 +- 0.310
mrr vals (pred, true): 0.052, 0.047
batch losses (mrrl, rdl): 3.60214e-05, 7.97063e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 812
rank avg (pred): 0.208 +- 0.182
mrr vals (pred, true): 0.352, 0.377
batch losses (mrrl, rdl): 0.0061002304, 0.000229026

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 328
rank avg (pred): 0.454 +- 0.313
mrr vals (pred, true): 0.046, 0.043
batch losses (mrrl, rdl): 0.0001918357, 3.11049e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 601
rank avg (pred): 0.470 +- 0.325
mrr vals (pred, true): 0.049, 0.039
batch losses (mrrl, rdl): 8.7926e-06, 4.3984e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1181
rank avg (pred): 0.456 +- 0.312
mrr vals (pred, true): 0.044, 0.038
batch losses (mrrl, rdl): 0.0003542693, 2.93811e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 734
rank avg (pred): 0.213 +- 0.203
mrr vals (pred, true): 0.361, 0.528
batch losses (mrrl, rdl): 0.2759347558, 0.0005361571

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 866
rank avg (pred): 0.471 +- 0.334
mrr vals (pred, true): 0.050, 0.049
batch losses (mrrl, rdl): 1.581e-07, 3.30391e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 828
rank avg (pred): 0.232 +- 0.157
mrr vals (pred, true): 0.246, 0.328
batch losses (mrrl, rdl): 0.0673825294, 0.0002530488

Epoch over!
epoch time: 76.833

Saving checkpoint at [1] epoch 20
Epoch 21 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 645
rank avg (pred): 0.499 +- 0.342
mrr vals (pred, true): 0.049, 0.045
batch losses (mrrl, rdl): 3.9544e-06, 4.49685e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 33
rank avg (pred): 0.235 +- 0.165
mrr vals (pred, true): 0.234, 0.212
batch losses (mrrl, rdl): 0.0049037212, 0.0001081352

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 199
rank avg (pred): 0.471 +- 0.337
mrr vals (pred, true): 0.051, 0.045
batch losses (mrrl, rdl): 7.4982e-06, 4.24874e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 994
rank avg (pred): 0.285 +- 0.272
mrr vals (pred, true): 0.273, 0.275
batch losses (mrrl, rdl): 2.17661e-05, 0.0002353214

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 321
rank avg (pred): 0.239 +- 0.164
mrr vals (pred, true): 0.219, 0.176
batch losses (mrrl, rdl): 0.0190834701, 3.76982e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 359
rank avg (pred): 0.474 +- 0.339
mrr vals (pred, true): 0.053, 0.048
batch losses (mrrl, rdl): 9.56697e-05, 4.36015e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 48
rank avg (pred): 0.234 +- 0.136
mrr vals (pred, true): 0.215, 0.208
batch losses (mrrl, rdl): 0.0005232375, 4.32784e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 167
rank avg (pred): 0.459 +- 0.319
mrr vals (pred, true): 0.046, 0.054
batch losses (mrrl, rdl): 0.0001719193, 3.78509e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 431
rank avg (pred): 0.468 +- 0.335
mrr vals (pred, true): 0.050, 0.056
batch losses (mrrl, rdl): 1.2686e-06, 3.48461e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1197
rank avg (pred): 0.503 +- 0.347
mrr vals (pred, true): 0.050, 0.045
batch losses (mrrl, rdl): 2.243e-07, 4.94766e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 79
rank avg (pred): 0.217 +- 0.120
mrr vals (pred, true): 0.236, 0.203
batch losses (mrrl, rdl): 0.0107335392, 4.71284e-05

Epoch over!
epoch time: 74.594

Epoch 22 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 452
rank avg (pred): 0.445 +- 0.314
mrr vals (pred, true): 0.045, 0.038
batch losses (mrrl, rdl): 0.000208835, 5.75066e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 691
rank avg (pred): 0.446 +- 0.316
mrr vals (pred, true): 0.052, 0.047
batch losses (mrrl, rdl): 5.59636e-05, 4.76142e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 317
rank avg (pred): 0.229 +- 0.127
mrr vals (pred, true): 0.233, 0.186
batch losses (mrrl, rdl): 0.021542443, 4.08302e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 601
rank avg (pred): 0.452 +- 0.309
mrr vals (pred, true): 0.047, 0.039
batch losses (mrrl, rdl): 6.40981e-05, 5.69361e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1206
rank avg (pred): 0.486 +- 0.327
mrr vals (pred, true): 0.049, 0.046
batch losses (mrrl, rdl): 1.55309e-05, 2.53548e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 271
rank avg (pred): 0.246 +- 0.163
mrr vals (pred, true): 0.231, 0.253
batch losses (mrrl, rdl): 0.0048589469, 0.0002060093

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1096
rank avg (pred): 0.470 +- 0.319
mrr vals (pred, true): 0.041, 0.043
batch losses (mrrl, rdl): 0.000869724, 2.71705e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 551
rank avg (pred): 0.453 +- 0.281
mrr vals (pred, true): 0.049, 0.025
batch losses (mrrl, rdl): 4.9292e-06, 0.000177827

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 62
rank avg (pred): 0.264 +- 0.156
mrr vals (pred, true): 0.217, 0.225
batch losses (mrrl, rdl): 0.0006427235, 0.0002374257

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1108
rank avg (pred): 0.523 +- 0.334
mrr vals (pred, true): 0.061, 0.047
batch losses (mrrl, rdl): 0.0012982471, 8.13579e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 383
rank avg (pred): 0.504 +- 0.323
mrr vals (pred, true): 0.047, 0.043
batch losses (mrrl, rdl): 0.0001032212, 3.83236e-05

Epoch over!
epoch time: 84.465

Epoch 23 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 550
rank avg (pred): 0.506 +- 0.327
mrr vals (pred, true): 0.052, 0.026
batch losses (mrrl, rdl): 3.39052e-05, 0.0001035365

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 795
rank avg (pred): 0.469 +- 0.310
mrr vals (pred, true): 0.041, 0.041
batch losses (mrrl, rdl): 0.0007544917, 3.01451e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1035
rank avg (pred): 0.531 +- 0.338
mrr vals (pred, true): 0.046, 0.044
batch losses (mrrl, rdl): 0.0001394323, 5.96215e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 727
rank avg (pred): 0.516 +- 0.338
mrr vals (pred, true): 0.048, 0.044
batch losses (mrrl, rdl): 2.94793e-05, 5.95349e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 42
rank avg (pred): 0.243 +- 0.157
mrr vals (pred, true): 0.235, 0.200
batch losses (mrrl, rdl): 0.0118294396, 6.22233e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 59
rank avg (pred): 0.247 +- 0.146
mrr vals (pred, true): 0.213, 0.267
batch losses (mrrl, rdl): 0.0293957964, 0.0002504372

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 423
rank avg (pred): 0.487 +- 0.328
mrr vals (pred, true): 0.049, 0.041
batch losses (mrrl, rdl): 1.70473e-05, 3.36438e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 848
rank avg (pred): 0.481 +- 0.330
mrr vals (pred, true): 0.050, 0.051
batch losses (mrrl, rdl): 1.8156e-06, 3.04845e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 469
rank avg (pred): 0.522 +- 0.351
mrr vals (pred, true): 0.047, 0.053
batch losses (mrrl, rdl): 9.58973e-05, 8.98838e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1111
rank avg (pred): 0.494 +- 0.337
mrr vals (pred, true): 0.048, 0.039
batch losses (mrrl, rdl): 3.83361e-05, 3.62414e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 852
rank avg (pred): 0.484 +- 0.340
mrr vals (pred, true): 0.048, 0.044
batch losses (mrrl, rdl): 5.35567e-05, 4.08709e-05

Epoch over!
epoch time: 76.265

Epoch 24 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 780
rank avg (pred): 0.456 +- 0.329
mrr vals (pred, true): 0.046, 0.038
batch losses (mrrl, rdl): 0.0001471691, 5.21213e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 441
rank avg (pred): 0.453 +- 0.322
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 3.68555e-05, 3.18031e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 677
rank avg (pred): 0.466 +- 0.322
mrr vals (pred, true): 0.046, 0.039
batch losses (mrrl, rdl): 0.0001318521, 3.14372e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 505
rank avg (pred): 0.450 +- 0.318
mrr vals (pred, true): 0.049, 0.030
batch losses (mrrl, rdl): 2.03527e-05, 0.0002176695

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 657
rank avg (pred): 0.431 +- 0.313
mrr vals (pred, true): 0.047, 0.041
batch losses (mrrl, rdl): 8.04379e-05, 5.47968e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 957
rank avg (pred): 0.448 +- 0.323
mrr vals (pred, true): 0.051, 0.041
batch losses (mrrl, rdl): 4.9605e-06, 7.64869e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1141
rank avg (pred): 0.441 +- 0.316
mrr vals (pred, true): 0.096, 0.023
batch losses (mrrl, rdl): 0.0210424233, 0.0001787149

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 669
rank avg (pred): 0.492 +- 0.333
mrr vals (pred, true): 0.049, 0.043
batch losses (mrrl, rdl): 1.42348e-05, 3.65722e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 595
rank avg (pred): 0.461 +- 0.324
mrr vals (pred, true): 0.044, 0.041
batch losses (mrrl, rdl): 0.0003062183, 4.18934e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 420
rank avg (pred): 0.456 +- 0.326
mrr vals (pred, true): 0.047, 0.051
batch losses (mrrl, rdl): 0.0001080377, 2.77842e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 509
rank avg (pred): 0.388 +- 0.262
mrr vals (pred, true): 0.047, 0.025
batch losses (mrrl, rdl): 9.72772e-05, 0.0004565254

Epoch over!
epoch time: 70.074

Epoch 25 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 542
rank avg (pred): 0.424 +- 0.290
mrr vals (pred, true): 0.050, 0.027
batch losses (mrrl, rdl): 1.2265e-06, 0.0002900682

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1040
rank avg (pred): 0.473 +- 0.330
mrr vals (pred, true): 0.046, 0.050
batch losses (mrrl, rdl): 0.0001542194, 3.15202e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 788
rank avg (pred): 0.439 +- 0.313
mrr vals (pred, true): 0.045, 0.045
batch losses (mrrl, rdl): 0.0002836531, 8.87883e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 319
rank avg (pred): 0.218 +- 0.131
mrr vals (pred, true): 0.237, 0.188
batch losses (mrrl, rdl): 0.0240250975, 2.40785e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 892
rank avg (pred): 0.461 +- 0.346
mrr vals (pred, true): 0.101, 0.020
batch losses (mrrl, rdl): 0.0263888538, 0.00061311

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 172
rank avg (pred): 0.457 +- 0.332
mrr vals (pred, true): 0.050, 0.047
batch losses (mrrl, rdl): 6.402e-07, 4.80856e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 647
rank avg (pred): 0.467 +- 0.344
mrr vals (pred, true): 0.049, 0.039
batch losses (mrrl, rdl): 5.8579e-06, 5.93166e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1066
rank avg (pred): 0.308 +- 0.313
mrr vals (pred, true): 0.272, 0.259
batch losses (mrrl, rdl): 0.0017330773, 0.0002236947

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 701
rank avg (pred): 0.464 +- 0.340
mrr vals (pred, true): 0.048, 0.044
batch losses (mrrl, rdl): 5.92692e-05, 4.43776e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 107
rank avg (pred): 0.508 +- 0.352
mrr vals (pred, true): 0.046, 0.042
batch losses (mrrl, rdl): 0.0001567973, 5.79606e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1203
rank avg (pred): 0.521 +- 0.367
mrr vals (pred, true): 0.047, 0.048
batch losses (mrrl, rdl): 8.84018e-05, 8.28299e-05

Epoch over!
epoch time: 82.067

Saving checkpoint at [1] epoch 25
Epoch 26 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 423
rank avg (pred): 0.480 +- 0.354
mrr vals (pred, true): 0.050, 0.041
batch losses (mrrl, rdl): 1.5596e-06, 6.3841e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 83
rank avg (pred): 0.488 +- 0.358
mrr vals (pred, true): 0.048, 0.041
batch losses (mrrl, rdl): 3.50518e-05, 6.28712e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 928
rank avg (pred): 0.450 +- 0.338
mrr vals (pred, true): 0.050, 0.039
batch losses (mrrl, rdl): 9.781e-07, 9.08117e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 265
rank avg (pred): 0.202 +- 0.113
mrr vals (pred, true): 0.251, 0.182
batch losses (mrrl, rdl): 0.047261972, 2.12451e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1085
rank avg (pred): 0.506 +- 0.352
mrr vals (pred, true): 0.045, 0.054
batch losses (mrrl, rdl): 0.0002232994, 5.71775e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 233
rank avg (pred): 0.474 +- 0.336
mrr vals (pred, true): 0.045, 0.051
batch losses (mrrl, rdl): 0.000289762, 3.73031e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 838
rank avg (pred): 0.470 +- 0.328
mrr vals (pred, true): 0.047, 0.051
batch losses (mrrl, rdl): 0.0001136369, 3.07595e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 335
rank avg (pred): 0.458 +- 0.320
mrr vals (pred, true): 0.046, 0.053
batch losses (mrrl, rdl): 0.000122585, 3.12485e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 504
rank avg (pred): 0.422 +- 0.310
mrr vals (pred, true): 0.052, 0.025
batch losses (mrrl, rdl): 6.03886e-05, 0.0003370876

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 57
rank avg (pred): 0.221 +- 0.132
mrr vals (pred, true): 0.228, 0.243
batch losses (mrrl, rdl): 0.00240054, 9.69862e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 984
rank avg (pred): 0.272 +- 0.255
mrr vals (pred, true): 0.267, 0.296
batch losses (mrrl, rdl): 0.008249321, 0.0002260249

Epoch over!
epoch time: 80.239

Epoch 27 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 352
rank avg (pred): 0.473 +- 0.335
mrr vals (pred, true): 0.047, 0.048
batch losses (mrrl, rdl): 8.78773e-05, 3.57809e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 764
rank avg (pred): 0.510 +- 0.354
mrr vals (pred, true): 0.047, 0.043
batch losses (mrrl, rdl): 6.62968e-05, 6.16916e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 216
rank avg (pred): 0.483 +- 0.346
mrr vals (pred, true): 0.048, 0.045
batch losses (mrrl, rdl): 6.23428e-05, 4.58745e-05

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1071
rank avg (pred): 0.283 +- 0.286
mrr vals (pred, true): 0.281, 0.282
batch losses (mrrl, rdl): 2.64295e-05, 0.0003395026

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1184
rank avg (pred): 0.508 +- 0.356
mrr vals (pred, true): 0.048, 0.030
batch losses (mrrl, rdl): 2.31204e-05, 6.46658e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 89
rank avg (pred): 0.474 +- 0.341
mrr vals (pred, true): 0.048, 0.045
batch losses (mrrl, rdl): 2.40448e-05, 4.37292e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 884
rank avg (pred): 0.458 +- 0.332
mrr vals (pred, true): 0.049, 0.045
batch losses (mrrl, rdl): 1.87792e-05, 4.47877e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 237
rank avg (pred): 0.474 +- 0.335
mrr vals (pred, true): 0.048, 0.048
batch losses (mrrl, rdl): 3.67189e-05, 3.85697e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 862
rank avg (pred): 0.483 +- 0.340
mrr vals (pred, true): 0.046, 0.043
batch losses (mrrl, rdl): 0.0001311194, 4.62537e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 390
rank avg (pred): 0.489 +- 0.350
mrr vals (pred, true): 0.050, 0.049
batch losses (mrrl, rdl): 1.529e-07, 5.04315e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 281
rank avg (pred): 0.230 +- 0.169
mrr vals (pred, true): 0.230, 0.226
batch losses (mrrl, rdl): 0.0001362636, 3.64987e-05

Epoch over!
epoch time: 73.894

Epoch 28 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 650
rank avg (pred): 0.492 +- 0.340
mrr vals (pred, true): 0.045, 0.048
batch losses (mrrl, rdl): 0.0002747909, 4.23876e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 912
rank avg (pred): 0.482 +- 0.340
mrr vals (pred, true): 0.052, 0.020
batch losses (mrrl, rdl): 3.75309e-05, 0.0004961896

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 556
rank avg (pred): 0.438 +- 0.307
mrr vals (pred, true): 0.053, 0.021
batch losses (mrrl, rdl): 6.74395e-05, 0.0002270875

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 162
rank avg (pred): 0.495 +- 0.338
mrr vals (pred, true): 0.049, 0.049
batch losses (mrrl, rdl): 1.81883e-05, 4.23335e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 879
rank avg (pred): 0.500 +- 0.327
mrr vals (pred, true): 0.046, 0.053
batch losses (mrrl, rdl): 0.0001826822, 3.57086e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 718
rank avg (pred): 0.503 +- 0.331
mrr vals (pred, true): 0.046, 0.039
batch losses (mrrl, rdl): 0.0001722045, 3.37228e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 267
rank avg (pred): 0.217 +- 0.133
mrr vals (pred, true): 0.268, 0.175
batch losses (mrrl, rdl): 0.0860828981, 2.04677e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 964
rank avg (pred): 0.455 +- 0.323
mrr vals (pred, true): 0.050, 0.045
batch losses (mrrl, rdl): 2.74e-08, 4.45132e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1058
rank avg (pred): 0.241 +- 0.257
mrr vals (pred, true): 0.356, 0.291
batch losses (mrrl, rdl): 0.0415800549, 7.42565e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 349
rank avg (pred): 0.491 +- 0.338
mrr vals (pred, true): 0.048, 0.051
batch losses (mrrl, rdl): 4.52252e-05, 3.93798e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 878
rank avg (pred): 0.455 +- 0.324
mrr vals (pred, true): 0.046, 0.049
batch losses (mrrl, rdl): 0.000136119, 6.17015e-05

Epoch over!
epoch time: 79.511

Epoch 29 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1007
rank avg (pred): 0.486 +- 0.333
mrr vals (pred, true): 0.045, 0.037
batch losses (mrrl, rdl): 0.0002133621, 3.75909e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 823
rank avg (pred): 0.210 +- 0.160
mrr vals (pred, true): 0.281, 0.321
batch losses (mrrl, rdl): 0.0160516538, 0.0001323612

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 251
rank avg (pred): 0.223 +- 0.151
mrr vals (pred, true): 0.244, 0.246
batch losses (mrrl, rdl): 4.26596e-05, 0.0001393497

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 99
rank avg (pred): 0.468 +- 0.329
mrr vals (pred, true): 0.045, 0.047
batch losses (mrrl, rdl): 0.0002790464, 3.92658e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 483
rank avg (pred): 0.473 +- 0.340
mrr vals (pred, true): 0.052, 0.051
batch losses (mrrl, rdl): 3.7757e-05, 4.03879e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1074
rank avg (pred): 0.336 +- 0.338
mrr vals (pred, true): 0.273, 0.262
batch losses (mrrl, rdl): 0.0010513159, 0.0004083013

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 563
rank avg (pred): 0.505 +- 0.357
mrr vals (pred, true): 0.052, 0.021
batch losses (mrrl, rdl): 4.60841e-05, 0.0002073556

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1187
rank avg (pred): 0.456 +- 0.330
mrr vals (pred, true): 0.044, 0.032
batch losses (mrrl, rdl): 0.0003930803, 8.1221e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 910
rank avg (pred): 0.502 +- 0.367
mrr vals (pred, true): 0.065, 0.020
batch losses (mrrl, rdl): 0.0023295947, 0.0003840303

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1177
rank avg (pred): 0.477 +- 0.339
mrr vals (pred, true): 0.048, 0.031
batch losses (mrrl, rdl): 5.00653e-05, 4.3081e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 140
rank avg (pred): 0.520 +- 0.349
mrr vals (pred, true): 0.044, 0.040
batch losses (mrrl, rdl): 0.0003354808, 6.96403e-05

Epoch over!
epoch time: 79.162

Epoch 30 -- 
running batch: 0 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 376
rank avg (pred): 0.506 +- 0.351
mrr vals (pred, true): 0.049, 0.044
batch losses (mrrl, rdl): 4.3265e-06, 6.07709e-05

running batch: 500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 967
rank avg (pred): 0.509 +- 0.351
mrr vals (pred, true): 0.046, 0.047
batch losses (mrrl, rdl): 0.000124775, 5.66244e-05

running batch: 1000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1050
rank avg (pred): 0.529 +- 0.354
mrr vals (pred, true): 0.044, 0.045
batch losses (mrrl, rdl): 0.000348132, 0.0001048051

running batch: 1500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 193
rank avg (pred): 0.519 +- 0.356
mrr vals (pred, true): 0.048, 0.043
batch losses (mrrl, rdl): 5.75753e-05, 6.71968e-05

running batch: 2000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 947
rank avg (pred): 0.512 +- 0.355
mrr vals (pred, true): 0.048, 0.047
batch losses (mrrl, rdl): 5.12971e-05, 6.95847e-05

running batch: 2500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1182
rank avg (pred): 0.511 +- 0.357
mrr vals (pred, true): 0.050, 0.034
batch losses (mrrl, rdl): 2.0307e-06, 8.17197e-05

running batch: 3000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 873
rank avg (pred): 0.485 +- 0.341
mrr vals (pred, true): 0.050, 0.056
batch losses (mrrl, rdl): 9.76e-08, 3.51439e-05

running batch: 3500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 182
rank avg (pred): 0.504 +- 0.350
mrr vals (pred, true): 0.047, 0.045
batch losses (mrrl, rdl): 9.70551e-05, 5.03289e-05

running batch: 4000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 793
rank avg (pred): 0.479 +- 0.338
mrr vals (pred, true): 0.046, 0.041
batch losses (mrrl, rdl): 0.0001721709, 4.92118e-05

running batch: 4500 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 455
rank avg (pred): 0.510 +- 0.342
mrr vals (pred, true): 0.047, 0.051
batch losses (mrrl, rdl): 9.40572e-05, 4.92031e-05

running batch: 5000 / 5470 and superbatch(1); data from UMLS, run 2.1, exp 1171
rank avg (pred): 0.502 +- 0.347
mrr vals (pred, true): 0.047, 0.035
batch losses (mrrl, rdl): 0.0001098879, 5.75386e-05

Epoch over!
epoch time: 69.984

Saving checkpoint at [1] epoch 30
Done training phase:  1
Testing model with dataset UMLS
Running eval on the test set
running batch: 0
rank avg (pred): 0.477 +- 0.338
mrr vals (pred, true): 0.056, 0.018

Evaluation for UMLS on the test set
==========================================
(Sorted by True MRR values)
i_pred 	 i_true 	 Pred MRR 	 True MRR 	 Change Flag
   79 	     0 	 0.05574 	 0.01773 	 m..s
   85 	     1 	 0.05836 	 0.02009 	 m..s
   83 	     2 	 0.05661 	 0.02164 	 m..s
   76 	     3 	 0.05208 	 0.02192 	 m..s
   82 	     4 	 0.05653 	 0.02235 	 m..s
   77 	     5 	 0.05422 	 0.02398 	 m..s
   78 	     6 	 0.05469 	 0.02414 	 m..s
   87 	     7 	 0.06728 	 0.02414 	 m..s
   84 	     8 	 0.05676 	 0.02423 	 m..s
   86 	     9 	 0.05856 	 0.02467 	 m..s
   88 	    10 	 0.07089 	 0.02475 	 m..s
   81 	    11 	 0.05651 	 0.02496 	 m..s
   89 	    12 	 0.08095 	 0.02544 	 m..s
   80 	    13 	 0.05630 	 0.02586 	 m..s
   14 	    14 	 0.04707 	 0.02933 	 ~...
   48 	    15 	 0.04747 	 0.03159 	 ~...
   75 	    16 	 0.04808 	 0.03197 	 ~...
   43 	    17 	 0.04740 	 0.03458 	 ~...
   74 	    18 	 0.04799 	 0.03549 	 ~...
   70 	    19 	 0.04775 	 0.03582 	 ~...
    2 	    20 	 0.04693 	 0.03732 	 ~...
   73 	    21 	 0.04787 	 0.03811 	 ~...
    4 	    22 	 0.04696 	 0.03856 	 ~...
   63 	    23 	 0.04765 	 0.03931 	 ~...
   67 	    24 	 0.04771 	 0.03957 	 ~...
   18 	    25 	 0.04713 	 0.03980 	 ~...
    9 	    26 	 0.04706 	 0.04032 	 ~...
    8 	    27 	 0.04705 	 0.04070 	 ~...
   68 	    28 	 0.04771 	 0.04080 	 ~...
   33 	    29 	 0.04722 	 0.04099 	 ~...
   28 	    30 	 0.04719 	 0.04129 	 ~...
   11 	    31 	 0.04707 	 0.04130 	 ~...
   42 	    32 	 0.04738 	 0.04163 	 ~...
   51 	    33 	 0.04754 	 0.04165 	 ~...
   34 	    34 	 0.04722 	 0.04176 	 ~...
   72 	    35 	 0.04777 	 0.04224 	 ~...
   49 	    36 	 0.04752 	 0.04272 	 ~...
   17 	    37 	 0.04713 	 0.04276 	 ~...
   26 	    38 	 0.04716 	 0.04306 	 ~...
   58 	    39 	 0.04763 	 0.04338 	 ~...
   15 	    40 	 0.04709 	 0.04372 	 ~...
   44 	    41 	 0.04740 	 0.04373 	 ~...
   39 	    42 	 0.04730 	 0.04388 	 ~...
   37 	    43 	 0.04725 	 0.04410 	 ~...
   69 	    44 	 0.04774 	 0.04419 	 ~...
   50 	    45 	 0.04753 	 0.04420 	 ~...
   38 	    46 	 0.04730 	 0.04423 	 ~...
   29 	    47 	 0.04720 	 0.04476 	 ~...
    0 	    48 	 0.04686 	 0.04514 	 ~...
   30 	    49 	 0.04720 	 0.04551 	 ~...
   57 	    50 	 0.04759 	 0.04564 	 ~...
   32 	    51 	 0.04721 	 0.04617 	 ~...
   27 	    52 	 0.04718 	 0.04642 	 ~...
   10 	    53 	 0.04706 	 0.04687 	 ~...
   40 	    54 	 0.04732 	 0.04699 	 ~...
    7 	    55 	 0.04700 	 0.04706 	 ~...
   35 	    56 	 0.04722 	 0.04718 	 ~...
   71 	    57 	 0.04777 	 0.04727 	 ~...
   25 	    58 	 0.04716 	 0.04740 	 ~...
   13 	    59 	 0.04707 	 0.04744 	 ~...
   19 	    60 	 0.04713 	 0.04750 	 ~...
    1 	    61 	 0.04690 	 0.04758 	 ~...
   20 	    62 	 0.04714 	 0.04763 	 ~...
   64 	    63 	 0.04769 	 0.04824 	 ~...
   56 	    64 	 0.04759 	 0.04857 	 ~...
   36 	    65 	 0.04722 	 0.04879 	 ~...
   16 	    66 	 0.04711 	 0.04879 	 ~...
   31 	    67 	 0.04720 	 0.04904 	 ~...
   46 	    68 	 0.04743 	 0.04921 	 ~...
    5 	    69 	 0.04696 	 0.04928 	 ~...
   12 	    70 	 0.04707 	 0.04929 	 ~...
   23 	    71 	 0.04714 	 0.04949 	 ~...
   24 	    72 	 0.04715 	 0.04956 	 ~...
   45 	    73 	 0.04742 	 0.04987 	 ~...
   62 	    74 	 0.04764 	 0.05004 	 ~...
   52 	    75 	 0.04755 	 0.05023 	 ~...
   66 	    76 	 0.04771 	 0.05056 	 ~...
   59 	    77 	 0.04763 	 0.05108 	 ~...
   61 	    78 	 0.04763 	 0.05128 	 ~...
   22 	    79 	 0.04714 	 0.05129 	 ~...
    6 	    80 	 0.04697 	 0.05144 	 ~...
    3 	    81 	 0.04694 	 0.05146 	 ~...
   60 	    82 	 0.04763 	 0.05160 	 ~...
   41 	    83 	 0.04732 	 0.05189 	 ~...
   54 	    84 	 0.04756 	 0.05246 	 ~...
   65 	    85 	 0.04769 	 0.05275 	 ~...
   47 	    86 	 0.04747 	 0.05352 	 ~...
   55 	    87 	 0.04758 	 0.05355 	 ~...
   53 	    88 	 0.04756 	 0.05567 	 ~...
   21 	    89 	 0.04714 	 0.05977 	 ~...
  110 	    90 	 0.22990 	 0.18889 	 m..s
   98 	    91 	 0.20015 	 0.18959 	 ~...
   97 	    92 	 0.19969 	 0.19213 	 ~...
  109 	    93 	 0.22968 	 0.19872 	 m..s
   90 	    94 	 0.19936 	 0.20550 	 ~...
   99 	    95 	 0.20025 	 0.20694 	 ~...
   90 	    96 	 0.19936 	 0.20727 	 ~...
   90 	    97 	 0.19936 	 0.21693 	 ~...
   90 	    98 	 0.19936 	 0.21723 	 ~...
   90 	    99 	 0.19936 	 0.21940 	 ~...
  100 	   100 	 0.20037 	 0.21956 	 ~...
  104 	   101 	 0.21856 	 0.23290 	 ~...
   90 	   102 	 0.19936 	 0.23984 	 m..s
  101 	   103 	 0.20691 	 0.24107 	 m..s
  103 	   104 	 0.21629 	 0.24218 	 ~...
  105 	   105 	 0.22071 	 0.24307 	 ~...
   90 	   106 	 0.19936 	 0.25298 	 m..s
  102 	   107 	 0.20849 	 0.25327 	 m..s
  115 	   108 	 0.27273 	 0.27378 	 ~...
  108 	   109 	 0.22679 	 0.27425 	 m..s
  106 	   110 	 0.22121 	 0.27441 	 m..s
  113 	   111 	 0.24976 	 0.27737 	 ~...
  107 	   112 	 0.22236 	 0.28034 	 m..s
  112 	   113 	 0.23186 	 0.28353 	 m..s
  111 	   114 	 0.23064 	 0.29788 	 m..s
  117 	   115 	 0.28717 	 0.29922 	 ~...
  114 	   116 	 0.25118 	 0.31748 	 m..s
  116 	   117 	 0.27352 	 0.33485 	 m..s
  118 	   118 	 0.33146 	 0.39525 	 m..s
  119 	   119 	 0.34069 	 0.52223 	 MISS
  120 	   120 	 0.34735 	 0.53924 	 MISS
==========================================
r_mrr = 0.9735651016235352
r2_mrr = 0.9048687219619751
spearmanr_mrr@5 = 0.9152770638465881
spearmanr_mrr@10 = 0.9249640703201294
spearmanr_mrr@50 = 0.9750857353210449
spearmanr_mrr@100 = 0.9838709831237793
spearmanr_mrr@All = 0.9841724038124084
==========================================
test time: 0.58
Done Testing dataset UMLS
Testing model with dataset Kinships
Running eval on the test set
running batch: 0
rank avg (pred): 0.375 +- 0.363
mrr vals (pred, true): 0.253, 0.228

Evaluation for Kinships on the test set
==========================================
(Sorted by True MRR values)
i_pred 	 i_true 	 Pred MRR 	 True MRR 	 Change Flag
   71 	     0 	 0.04536 	 0.04713 	 ~...
   22 	     1 	 0.04043 	 0.04727 	 ~...
   47 	     2 	 0.04290 	 0.04763 	 ~...
   40 	     3 	 0.04222 	 0.04803 	 ~...
   30 	     4 	 0.04094 	 0.04830 	 ~...
    1 	     5 	 0.03957 	 0.04840 	 ~...
    4 	     6 	 0.03973 	 0.04863 	 ~...
    6 	     7 	 0.03983 	 0.04890 	 ~...
   45 	     8 	 0.04281 	 0.04927 	 ~...
   44 	     9 	 0.04271 	 0.04930 	 ~...
   58 	    10 	 0.04363 	 0.04948 	 ~...
   42 	    11 	 0.04258 	 0.04950 	 ~...
   46 	    12 	 0.04283 	 0.04954 	 ~...
   35 	    13 	 0.04137 	 0.04990 	 ~...
   61 	    14 	 0.04368 	 0.05021 	 ~...
    2 	    15 	 0.03965 	 0.05035 	 ~...
   55 	    16 	 0.04335 	 0.05050 	 ~...
   17 	    17 	 0.04016 	 0.05071 	 ~...
   53 	    18 	 0.04321 	 0.05076 	 ~...
   29 	    19 	 0.04087 	 0.05097 	 ~...
   31 	    20 	 0.04098 	 0.05105 	 ~...
   74 	    21 	 0.05648 	 0.05107 	 ~...
   28 	    22 	 0.04085 	 0.05112 	 ~...
   73 	    23 	 0.04594 	 0.05113 	 ~...
   18 	    24 	 0.04017 	 0.05127 	 ~...
   43 	    25 	 0.04269 	 0.05151 	 ~...
   33 	    26 	 0.04106 	 0.05154 	 ~...
   11 	    27 	 0.03999 	 0.05179 	 ~...
   26 	    28 	 0.04080 	 0.05186 	 ~...
   62 	    29 	 0.04374 	 0.05193 	 ~...
   48 	    30 	 0.04306 	 0.05211 	 ~...
   41 	    31 	 0.04253 	 0.05215 	 ~...
   65 	    32 	 0.04446 	 0.05219 	 ~...
   36 	    33 	 0.04140 	 0.05236 	 ~...
   27 	    34 	 0.04080 	 0.05312 	 ~...
   37 	    35 	 0.04208 	 0.05317 	 ~...
   51 	    36 	 0.04317 	 0.05317 	 ~...
   49 	    37 	 0.04307 	 0.05341 	 ~...
   56 	    38 	 0.04335 	 0.05350 	 ~...
   75 	    39 	 0.06133 	 0.05351 	 ~...
   15 	    40 	 0.04013 	 0.05358 	 ~...
   38 	    41 	 0.04209 	 0.05406 	 ~...
    5 	    42 	 0.03979 	 0.05428 	 ~...
    7 	    43 	 0.03991 	 0.05440 	 ~...
    8 	    44 	 0.03991 	 0.05481 	 ~...
   64 	    45 	 0.04434 	 0.05498 	 ~...
   25 	    46 	 0.04067 	 0.05510 	 ~...
   69 	    47 	 0.04489 	 0.05531 	 ~...
   34 	    48 	 0.04133 	 0.05575 	 ~...
   14 	    49 	 0.04007 	 0.05576 	 ~...
   19 	    50 	 0.04023 	 0.05587 	 ~...
   72 	    51 	 0.04545 	 0.05596 	 ~...
   59 	    52 	 0.04363 	 0.05638 	 ~...
   57 	    53 	 0.04357 	 0.05694 	 ~...
    3 	    54 	 0.03966 	 0.05696 	 ~...
   60 	    55 	 0.04367 	 0.05719 	 ~...
   20 	    56 	 0.04027 	 0.05723 	 ~...
   68 	    57 	 0.04467 	 0.05725 	 ~...
   70 	    58 	 0.04490 	 0.05733 	 ~...
   50 	    59 	 0.04313 	 0.05749 	 ~...
   12 	    60 	 0.03999 	 0.05787 	 ~...
   67 	    61 	 0.04453 	 0.05825 	 ~...
   24 	    62 	 0.04067 	 0.05868 	 ~...
   23 	    63 	 0.04048 	 0.05870 	 ~...
   52 	    64 	 0.04320 	 0.05874 	 ~...
   16 	    65 	 0.04016 	 0.05881 	 ~...
   66 	    66 	 0.04446 	 0.05882 	 ~...
   13 	    67 	 0.04000 	 0.05918 	 ~...
   10 	    68 	 0.03997 	 0.05969 	 ~...
   21 	    69 	 0.04040 	 0.05993 	 ~...
    0 	    70 	 0.03943 	 0.06014 	 ~...
    9 	    71 	 0.03992 	 0.06038 	 ~...
   39 	    72 	 0.04221 	 0.06049 	 ~...
   63 	    73 	 0.04427 	 0.06096 	 ~...
   32 	    74 	 0.04104 	 0.06158 	 ~...
   54 	    75 	 0.04334 	 0.06229 	 ~...
   76 	    76 	 0.21377 	 0.16198 	 m..s
   77 	    77 	 0.23575 	 0.18404 	 m..s
   81 	    78 	 0.25156 	 0.18970 	 m..s
   78 	    79 	 0.23889 	 0.19886 	 m..s
   82 	    80 	 0.25255 	 0.21213 	 m..s
   80 	    81 	 0.25074 	 0.21714 	 m..s
   79 	    82 	 0.24985 	 0.21822 	 m..s
   85 	    83 	 0.26805 	 0.21861 	 m..s
   84 	    84 	 0.25389 	 0.22784 	 ~...
   83 	    85 	 0.25312 	 0.22825 	 ~...
   86 	    86 	 0.29059 	 0.25404 	 m..s
   92 	    87 	 0.32632 	 0.26205 	 m..s
   91 	    88 	 0.32566 	 0.26840 	 m..s
   90 	    89 	 0.32520 	 0.27182 	 m..s
   93 	    90 	 0.32636 	 0.28071 	 m..s
  101 	    91 	 0.33702 	 0.28148 	 m..s
   93 	    92 	 0.32636 	 0.28774 	 m..s
   88 	    93 	 0.32500 	 0.29619 	 ~...
   93 	    94 	 0.32636 	 0.29634 	 m..s
  106 	    95 	 0.34420 	 0.29652 	 m..s
   93 	    96 	 0.32636 	 0.30510 	 ~...
  102 	    97 	 0.33848 	 0.30598 	 m..s
   93 	    98 	 0.32636 	 0.30754 	 ~...
  100 	    99 	 0.33229 	 0.30803 	 ~...
   89 	   100 	 0.32510 	 0.30884 	 ~...
  105 	   101 	 0.34290 	 0.31529 	 ~...
  104 	   102 	 0.34256 	 0.31655 	 ~...
   93 	   103 	 0.32636 	 0.32286 	 ~...
   87 	   104 	 0.31527 	 0.33122 	 ~...
   93 	   105 	 0.32636 	 0.34296 	 ~...
  107 	   106 	 0.34535 	 0.36221 	 ~...
  108 	   107 	 0.34920 	 0.36880 	 ~...
  103 	   108 	 0.33967 	 0.36975 	 m..s
  111 	   109 	 0.37533 	 0.37989 	 ~...
  110 	   110 	 0.37353 	 0.38991 	 ~...
  113 	   111 	 0.43285 	 0.40258 	 m..s
  114 	   112 	 0.44466 	 0.40967 	 m..s
  109 	   113 	 0.37211 	 0.41075 	 m..s
  112 	   114 	 0.39020 	 0.42112 	 m..s
  115 	   115 	 0.49069 	 0.47933 	 ~...
  116 	   116 	 0.49207 	 0.48000 	 ~...
  117 	   117 	 0.50018 	 0.50285 	 ~...
  119 	   118 	 0.57301 	 0.61365 	 m..s
  118 	   119 	 0.56523 	 0.61786 	 m..s
  120 	   120 	 0.58684 	 0.62288 	 m..s
==========================================
r_mrr = 0.9889978766441345
r2_mrr = 0.9741365313529968
spearmanr_mrr@5 = 0.9902940988540649
spearmanr_mrr@10 = 0.9629756808280945
spearmanr_mrr@50 = 0.9791558980941772
spearmanr_mrr@100 = 0.9896883964538574
spearmanr_mrr@All = 0.9907816648483276
==========================================
test time: 0.624
Done Testing dataset Kinships
Testing model with dataset CoDExSmall
Running eval on the test set
running batch: 0
rank avg (pred): 0.461 +- 0.344
mrr vals (pred, true): 0.051, 0.001

Evaluation for CoDExSmall on the test set
==========================================
(Sorted by True MRR values)
i_pred 	 i_true 	 Pred MRR 	 True MRR 	 Change Flag
   85 	     0 	 0.05487 	 0.00086 	 m..s
   82 	     1 	 0.05077 	 0.00089 	 m..s
   27 	     2 	 0.04906 	 0.00170 	 m..s
   83 	     3 	 0.05253 	 0.00174 	 m..s
   48 	     4 	 0.04929 	 0.00204 	 m..s
   49 	     5 	 0.04929 	 0.00240 	 m..s
   59 	     6 	 0.04934 	 0.00242 	 m..s
   55 	     7 	 0.04933 	 0.00242 	 m..s
   47 	     8 	 0.04924 	 0.00287 	 m..s
    8 	     9 	 0.04892 	 0.00289 	 m..s
   60 	    10 	 0.04934 	 0.00291 	 m..s
   19 	    11 	 0.04899 	 0.00292 	 m..s
   57 	    12 	 0.04933 	 0.00296 	 m..s
   53 	    13 	 0.04932 	 0.00310 	 m..s
   50 	    14 	 0.04931 	 0.00315 	 m..s
   18 	    15 	 0.04898 	 0.00316 	 m..s
   58 	    16 	 0.04934 	 0.00317 	 m..s
   29 	    17 	 0.04909 	 0.00325 	 m..s
    9 	    18 	 0.04896 	 0.00331 	 m..s
   46 	    19 	 0.04924 	 0.00331 	 m..s
   23 	    20 	 0.04901 	 0.00336 	 m..s
   24 	    21 	 0.04901 	 0.00337 	 m..s
   33 	    22 	 0.04913 	 0.00345 	 m..s
    1 	    23 	 0.04879 	 0.00345 	 m..s
   35 	    24 	 0.04916 	 0.00356 	 m..s
   63 	    25 	 0.04934 	 0.00360 	 m..s
   25 	    26 	 0.04901 	 0.00362 	 m..s
    5 	    27 	 0.04888 	 0.00362 	 m..s
   17 	    28 	 0.04898 	 0.00363 	 m..s
    7 	    29 	 0.04889 	 0.00363 	 m..s
   70 	    30 	 0.04936 	 0.00364 	 m..s
   62 	    31 	 0.04934 	 0.00368 	 m..s
   71 	    32 	 0.04940 	 0.00368 	 m..s
   16 	    33 	 0.04898 	 0.00374 	 m..s
   75 	    34 	 0.04969 	 0.00376 	 m..s
   52 	    35 	 0.04932 	 0.00376 	 m..s
   56 	    36 	 0.04933 	 0.00381 	 m..s
   40 	    37 	 0.04921 	 0.00381 	 m..s
   66 	    38 	 0.04936 	 0.00384 	 m..s
   61 	    39 	 0.04934 	 0.00389 	 m..s
   67 	    40 	 0.04936 	 0.00391 	 m..s
    0 	    41 	 0.04874 	 0.00394 	 m..s
   30 	    42 	 0.04910 	 0.00399 	 m..s
   54 	    43 	 0.04933 	 0.00400 	 m..s
   11 	    44 	 0.04897 	 0.00402 	 m..s
   21 	    45 	 0.04900 	 0.00404 	 m..s
   42 	    46 	 0.04922 	 0.00406 	 m..s
   43 	    47 	 0.04923 	 0.00409 	 m..s
   22 	    48 	 0.04900 	 0.00412 	 m..s
    4 	    49 	 0.04888 	 0.00413 	 m..s
   28 	    50 	 0.04909 	 0.00415 	 m..s
   10 	    51 	 0.04896 	 0.00415 	 m..s
   65 	    52 	 0.04935 	 0.00415 	 m..s
   73 	    53 	 0.04964 	 0.00415 	 m..s
   39 	    54 	 0.04920 	 0.00416 	 m..s
   74 	    55 	 0.04966 	 0.00418 	 m..s
   32 	    56 	 0.04912 	 0.00418 	 m..s
   64 	    57 	 0.04934 	 0.00420 	 m..s
    3 	    58 	 0.04888 	 0.00422 	 m..s
   37 	    59 	 0.04919 	 0.00424 	 m..s
   41 	    60 	 0.04921 	 0.00440 	 m..s
    2 	    61 	 0.04888 	 0.00454 	 m..s
   12 	    62 	 0.04897 	 0.00455 	 m..s
   34 	    63 	 0.04915 	 0.00459 	 m..s
   38 	    64 	 0.04919 	 0.00460 	 m..s
   72 	    65 	 0.04959 	 0.00461 	 m..s
   51 	    66 	 0.04932 	 0.00461 	 m..s
   15 	    67 	 0.04897 	 0.00467 	 m..s
   20 	    68 	 0.04899 	 0.00469 	 m..s
   31 	    69 	 0.04912 	 0.00470 	 m..s
   14 	    70 	 0.04897 	 0.00473 	 m..s
   44 	    71 	 0.04923 	 0.00477 	 m..s
   68 	    72 	 0.04936 	 0.00478 	 m..s
   36 	    73 	 0.04917 	 0.00485 	 m..s
   26 	    74 	 0.04901 	 0.00500 	 m..s
    6 	    75 	 0.04888 	 0.00501 	 m..s
   69 	    76 	 0.04936 	 0.00514 	 m..s
   45 	    77 	 0.04923 	 0.00551 	 m..s
   13 	    78 	 0.04897 	 0.00604 	 m..s
   77 	    79 	 0.05015 	 0.00680 	 m..s
   76 	    80 	 0.05006 	 0.00694 	 m..s
   80 	    81 	 0.05056 	 0.00739 	 m..s
   79 	    82 	 0.05052 	 0.00804 	 m..s
   78 	    83 	 0.05047 	 0.01152 	 m..s
   81 	    84 	 0.05064 	 0.01271 	 m..s
   86 	    85 	 0.05595 	 0.02050 	 m..s
   89 	    86 	 0.07275 	 0.02430 	 m..s
   84 	    87 	 0.05414 	 0.02863 	 ~...
   88 	    88 	 0.06063 	 0.02916 	 m..s
   87 	    89 	 0.05792 	 0.02920 	 ~...
   99 	    90 	 0.16991 	 0.12715 	 m..s
   90 	    91 	 0.15378 	 0.12799 	 ~...
  100 	    92 	 0.17089 	 0.13094 	 m..s
   90 	    93 	 0.15378 	 0.13140 	 ~...
   90 	    94 	 0.15378 	 0.13806 	 ~...
   90 	    95 	 0.15378 	 0.14041 	 ~...
   97 	    96 	 0.16388 	 0.17202 	 ~...
   98 	    97 	 0.16899 	 0.17271 	 ~...
   90 	    98 	 0.15378 	 0.17434 	 ~...
   90 	    99 	 0.15378 	 0.17792 	 ~...
  102 	   100 	 0.23547 	 0.18551 	 m..s
   90 	   101 	 0.15378 	 0.18924 	 m..s
  104 	   102 	 0.24151 	 0.19630 	 m..s
  106 	   103 	 0.24302 	 0.20171 	 m..s
  105 	   104 	 0.24230 	 0.21048 	 m..s
  101 	   105 	 0.23325 	 0.22857 	 ~...
  109 	   106 	 0.25325 	 0.22949 	 ~...
  115 	   107 	 0.27216 	 0.23928 	 m..s
  111 	   108 	 0.26417 	 0.24645 	 ~...
  116 	   109 	 0.27240 	 0.25269 	 ~...
  119 	   110 	 0.31590 	 0.25972 	 m..s
  103 	   111 	 0.23618 	 0.26879 	 m..s
  118 	   112 	 0.31290 	 0.27244 	 m..s
  113 	   113 	 0.26956 	 0.28454 	 ~...
  120 	   114 	 0.31972 	 0.29618 	 ~...
  107 	   115 	 0.24842 	 0.30562 	 m..s
  112 	   116 	 0.26490 	 0.31181 	 m..s
  114 	   117 	 0.27044 	 0.31362 	 m..s
  117 	   118 	 0.27426 	 0.31910 	 m..s
  110 	   119 	 0.25365 	 0.33494 	 m..s
  108 	   120 	 0.25287 	 0.34039 	 m..s
==========================================
r_mrr = 0.9785043597221375
r2_mrr = 0.8185217976570129
spearmanr_mrr@5 = 0.8500381112098694
spearmanr_mrr@10 = 0.8455164432525635
spearmanr_mrr@50 = 0.989733099937439
spearmanr_mrr@100 = 0.993941605091095
spearmanr_mrr@All = 0.9943310022354126
==========================================
test time: 0.596
Done Testing dataset CoDExSmall
Testing model with dataset DBpedia50
Running eval on the test set
running batch: 0
rank avg (pred): 0.463 +- 0.351
mrr vals (pred, true): 0.067, 0.002

Evaluation for DBpedia50 on the test set
==========================================
(Sorted by True MRR values)
i_pred 	 i_true 	 Pred MRR 	 True MRR 	 Change Flag
   39 	     0 	 0.04953 	 0.00014 	 m..s
   61 	     1 	 0.04964 	 0.00014 	 m..s
   24 	     2 	 0.04951 	 0.00014 	 m..s
   86 	     3 	 0.07470 	 0.00015 	 m..s
    6 	     4 	 0.04945 	 0.00016 	 m..s
    5 	     5 	 0.04944 	 0.00016 	 m..s
   27 	     6 	 0.04952 	 0.00017 	 m..s
   49 	     7 	 0.04955 	 0.00017 	 m..s
   66 	     8 	 0.04972 	 0.00018 	 m..s
   67 	     9 	 0.04972 	 0.00018 	 m..s
   57 	    10 	 0.04959 	 0.00018 	 m..s
    8 	    11 	 0.04945 	 0.00019 	 m..s
   45 	    12 	 0.04955 	 0.00019 	 m..s
   36 	    13 	 0.04952 	 0.00021 	 m..s
   38 	    14 	 0.04953 	 0.00021 	 m..s
   11 	    15 	 0.04947 	 0.00021 	 m..s
   14 	    16 	 0.04947 	 0.00021 	 m..s
    3 	    17 	 0.04944 	 0.00021 	 m..s
   35 	    18 	 0.04952 	 0.00021 	 m..s
   70 	    19 	 0.04974 	 0.00022 	 m..s
   12 	    20 	 0.04947 	 0.00022 	 m..s
   43 	    21 	 0.04955 	 0.00023 	 m..s
   37 	    22 	 0.04952 	 0.00023 	 m..s
   20 	    23 	 0.04950 	 0.00024 	 m..s
   42 	    24 	 0.04955 	 0.00024 	 m..s
   10 	    25 	 0.04947 	 0.00024 	 m..s
   50 	    26 	 0.04956 	 0.00024 	 m..s
   64 	    27 	 0.04970 	 0.00024 	 m..s
   71 	    28 	 0.04988 	 0.00024 	 m..s
   53 	    29 	 0.04956 	 0.00025 	 m..s
   31 	    30 	 0.04952 	 0.00025 	 m..s
   63 	    31 	 0.04970 	 0.00025 	 m..s
    7 	    32 	 0.04945 	 0.00026 	 m..s
   55 	    33 	 0.04956 	 0.00026 	 m..s
   18 	    34 	 0.04950 	 0.00027 	 m..s
    1 	    35 	 0.04942 	 0.00027 	 m..s
   69 	    36 	 0.04974 	 0.00028 	 m..s
   15 	    37 	 0.04948 	 0.00028 	 m..s
   41 	    38 	 0.04954 	 0.00028 	 m..s
   21 	    39 	 0.04951 	 0.00029 	 m..s
   60 	    40 	 0.04961 	 0.00029 	 m..s
   29 	    41 	 0.04952 	 0.00029 	 m..s
   51 	    42 	 0.04956 	 0.00030 	 m..s
    0 	    43 	 0.04941 	 0.00030 	 m..s
   46 	    44 	 0.04955 	 0.00030 	 m..s
   47 	    45 	 0.04955 	 0.00031 	 m..s
   13 	    46 	 0.04947 	 0.00031 	 m..s
   25 	    47 	 0.04951 	 0.00032 	 m..s
   33 	    48 	 0.04952 	 0.00032 	 m..s
   40 	    49 	 0.04953 	 0.00033 	 m..s
   34 	    50 	 0.04952 	 0.00034 	 m..s
    2 	    51 	 0.04944 	 0.00034 	 m..s
   75 	    52 	 0.05130 	 0.00034 	 m..s
    9 	    53 	 0.04947 	 0.00035 	 m..s
   65 	    54 	 0.04970 	 0.00036 	 m..s
   23 	    55 	 0.04951 	 0.00037 	 m..s
   26 	    56 	 0.04952 	 0.00037 	 m..s
   73 	    57 	 0.04993 	 0.00038 	 m..s
   16 	    58 	 0.04948 	 0.00038 	 m..s
   52 	    59 	 0.04956 	 0.00039 	 m..s
   48 	    60 	 0.04955 	 0.00039 	 m..s
   59 	    61 	 0.04961 	 0.00039 	 m..s
   44 	    62 	 0.04955 	 0.00039 	 m..s
   22 	    63 	 0.04951 	 0.00043 	 m..s
   68 	    64 	 0.04973 	 0.00043 	 m..s
   28 	    65 	 0.04952 	 0.00046 	 m..s
   19 	    66 	 0.04950 	 0.00049 	 m..s
   74 	    67 	 0.05065 	 0.00050 	 m..s
   17 	    68 	 0.04949 	 0.00052 	 m..s
   30 	    69 	 0.04952 	 0.00053 	 m..s
   32 	    70 	 0.04952 	 0.00055 	 m..s
   62 	    71 	 0.04964 	 0.00056 	 m..s
   58 	    72 	 0.04961 	 0.00057 	 m..s
   72 	    73 	 0.04992 	 0.00076 	 m..s
    4 	    74 	 0.04944 	 0.00079 	 m..s
   56 	    75 	 0.04957 	 0.00084 	 m..s
   54 	    76 	 0.04956 	 0.00129 	 m..s
   79 	    77 	 0.06697 	 0.00171 	 m..s
   82 	    78 	 0.07028 	 0.00789 	 m..s
   99 	    79 	 0.09386 	 0.04857 	 m..s
   77 	    80 	 0.06389 	 0.06447 	 ~...
   88 	    81 	 0.08305 	 0.07961 	 ~...
   88 	    82 	 0.08305 	 0.08371 	 ~...
   81 	    83 	 0.06899 	 0.08488 	 ~...
   88 	    84 	 0.08305 	 0.08803 	 ~...
   95 	    85 	 0.08900 	 0.08860 	 ~...
   85 	    86 	 0.07327 	 0.08867 	 ~...
  100 	    87 	 0.09439 	 0.09060 	 ~...
   88 	    88 	 0.08305 	 0.09126 	 ~...
   88 	    89 	 0.08305 	 0.09149 	 ~...
   88 	    90 	 0.08305 	 0.09180 	 ~...
   80 	    91 	 0.06773 	 0.09286 	 ~...
   78 	    92 	 0.06553 	 0.09363 	 ~...
   98 	    93 	 0.09330 	 0.09460 	 ~...
   76 	    94 	 0.06382 	 0.09532 	 m..s
  105 	    95 	 0.17477 	 0.09535 	 m..s
  107 	    96 	 0.17793 	 0.09764 	 m..s
   83 	    97 	 0.07124 	 0.10902 	 m..s
  101 	    98 	 0.10638 	 0.12319 	 ~...
   84 	    99 	 0.07326 	 0.13164 	 m..s
   96 	   100 	 0.08955 	 0.13674 	 m..s
  102 	   101 	 0.16414 	 0.13680 	 ~...
   88 	   102 	 0.08305 	 0.13810 	 m..s
   87 	   103 	 0.07944 	 0.14653 	 m..s
   97 	   104 	 0.09064 	 0.15318 	 m..s
  111 	   105 	 0.19461 	 0.16378 	 m..s
  103 	   106 	 0.16491 	 0.16586 	 ~...
  104 	   107 	 0.16693 	 0.18204 	 ~...
  106 	   108 	 0.17501 	 0.18503 	 ~...
  109 	   109 	 0.18040 	 0.21574 	 m..s
  110 	   110 	 0.18155 	 0.21666 	 m..s
  108 	   111 	 0.18027 	 0.22657 	 m..s
  112 	   112 	 0.21047 	 0.26914 	 m..s
  117 	   113 	 0.25208 	 0.28706 	 m..s
  115 	   114 	 0.25151 	 0.30486 	 m..s
  116 	   115 	 0.25161 	 0.31033 	 m..s
  113 	   116 	 0.21151 	 0.31527 	 MISS
  120 	   117 	 0.30220 	 0.31960 	 ~...
  114 	   118 	 0.21159 	 0.33534 	 MISS
  118 	   119 	 0.28268 	 0.34767 	 m..s
  119 	   120 	 0.29240 	 0.38203 	 m..s
==========================================
r_mrr = 0.9443128705024719
r2_mrr = 0.730882465839386
spearmanr_mrr@5 = 0.9163690209388733
spearmanr_mrr@10 = 0.920735239982605
spearmanr_mrr@50 = 0.9630383849143982
spearmanr_mrr@100 = 0.9723854660987854
spearmanr_mrr@All = 0.9737160205841064
==========================================
test time: 0.626
Done Testing dataset DBpedia50
Testing model with dataset OpenEA
Running eval on the test set
running batch: 0
rank avg (pred): 0.489 +- 0.363
mrr vals (pred, true): 0.060, 0.002

Evaluation for OpenEA on the test set
==========================================
(Sorted by True MRR values)
i_pred 	 i_true 	 Pred MRR 	 True MRR 	 Change Flag
   96 	     0 	 0.06837 	 0.00031 	 m..s
    7 	     1 	 0.05041 	 0.00045 	 m..s
    2 	     2 	 0.05033 	 0.00047 	 m..s
   68 	     3 	 0.05178 	 0.00051 	 m..s
   59 	     4 	 0.05126 	 0.00052 	 m..s
   57 	     5 	 0.05119 	 0.00053 	 m..s
   61 	     6 	 0.05140 	 0.00053 	 m..s
   54 	     7 	 0.05103 	 0.00055 	 m..s
   14 	     8 	 0.05054 	 0.00055 	 m..s
   31 	     9 	 0.05081 	 0.00056 	 m..s
    3 	    10 	 0.05033 	 0.00056 	 m..s
   42 	    11 	 0.05094 	 0.00057 	 m..s
   50 	    12 	 0.05099 	 0.00057 	 m..s
   45 	    13 	 0.05096 	 0.00057 	 m..s
   32 	    14 	 0.05081 	 0.00057 	 m..s
   41 	    15 	 0.05090 	 0.00058 	 m..s
    9 	    16 	 0.05051 	 0.00059 	 m..s
   75 	    17 	 0.05269 	 0.00059 	 m..s
   52 	    18 	 0.05101 	 0.00060 	 m..s
   39 	    19 	 0.05084 	 0.00060 	 m..s
   72 	    20 	 0.05245 	 0.00061 	 m..s
   70 	    21 	 0.05182 	 0.00064 	 m..s
   44 	    22 	 0.05095 	 0.00068 	 m..s
   71 	    23 	 0.05183 	 0.00069 	 m..s
   28 	    24 	 0.05075 	 0.00069 	 m..s
   13 	    25 	 0.05053 	 0.00070 	 m..s
   40 	    26 	 0.05088 	 0.00071 	 m..s
   22 	    27 	 0.05073 	 0.00072 	 m..s
   18 	    28 	 0.05062 	 0.00073 	 m..s
   62 	    29 	 0.05144 	 0.00073 	 m..s
   56 	    30 	 0.05105 	 0.00075 	 m..s
   38 	    31 	 0.05084 	 0.00076 	 m..s
   33 	    32 	 0.05081 	 0.00076 	 m..s
   60 	    33 	 0.05129 	 0.00076 	 m..s
   26 	    34 	 0.05074 	 0.00077 	 m..s
   29 	    35 	 0.05077 	 0.00078 	 m..s
   37 	    36 	 0.05082 	 0.00078 	 m..s
   27 	    37 	 0.05075 	 0.00080 	 m..s
   11 	    38 	 0.05053 	 0.00081 	 m..s
   49 	    39 	 0.05098 	 0.00081 	 m..s
   23 	    40 	 0.05073 	 0.00087 	 m..s
    5 	    41 	 0.05034 	 0.00088 	 m..s
   34 	    42 	 0.05082 	 0.00091 	 m..s
    6 	    43 	 0.05040 	 0.00092 	 m..s
   55 	    44 	 0.05103 	 0.00101 	 m..s
   48 	    45 	 0.05098 	 0.00103 	 m..s
   74 	    46 	 0.05263 	 0.00104 	 m..s
   35 	    47 	 0.05082 	 0.00106 	 m..s
   25 	    48 	 0.05074 	 0.00108 	 m..s
   20 	    49 	 0.05071 	 0.00112 	 m..s
    8 	    50 	 0.05041 	 0.00115 	 m..s
   16 	    51 	 0.05056 	 0.00116 	 m..s
   15 	    52 	 0.05055 	 0.00116 	 m..s
   12 	    53 	 0.05053 	 0.00118 	 m..s
   36 	    54 	 0.05082 	 0.00120 	 m..s
   63 	    55 	 0.05167 	 0.00122 	 m..s
   10 	    56 	 0.05052 	 0.00123 	 m..s
   53 	    57 	 0.05101 	 0.00133 	 m..s
   24 	    58 	 0.05074 	 0.00136 	 m..s
   51 	    59 	 0.05100 	 0.00137 	 m..s
   43 	    60 	 0.05094 	 0.00139 	 m..s
    1 	    61 	 0.05024 	 0.00142 	 m..s
   47 	    62 	 0.05097 	 0.00142 	 m..s
   67 	    63 	 0.05176 	 0.00143 	 m..s
   64 	    64 	 0.05168 	 0.00146 	 m..s
   21 	    65 	 0.05072 	 0.00153 	 m..s
   66 	    66 	 0.05176 	 0.00156 	 m..s
   17 	    67 	 0.05060 	 0.00161 	 m..s
   30 	    68 	 0.05079 	 0.00170 	 m..s
    4 	    69 	 0.05033 	 0.00186 	 m..s
    0 	    70 	 0.05012 	 0.00194 	 m..s
   69 	    71 	 0.05179 	 0.00195 	 m..s
   73 	    72 	 0.05256 	 0.00196 	 m..s
   46 	    73 	 0.05096 	 0.00199 	 m..s
   65 	    74 	 0.05172 	 0.00200 	 m..s
   19 	    75 	 0.05071 	 0.00200 	 m..s
   58 	    76 	 0.05126 	 0.00224 	 m..s
   90 	    77 	 0.05955 	 0.00249 	 m..s
   92 	    78 	 0.06259 	 0.00459 	 m..s
   79 	    79 	 0.05675 	 0.04959 	 ~...
   82 	    80 	 0.05681 	 0.05253 	 ~...
   83 	    81 	 0.05748 	 0.06381 	 ~...
   83 	    82 	 0.05748 	 0.07113 	 ~...
   83 	    83 	 0.05748 	 0.07360 	 ~...
   81 	    84 	 0.05679 	 0.07464 	 ~...
   99 	    85 	 0.07092 	 0.07469 	 ~...
   91 	    86 	 0.06225 	 0.07542 	 ~...
   83 	    87 	 0.05748 	 0.07636 	 ~...
   80 	    88 	 0.05675 	 0.07648 	 ~...
   93 	    89 	 0.06447 	 0.07650 	 ~...
   78 	    90 	 0.05666 	 0.07667 	 ~...
   83 	    91 	 0.05748 	 0.07719 	 ~...
   77 	    92 	 0.05660 	 0.07971 	 ~...
  106 	    93 	 0.17068 	 0.08036 	 m..s
   95 	    94 	 0.06536 	 0.08403 	 ~...
   94 	    95 	 0.06489 	 0.08523 	 ~...
   83 	    96 	 0.05748 	 0.08922 	 m..s
   83 	    97 	 0.05748 	 0.08956 	 m..s
  101 	    98 	 0.10138 	 0.09360 	 ~...
  100 	    99 	 0.07839 	 0.09838 	 ~...
  105 	   100 	 0.16654 	 0.10039 	 m..s
  103 	   101 	 0.16158 	 0.11871 	 m..s
   98 	   102 	 0.07086 	 0.12857 	 m..s
  104 	   103 	 0.16167 	 0.12860 	 m..s
  111 	   104 	 0.18778 	 0.13637 	 m..s
  102 	   105 	 0.16036 	 0.13818 	 ~...
  110 	   106 	 0.17982 	 0.17068 	 ~...
   76 	   107 	 0.05660 	 0.17901 	 MISS
  107 	   108 	 0.17494 	 0.18394 	 ~...
  109 	   109 	 0.17644 	 0.18588 	 ~...
  108 	   110 	 0.17500 	 0.18649 	 ~...
  114 	   111 	 0.21069 	 0.21233 	 ~...
  117 	   112 	 0.25272 	 0.21589 	 m..s
   97 	   113 	 0.07061 	 0.22307 	 MISS
  116 	   114 	 0.25079 	 0.27717 	 ~...
  115 	   115 	 0.25052 	 0.28122 	 m..s
  112 	   116 	 0.21064 	 0.28885 	 m..s
  113 	   117 	 0.21069 	 0.29363 	 m..s
  118 	   118 	 0.27894 	 0.31774 	 m..s
  119 	   119 	 0.28217 	 0.34668 	 m..s
  120 	   120 	 0.28500 	 0.34919 	 m..s
==========================================
r_mrr = 0.9021684527397156
r2_mrr = 0.6670047044754028
spearmanr_mrr@5 = 0.9438341856002808
spearmanr_mrr@10 = 0.9364438652992249
spearmanr_mrr@50 = 0.9552798271179199
spearmanr_mrr@100 = 0.954671323299408
spearmanr_mrr@All = 0.9557948708534241
==========================================
test time: 0.781
Done Testing dataset OpenEA
total time taken: 3474.4074804782867
training time taken: 3409.938891649246
TWIG out ;))
