loading NN
done loading NN
loading dataset
training TWIG with:
dataset_to_run_ids
{'DBpedia50': ['2.1', '2.2', '2.3', '2.4'], 'UMLS': ['2.1', '2.2', '2.3', '2.4'], 'CoDExSmall': ['2.1', '2.2', '2.3', '2.4'], 'OpenEA': ['2.1', '2.2', '2.3', '2.4'], 'Countries': ['2.1', '2.2', '2.3', '2.4'], 'Nations': ['2.1', '2.2', '2.3', '2.4'], 'Kinships': ['2.1', '2.2', '2.3', '2.4']}

num_exps_to_select
122

Loading data for UMLS
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
Loading the saved dataset...done
block_randomisation_tensor
[1123, 1182, 236, 701, 936, 689, 585, 593, 713, 482, 116, 852, 257, 60, 122, 63, 487, 757, 913, 805, 591, 935, 271, 302, 446, 448, 514, 728, 1120, 437, 263, 830, 1196, 235, 910, 436, 980, 208, 698, 464, 784, 991, 285, 579, 98, 653, 727, 883, 876, 874, 549, 649, 930, 1002, 650, 524, 253, 647, 798, 721, 127, 372, 646, 346, 1136, 636, 1195, 843, 1102, 258, 515, 543, 16, 242, 343, 369, 481, 64, 173, 245, 791, 528, 85, 71, 162, 862, 748, 512, 990, 452, 17, 612, 614, 617, 278, 1103, 897, 77, 501, 170, 786, 982, 199, 220, 19, 620, 775, 405, 872, 422, 342, 81, 333, 810, 750, 832, 616, 128, 572, 960, 570, 478, 658, 696, 1032, 191, 909, 321, 860, 718, 38, 416, 824, 552, 133, 212, 404, 341, 746, 10, 510, 541, 509, 957, 968, 866, 943, 826, 704, 294, 351, 70, 12, 508, 622, 742, 1192, 204, 751, 1059, 542, 37, 787, 630, 1075, 314, 624, 159, 361, 1005, 1040, 604, 625, 733, 554, 1105, 45, 965, 837, 950, 705, 188, 83, 638, 665, 11, 375, 958, 419, 1131, 730, 1106, 929, 398, 1093, 927, 513, 296, 894, 467, 389, 1021, 551, 1162, 503, 335, 1065, 580, 1077, 865, 592, 1135, 590, 424, 868, 477, 1076, 328, 884, 539, 377, 1042, 368, 1079, 104, 20, 193, 76, 1138, 632, 110, 438, 229, 898, 425, 226, 1188, 350, 1152, 318, 135, 765, 1139, 295, 719, 972, 948, 1114, 1149, 90, 256, 46, 740, 79, 217, 86, 62, 708, 430, 451, 287, 1147, 816, 922, 800, 164, 564, 613, 1190, 688, 568, 657, 557, 578, 663, 995, 352, 1133, 50, 556, 1029, 15, 399, 339, 427, 233, 259, 1036, 219, 367, 681, 1056, 88, 360, 492, 941, 998, 1044, 1052, 1084, 869, 772, 118, 1010, 1183, 945, 724, 345, 202, 167, 240, 873, 732, 629, 384, 223, 137, 639, 91, 870, 228, 29, 690, 900, 734, 99, 589, 35, 838, 576, 396, 763, 550, 1187, 69, 246, 959, 108, 1058, 970, 472, 961, 546, 985, 834, 888, 423, 174, 1082, 363, 992, 911, 184, 687, 488, 306, 186, 215, 139, 216, 799, 260, 1001, 1026, 1030, 937, 1097, 662, 270, 736, 338, 445, 652, 767, 807, 93, 916, 966, 731, 737, 582, 1007, 1046, 49, 468, 899, 631, 567, 856, 675, 454, 1101, 379, 1043, 923, 598, 993, 659, 1022, 21, 412, 606, 849, 879, 463, 210, 587, 1041, 33, 132, 274, 386, 1205, 686, 1006, 373, 917, 712, 1098, 818, 893, 753, 359, 51, 22, 490, 420, 23, 180, 252, 288, 605, 666, 555, 634, 886, 931, 670, 1031, 59, 1094, 42, 413, 1064, 878, 449, 759, 835, 565, 1206, 1038, 1184, 13, 205, 1048, 421, 476, 1080, 1054, 148, 364, 232, 796, 8, 298, 1169, 654, 254, 1129, 710, 536, 75, 147, 1118, 813, 1127, 234, 1155, 169, 707, 516, 433, 1143, 789, 48, 54, 322, 569, 5, 1203, 814, 87, 973, 563, 889, 519, 470, 165, 788, 680, 395, 547, 484, 812, 722, 926, 752, 34, 151, 279, 538, 540, 303, 206, 315, 534, 309, 231, 1156, 1153, 642, 725, 525, 907, 269, 439, 130, 597, 100, 871, 244, 1099, 310, 1057, 779, 833, 983, 955, 967, 443, 615, 1116, 1112, 1167, 963, 289, 175, 562, 474, 717, 1137, 25, 739, 176, 1028, 428, 601, 431, 720, 768, 121, 123, 1174, 1016, 89, 846, 273, 854, 1141, 460, 370, 1207, 891, 134, 280, 72, 627, 192, 989, 1066, 344, 103, 155, 371, 677, 249, 1119, 949, 697, 928, 106, 4, 197, 803, 55, 144, 817, 1121, 247, 1019, 1117, 429, 758, 559, 24, 952, 656, 264, 475, 655, 700, 880, 848, 857, 896, 378, 1090, 773, 633, 92, 827, 1208, 157, 669, 744, 334, 644, 1067, 575, 1091, 101, 1168, 842, 904, 455, 706, 156, 479, 469, 517, 610, 586, 699, 977, 115, 1, 1089, 493, 938, 1191, 994, 1211, 839, 924, 672, 491, 1018, 673, 711, 635, 895, 1015, 864, 129, 932, 331, 2, 65, 500, 453, 535, 385, 362, 1171, 912, 693, 96, 447, 112, 138, 218, 415, 1145, 523, 1008, 691, 465, 671, 498, 1177, 1214, 1113, 920, 505, 213, 347, 1061, 828, 529, 1100, 595, 714, 942, 109, 411, 282, 1148, 1037, 119, 14, 885, 577, 766, 141, 195, 861, 9, 804, 520, 623, 976, 694, 1068, 47, 1176, 561, 329, 185, 36, 152, 97, 573, 518, 105, 1062, 1166, 214, 166, 458, 626, 919, 381, 771, 1178, 1035, 299, 684, 1146, 1049, 221, 440, 1000, 1108, 532, 978, 153, 1163, 667, 594, 376, 327, 863, 26, 243, 1053, 969, 297, 820, 3, 678, 553, 1201, 301, 1151, 125, 390, 506, 58, 1071, 822, 1200, 794, 250, 142, 847, 1150, 178, 267, 637, 57, 581, 325, 1050, 194, 1173, 145, 641, 971, 915, 284, 311, 268, 102, 954, 1157, 1154, 628, 435, 382, 584, 27, 1078, 531, 406, 560, 544, 44, 84, 312, 337, 988, 1074, 383, 480, 126, 881, 790, 984, 1096, 1069, 651, 483, 40, 417, 761, 770, 336, 78, 224, 981, 607, 357, 735, 332, 921, 823, 340, 120, 1063, 313, 851, 286, 237, 1027, 729, 802, 808, 374, 1193, 1070, 326, 815, 1213, 154, 131, 1180, 608, 683, 1011, 304, 940, 901, 1210, 113, 611, 182, 1140, 1023, 905, 877, 434, 177, 1017, 290, 566, 366, 600, 819, 56, 902, 522, 979, 1009, 251, 0, 1107, 319, 825, 1083, 887, 853, 908, 307, 408, 892, 292, 1087, 32, 407, 496, 462, 1020, 227, 769, 324, 136, 1081, 320, 365, 709, 875, 316, 850, 450, 203, 1033, 776, 1109, 276, 939, 1144, 841, 1045, 457, 783, 94, 1039, 140, 277, 951, 209, 1199, 1111, 402, 356, 355, 619, 1110, 1186, 73, 1051, 934, 68, 387, 486, 533, 781, 444, 161, 947, 890, 858, 1128, 225, 741, 867, 596, 530, 602, 52, 836, 255, 1025, 583, 30, 1142, 1165, 358, 466, 146, 1122, 181, 588, 238, 442, 548, 603, 403, 41, 1134, 418, 6, 695, 964, 281, 388, 1185, 640, 760, 609, 330, 1158, 664, 305, 400, 248, 764, 394, 348, 262, 738, 674, 1164, 409, 53, 149, 1179, 801, 953, 643, 743, 944, 397, 114, 774, 1125, 1003, 117, 914, 39, 261, 222, 1132, 61, 1004, 521, 986, 537, 160, 1204, 1088, 1198, 168, 685, 882, 1175, 1172, 283, 95, 660, 903, 527, 755, 473, 163, 1115, 855, 574, 1024, 999, 1181, 456, 906, 275, 43, 1085, 504, 777, 1086, 198, 571, 780, 401, 143, 239, 1126, 111, 996, 1073, 207, 545, 747, 1160, 300, 809, 485, 497, 67, 183, 291, 745, 1072, 230, 80, 426, 754, 489, 1159, 495, 317, 459, 441, 308, 1161, 511, 974, 845, 676, 795, 1212, 526, 679, 661, 956, 150, 962, 1130, 471, 1197, 1092, 723, 494, 1104, 201, 1170, 31, 645, 189, 821, 1194, 187, 933, 172, 997, 782, 618, 749, 1013, 558, 797, 1209, 621, 716, 682, 507, 702, 179, 171, 859, 266, 7, 82, 987, 918, 715, 353, 66, 158, 391, 190, 432, 502, 461, 1034, 811, 293, 648, 844, 499, 74, 354, 1202, 762, 975, 1012, 265, 124, 946, 196, 28, 200, 726, 107, 1055, 18, 1189, 1047, 668, 703, 241, 392, 1060, 806, 692, 1124, 785, 925, 1014, 323, 1095, 272, 792, 831, 829, 778, 414, 380, 211, 840, 599, 410, 349, 793, 756, 393]

UMLS
2.1
2.2
2.3
2.4
training run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
training_data_x shape --> torch.Size([5701088, 33])
training_data_y shape --> torch.Size([5701088])
testing run IDs dict_keys(['2.1', '2.2', '2.3', '2.4'])
testing_data_x shape --> torch.Size([636352, 33])
testing_data_y shape --> torch.Size([636352])
configuring batches; using training batch size 1304
configuring batches; using testing batch size 1304
done loading dataset
running training and eval
NeuralNetwork_HPs_v3(
  (linear_struct_1): Linear(in_features=23, out_features=10, bias=True)
  (relu_1): ReLU()
  (linear_struct_2): Linear(in_features=10, out_features=10, bias=True)
  (relu_2): ReLU()
  (linear_hps_1): Linear(in_features=9, out_features=6, bias=True)
  (relu_3): ReLU()
  (linear_integrate_1): Linear(in_features=16, out_features=8, bias=True)
  (relu_4): ReLU()
  (linear_final): Linear(in_features=8, out_features=1, bias=True)
  (sigmoid_final): Sigmoid()
)
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for UMLS
IMPORTANT WARNING :: all dataloaders should have a multiple of 1215 batches, but I calculated {num_batches} for {dataset_name}. THIS IS ONLY VALID IF YOU ARE USING THE "HYP" TESTING MODE. If you are not, this is a critical error and means that data was not loaded properly.
validated training data for UMLS
REC: Training with epochs in stages 1: 5 and 2: 10
Epoch 1 -- batch 0 / 4372 mrrl: 0.0; urll: 2.087156190100359e-06; 
	rank: pred, true, means tensor(0.4210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0.0111, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0174, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 8.103748427856772e-07; 
	rank: pred, true, means tensor(0.4440, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0.0165, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 8.37196978409338e-07; 
	rank: pred, true, means tensor(0.4428, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0.0031, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.1662642691590008e-06; 
	rank: pred, true, means tensor(0.4352, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0.0022, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0169, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 9.357929684483679e-07; 
	rank: pred, true, means tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0.0022, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 6.340444542729529e-07; 
	rank: pred, true, means tensor(0.1433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0.0036, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.0495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 8.327265845764487e-07; 
	rank: pred, true, means tensor(0.4496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0.0019, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 4.912416216029669e-07; 
	rank: pred, true, means tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0.0018, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 8.804103117654449e-07; 
	rank: pred, true, means tensor(0.4390, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0.0008, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 0.0; urll: 6.238619789655786e-07; 
	rank: pred, true, means tensor(0.4570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0.0005, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 7.311503509299655e-07; 
	rank: pred, true, means tensor(0.4382, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 8.307397934004257e-07; 
	rank: pred, true, means tensor(0.4426, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.0756155006674817e-06; 
	rank: pred, true, means tensor(0.4375, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 9.559095133226947e-07; 
	rank: pred, true, means tensor(0.4432, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 5.051493872088031e-07; 
	rank: pred, true, means tensor(0.1468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.659197081011371e-07; 
	rank: pred, true, means tensor(0.4457, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.1563301995920483e-06; 
	rank: pred, true, means tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(6.8371e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 9.782612551134662e-07; 
	rank: pred, true, means tensor(0.4356, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(9.1555e-06, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 0.0; urll: 6.102025622567453e-07; 
	rank: pred, true, means tensor(0.4589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(4.6848e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 7.842978106964438e-07; 
	rank: pred, true, means tensor(0.4423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 8.235375617005047e-07; 
	rank: pred, true, means tensor(0.4423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.0502835721126758e-06; 
	rank: pred, true, means tensor(0.4381, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 1.0619561408020672e-06; 
	rank: pred, true, means tensor(0.4467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(3.6015e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 7.602076266266522e-07; 
	rank: pred, true, means tensor(0.1403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(3.6857e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.0505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.388492804238922e-07; 
	rank: pred, true, means tensor(0.4433, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 7.830560662114294e-07; 
	rank: pred, true, means tensor(0.5564, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(2.0257e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 9.531776754556631e-07; 
	rank: pred, true, means tensor(0.4365, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 0.0; urll: 6.206333864611224e-07; 
	rank: pred, true, means tensor(0.4576, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(2.0798e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 8.421640131928143e-07; 
	rank: pred, true, means tensor(0.4454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 8.210540158870572e-07; 
	rank: pred, true, means tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.056740757121588e-06; 
	rank: pred, true, means tensor(0.4379, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 9.08722540771123e-07; 
	rank: pred, true, means tensor(0.4417, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(2.0259e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 6.243586767595843e-07; 
	rank: pred, true, means tensor(0.1436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(4.2855e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.0494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.326404443119827e-07; 
	rank: pred, true, means tensor(0.4423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 5.600353460977203e-07; 
	rank: pred, true, means tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(2.1095e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0131, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 9.564062111167004e-07; 
	rank: pred, true, means tensor(0.4363, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 0.0; urll: 6.576379405487387e-07; 
	rank: pred, true, means tensor(0.4541, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(1.5464e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0162, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0; urll: 7.785857292219589e-07; 
	rank: pred, true, means tensor(0.4422, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.0; urll: 8.588036166656821e-07; 
	rank: pred, true, means tensor(0.4438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0; urll: 1.0890265684793121e-06; 
	rank: pred, true, means tensor(0.4371, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0; urll: 9.618700005376013e-07; 
	rank: pred, true, means tensor(0.4436, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(1.5928e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0165, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0; urll: 7.388492804238922e-07; 
	rank: pred, true, means tensor(0.1408, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(4.3141e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.0503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0; urll: 7.306536531359598e-07; 
	rank: pred, true, means tensor(0.4420, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0; urll: 1.5596549474139465e-07; 
	rank: pred, true, means tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(5.4225e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0; urll: 9.44733642427309e-07; 
	rank: pred, true, means tensor(0.4368, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Saving checkpoint at [1] epoch 5
Done Training (dist)!
Epoch 1 -- batch 0 / 4372 mrrl: 0.0036007468588650227; urll: 6.126861080701929e-07; 
	rank: pred, true, means tensor(0.4581, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(1.4981e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0009776151273399591; urll: 4.780516246682964e-05; 
	rank: pred, true, means tensor(0.1996, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0.0003, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0360, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.005653121042996645; urll: 1.6785910702310503e-05; 
	rank: pred, true, means tensor(0.2924, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0249, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00017877051504910924; urll: 8.536379027646035e-05; 
	rank: pred, true, means tensor(0.1475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0.0002, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.005103275761939585; urll: 2.829060031217523e-05; 
	rank: pred, true, means tensor(0.2491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0009115479042520747; urll: 1.8251936126034707e-05; 
	rank: pred, true, means tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(2.2726e-06, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2340, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.0002792951636365615; urll: 6.971210677875206e-05; 
	rank: pred, true, means tensor(0.1570, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(1.3777e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0454, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 3.612975206124247e-05; urll: 5.6658936955500394e-05; 
	rank: pred, true, means tensor(0.3296, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0.0003, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 0.0003834454037132673; urll: 6.476144335465506e-05; 
	rank: pred, true, means tensor(0.1826, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0393, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 2 -- batch 0 / 4372 mrrl: 0.0004007849929621443; urll: 7.371008541667834e-05; 
	rank: pred, true, means tensor(0.1731, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0413, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 3.961758920922875e-06; urll: 6.654958269791678e-05; 
	rank: pred, true, means tensor(0.1573, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(1.1869e-05, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 0.00014543816178047564; urll: 6.392623618012294e-05; 
	rank: pred, true, means tensor(0.1589, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0448, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 3.85337170882849e-05; urll: 8.123766019707546e-05; 
	rank: pred, true, means tensor(0.1552, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0459, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0002807468445098493; urll: 6.620387284783646e-05; 
	rank: pred, true, means tensor(0.1535, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0019389361841604114; urll: 1.840119693952147e-05; 
	rank: pred, true, means tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(2.0626e-06, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2383, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 9.694977052276954e-05; urll: 7.348036160692573e-05; 
	rank: pred, true, means tensor(0.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 8.448984090136946e-07; urll: 4.138574149692431e-05; 
	rank: pred, true, means tensor(0.3666, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0.0004, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0199, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 4.205987806926714e-05; urll: 8.14137383713387e-05; 
	rank: pred, true, means tensor(0.1496, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 3 -- batch 0 / 4372 mrrl: 0.001670555939199403; urll: 8.68884235387668e-05; 
	rank: pred, true, means tensor(0.1482, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 6.37928405922139e-05; urll: 7.180670945672318e-05; 
	rank: pred, true, means tensor(0.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 1.0857348797799204e-05; urll: 6.856869003968313e-05; 
	rank: pred, true, means tensor(0.1493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00012394024452078156; urll: 8.410563168581575e-05; 
	rank: pred, true, means tensor(0.1498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00020087798475287855; urll: 6.755292997695506e-05; 
	rank: pred, true, means tensor(0.1507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0073198729660362005; urll: 1.8827618987415917e-05; 
	rank: pred, true, means tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(1.4520e-07, device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 0.00010449258297740016; urll: 7.328068750211969e-05; 
	rank: pred, true, means tensor(0.1499, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 1.9743600887522916e-06; urll: 4.659270416595973e-05; 
	rank: pred, true, means tensor(0.3533, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 1.7986512830248103e-05; urll: 8.014912600629032e-05; 
	rank: pred, true, means tensor(0.1520, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0468, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 4 -- batch 0 / 4372 mrrl: 0.0016014452558010817; urll: 8.639792940812185e-05; 
	rank: pred, true, means tensor(0.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 5.781189429399092e-05; urll: 7.161349640227854e-05; 
	rank: pred, true, means tensor(0.1470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 1.6847147890075576e-05; urll: 6.815965025452897e-05; 
	rank: pred, true, means tensor(0.1501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00011482045010779984; urll: 8.386796253034845e-05; 
	rank: pred, true, means tensor(0.1503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00020692692487500608; urll: 6.744291022187099e-05; 
	rank: pred, true, means tensor(0.1509, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.0034976424649357796; urll: 1.8561135220807046e-05; 
	rank: pred, true, means tensor(0.0232, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2431, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 8.971583156380802e-05; urll: 7.367407670244575e-05; 
	rank: pred, true, means tensor(0.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 2.8585568543348927e-05; urll: 3.135254155495204e-05; 
	rank: pred, true, means tensor(0.3948, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 3.3983444609475555e-05; urll: 8.104865992208943e-05; 
	rank: pred, true, means tensor(0.1503, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 5 -- batch 0 / 4372 mrrl: 0.001606182922841981; urll: 8.643369073979557e-05; 
	rank: pred, true, means tensor(0.1491, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0477, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 5.482751021190779e-05; urll: 7.151639147195965e-05; 
	rank: pred, true, means tensor(0.1472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 1.6999804302031407e-05; urll: 6.814723747083917e-05; 
	rank: pred, true, means tensor(0.1501, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0474, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00010018469765782356; urll: 8.346066169906408e-05; 
	rank: pred, true, means tensor(0.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00022293019355856813; urll: 6.715903873555362e-05; 
	rank: pred, true, means tensor(0.1515, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.004984352854080498; urll: 1.8678358173929155e-05; 
	rank: pred, true, means tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2467, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 9.68087806541007e-05; urll: 7.347986684180796e-05; 
	rank: pred, true, means tensor(0.1495, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0475, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.00012768688065989409; urll: 1.8141170585295185e-05; 
	rank: pred, true, means tensor(0.4403, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0167, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 2.562602730904473e-05; urll: 8.061553671723232e-05; 
	rank: pred, true, means tensor(0.1511, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Saving checkpoint at [2] epoch 5
Epoch 6 -- batch 0 / 4372 mrrl: 0.0015952369722072035; urll: 8.635521226096898e-05; 
	rank: pred, true, means tensor(0.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 4.270070348866284e-05; urll: 7.107357669156045e-05; 
	rank: pred, true, means tensor(0.1480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 2.1458436094690114e-05; urll: 6.789043982280418e-05; 
	rank: pred, true, means tensor(0.1507, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 9.716680324345361e-05; urll: 8.337821054738015e-05; 
	rank: pred, true, means tensor(0.1512, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00021827185264555737; urll: 6.723925616825e-05; 
	rank: pred, true, means tensor(0.1513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.005888411542400718; urll: 1.8738459402811714e-05; 
	rank: pred, true, means tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2487, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 7.97161555965431e-05; urll: 7.396042929030955e-05; 
	rank: pred, true, means tensor(0.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 4.947693014401011e-05; urll: 2.7541569579625502e-05; 
	rank: pred, true, means tensor(0.4068, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 2.382344746365561e-05; urll: 8.051023178268224e-05; 
	rank: pred, true, means tensor(0.1513, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 7 -- batch 0 / 4372 mrrl: 0.0015829257608857006; urll: 8.627028000773862e-05; 
	rank: pred, true, means tensor(0.1494, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 3.420465873205103e-05; urll: 7.072364678606391e-05; 
	rank: pred, true, means tensor(0.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 2.4246548946393887e-05; urll: 6.773770292056724e-05; 
	rank: pred, true, means tensor(0.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 8.895844985090662e-05; urll: 8.313457510666922e-05; 
	rank: pred, true, means tensor(0.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00021046807887614705; urll: 6.737858348060399e-05; 
	rank: pred, true, means tensor(0.1510, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.011603496968746185; urll: 1.9038718164665624e-05; 
	rank: pred, true, means tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2585, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 7.695800377405249e-05; urll: 7.404188363580033e-05; 
	rank: pred, true, means tensor(0.1484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0002806216070894152; urll: 7.508695489377715e-06; 
	rank: pred, true, means tensor(0.4920, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 2.1315154299372807e-05; urll: 8.035824430407956e-05; 
	rank: pred, true, means tensor(0.1516, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 8 -- batch 0 / 4372 mrrl: 0.0016261226846836507; urll: 8.657749276608229e-05; 
	rank: pred, true, means tensor(0.1488, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 5.5629961934755556e-05; urll: 7.154048216762021e-05; 
	rank: pred, true, means tensor(0.1471, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 7.086274536050041e-06; urll: 6.889229553053156e-05; 
	rank: pred, true, means tensor(0.1486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0478, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00013780481822323054; urll: 8.44476162455976e-05; 
	rank: pred, true, means tensor(0.1492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00025366251065861434; urll: 6.664023385383189e-05; 
	rank: pred, true, means tensor(0.1526, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.00434067304013297; urll: 1.8630922568263486e-05; 
	rank: pred, true, means tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 6.369483799062436e-05; urll: 7.44586213841103e-05; 
	rank: pred, true, means tensor(0.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 0.0002882267290260643; urll: 7.1279710027738474e-06; 
	rank: pred, true, means tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0149, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 3.28911050928582e-05; urll: 8.099576371023431e-05; 
	rank: pred, true, means tensor(0.1504, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0473, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 9 -- batch 0 / 4372 mrrl: 0.0016930718265939504; urll: 8.704215724719688e-05; 
	rank: pred, true, means tensor(0.1480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 7.158358585002134e-05; urll: 7.20443858881481e-05; 
	rank: pred, true, means tensor(0.1461, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0486, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 4.520967138432752e-06; urll: 6.916150596225634e-05; 
	rank: pred, true, means tensor(0.1481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.00016809561202535406; urll: 8.513679495081306e-05; 
	rank: pred, true, means tensor(0.1479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0480, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.00014346587704494596; urll: 6.867523188702762e-05; 
	rank: pred, true, means tensor(0.1484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0479, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.003947250370401889; urll: 1.859987787611317e-05; 
	rank: pred, true, means tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2443, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 1.783007519406965e-05; urll: 7.638111856067553e-05; 
	rank: pred, true, means tensor(0.1439, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 1.7452108522775234e-05; urll: 3.400494824745692e-05; 
	rank: pred, true, means tensor(0.3870, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 8.893312042346224e-05; urll: 8.303995127789676e-05; 
	rank: pred, true, means tensor(0.1466, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0484, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Epoch 10 -- batch 0 / 4372 mrrl: 0.000586210771871265; urll: 7.659247057745233e-05; 
	rank: pred, true, means tensor(0.1675, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4624, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2559, device='cuda:0')
	pred, true, mrr tensor(0.0427, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0350, device='cuda:0')

batch 500 / 4372 mrrl: 0.0001533434806333389; urll: 7.397160516120493e-05; 
	rank: pred, true, means tensor(0.1423, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4331, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2676, device='cuda:0')
	pred, true, mrr tensor(0.0498, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0459, device='cuda:0')

batch 1000 / 4372 mrrl: 4.729822080662416e-06; urll: 7.128094875952229e-05; 
	rank: pred, true, means tensor(0.1438, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4291, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2641, device='cuda:0')
	pred, true, mrr tensor(0.0493, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0487, device='cuda:0')

batch 1500 / 4372 mrrl: 0.0002787929588521365; urll: 8.7181237176992e-05; 
	rank: pred, true, means tensor(0.1442, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4595, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2617, device='cuda:0')
	pred, true, mrr tensor(0.0492, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0439, device='cuda:0')

batch 2000 / 4372 mrrl: 0.0002779536953312345; urll: 6.625155947403982e-05; 
	rank: pred, true, means tensor(0.1534, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4270, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2686, device='cuda:0')
	pred, true, mrr tensor(0.0464, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0517, device='cuda:0')

batch 2500 / 4372 mrrl: 0.013031626585870981; urll: 1.909757702378556e-05; 
	rank: pred, true, means tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.1661, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1933, device='cuda:0')
	pred, true, mrr tensor(0.2605, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.2244, device='cuda:0')

batch 3000 / 4372 mrrl: 6.340483651001705e-05; urll: 7.446483505191281e-05; 
	rank: pred, true, means tensor(0.1476, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4379, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2678, device='cuda:0')
	pred, true, mrr tensor(0.0481, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0506, device='cuda:0')

batch 3500 / 4372 mrrl: 5.448426918519544e-06; urll: 4.8652043915353715e-05; 
	rank: pred, true, means tensor(0.3483, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.5835, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.1761, device='cuda:0')
	pred, true, mrr tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0202, device='cuda:0')

batch 4000 / 4372 mrrl: 3.155322474412969e-05; urll: 8.092572534224018e-05; 
	rank: pred, true, means tensor(0.1505, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.4534, device='cuda:0')
	rank: pred, true, stds tensor(0., device='cuda:0', grad_fn=<StdBackward0>) tensor(0.2662, device='cuda:0')
	pred, true, mrr tensor(0.0472, device='cuda:0', grad_fn=<MeanBackward0>) tensor(0.0455, device='cuda:0')

Saving checkpoint at [2] epoch 10
Done Training (mrr)!
REC: Testing model with dataloader UMLS
Testing: batch 0 / 488


Testing data for dataloader(s) UMLS
==========================================

Predicted MRRs
------------------------------------------
0.023949384689331055
0.045587942004203796
0.2580460011959076
0.045833129435777664
0.04586783051490784
0.30438604950904846
0.23559752106666565
0.2861998677253723
0.045483388006687164
0.045991431921720505
0.04683961346745491
0.047685787081718445
0.04804762080311775
0.025515753775835037
0.20603540539741516
0.045968737453222275
0.04618636518716812
0.04832969233393669
0.024390902370214462
0.04775230213999748
0.027118945494294167
0.04449450224637985
0.02513657882809639
0.04643221199512482
0.04784851521253586
0.04702717065811157
0.1977536976337433
0.027327770367264748
0.26397690176963806
0.04719679057598114
0.25582146644592285
0.047925326973199844
0.04780535027384758
0.04583258554339409
0.2820264995098114
0.04612843692302704
0.37037691473960876
0.19936782121658325
0.047375913709402084
0.047465693205595016
0.02140836790204048
0.02434992417693138
0.046954184770584106
0.04749685898423195
0.04634851962327957
0.4951549470424652
0.026552902534604073
0.048033617436885834
0.045497313141822815
0.4354177713394165
0.04708367586135864
0.04520316794514656
0.04672129079699516
0.04798594489693642
0.02537562884390354
0.047615066170692444
0.046022120863199234
0.28325873613357544
0.25910675525665283
0.04826653003692627
0.047007400542497635
0.04758323356509209
0.04799322411417961
0.2189687192440033
0.025813015177845955
0.04575642570853233
0.04751179739832878
0.020831843838095665
0.027327770367264748
0.04674489051103592
0.21388129889965057
0.04674670472741127
0.04791995510458946
0.046981412917375565
0.04822609946131706
0.24864709377288818
0.025096185505390167
0.04560083895921707
0.04722779989242554
0.046148765832185745
0.3225554823875427
0.04526481777429581
0.25233525037765503
0.04773249104619026
0.047992873936891556
0.04620838537812233
0.046690933406353
0.045988693833351135
0.04669298231601715
0.24025866389274597
0.04628342390060425
0.04624436795711517
0.04831577092409134
0.044261425733566284
0.20954449474811554
0.0478498712182045
0.047238923609256744
0.047120351344347
0.0470132939517498
0.1956443339586258
0.23132547736167908
0.30305254459381104
0.3013526499271393
0.04606710374355316
0.04776284471154213
0.04812685027718544
0.02660476043820381
0.04797448590397835
0.04781503975391388
0.047017909586429596
0.046779368072748184
0.04773293808102608
0.048093389719724655
0.048231493681669235
0.047397952526807785
0.048035264015197754
0.3085847795009613
0.04788912460207939
0.21872733533382416
0.04715975001454353
0.047888174653053284
0.04605550691485405
0.047033797949552536
0.04704441502690315
0.04822917282581329
0.1930728703737259
0.02513657882809639
0.23132547736167908
0.04690685123205185
0.025766635313630104
0.23026499152183533
0.04814974591135979
0.04742131754755974
0.046824198216199875
0.01962769590318203
0.3061874806880951
0.22872236371040344
0.045968737453222275
0.04777098074555397
0.04596872255206108
0.04721224308013916
0.04598071053624153
0.046022120863199234
0.04734847694635391
0.04691999405622482
0.21523097157478333
0.04312369227409363
0.04740701615810394
0.04667671024799347
0.046687740832567215
0.046198900789022446
0.046954184770584106
0.21625331044197083
0.21010369062423706
0.04776284471154213
0.19487716257572174
0.0466105081140995
0.04672129079699516
0.026610519737005234
0.02356334961950779
0.04503036290407181
0.04726489260792732
0.2873026728630066
0.04827677458524704
0.022870954126119614
0.04694657772779465
0.027327770367264748
0.047465693205595016
0.04808608815073967
0.047685787081718445
0.026499401777982712
0.044458337128162384
0.046425484120845795
0.04711183160543442
0.04720279946923256
0.04693283513188362
0.04520316794514656
0.04675604775547981
0.04534340277314186
0.04735708609223366
0.04654542729258537
0.0467882864177227
0.047285206615924835
0.04696175828576088
0.30841049551963806
0.21512271463871002
0.04606146365404129
0.04753418639302254
0.047435589134693146
0.046680863946676254
0.04659932851791382
0.047238923609256744
0.04583258554339409
0.2219664603471756
0.04780380055308342
0.0466742143034935
0.02494845911860466
0.04608112573623657
0.04702186584472656
0.04643663018941879
0.23573406040668488
0.30441048741340637
0.04749616980552673
0.04643221199512482
0.04600777104496956
0.04606114700436592
0.048059750348329544
0.04728194326162338
0.04795172065496445
0.04793379455804825
0.04632443189620972
0.21748290956020355
0.1956443339586258
0.04634851962327957
0.024214232340455055
0.047227103263139725
0.0473211444914341
0.04698663204908371
0.21540440618991852
0.020191103219985962
0.28822439908981323
0.2147255837917328
0.21146832406520844
0.047980450093746185
0.04560507461428642
0.04774122312664986
0.023112626746296883
0.04663873463869095
0.0467899926006794
0.04705224186182022
0.027327770367264748
0.04666958376765251
0.2169930338859558
0.045312561094760895
0.4589974284172058
0.29889458417892456
0.04700968787074089
0.023410743102431297
0.04564906656742096
0.04669825732707977
0.04813316464424133
0.025262193754315376
0.04675723612308502
0.21944239735603333
0.04420836642384529
0.04634430259466171
0.24293456971645355
0.20871587097644806
0.04698663204908371
0.0466797761619091
0.048382800072431564
0.0463322214782238
0.04689664766192436
0.045039575546979904
0.04596816748380661
0.21512271463871002
0.19969472289085388
0.04768315330147743
0.045145999640226364
0.2853758931159973
0.04566304013133049
0.04643632099032402
0.04818419739603996
0.22157952189445496
0.3291732668876648
0.047115348279476166
0.3335581421852112
0.04597466439008713
0.04775230213999748
0.04618636518716812
0.22071495652198792
0.047375913709402084
0.04779708385467529
0.04772035777568817
0.02503330633044243
0.04633612185716629
0.04705072194337845
0.04672129079699516
0.04813937097787857
0.287278950214386
0.2157515436410904
0.04697765037417412
0.045216985046863556
0.048162803053855896
0.04350024461746216
0.047988247126340866
0.04731099307537079
0.04798594489693642
0.2584552466869354
0.20605412125587463
0.04599428549408913
0.2147255837917328
0.02434992417693138
0.46355876326560974
0.04768409952521324
0.26397690176963806
0.047119129449129105
0.19566230475902557
0.023987766355276108
0.04446621611714363
0.04728194326162338
0.04708367586135864
0.23022755980491638
0.04768511280417442
0.23571327328681946
0.046833984553813934
0.25786203145980835
0.04721224308013916
0.024214232340455055
0.048162512481212616
0.04832969233393669
0.047160036861896515
0.23364710807800293
0.025580130517482758
0.047835107892751694
0.04714293032884598
0.047466620802879333
0.04727540910243988
0.04703197628259659
0.04641946405172348
0.046710673719644547
0.025232115760445595
0.048293646425008774
0.046687740832567215
0.032165393233299255
0.046368833631277084
0.04636704921722412
0.04722832888364792
0.04645026475191116
0.025813015177845955
0.04774122312664986
0.0467882864177227
0.04808608815073967
0.04701418802142143
0.04746691882610321
0.04635082185268402
0.04729010537266731
0.23015649616718292
0.047027453780174255
0.04722779989242554
0.04798854514956474
0.02179606631398201
0.04634302109479904
0.04834900051355362
0.04792386665940285
0.04768221825361252
0.044511742889881134
0.04663873463869095
0.2327478677034378
0.046906158328056335
0.046037472784519196
0.04706298187375069
0.21488456428050995
0.048275213688611984
0.046685826033353806
0.047310709953308105
0.048421453684568405
0.04520316794514656
0.027327770367264748
0.04715640842914581
0.027327770367264748
0.19614562392234802
0.20380574464797974
0.021240178495645523
0.2820340096950531
0.04715975001454353
0.045556969940662384
0.02080470323562622
0.026072466745972633
0.0468892939388752
0.02399446815252304
0.04790244624018669
0.046037472784519196
0.04675476625561714
0.048382800072431564
0.024585489183664322
0.04773404076695442
0.22966812551021576
0.045976124703884125
0.04776284471154213
0.23022755980491638
0.04666958376765251
0.04806704446673393
0.0478719100356102
0.04711183160543442
0.04808608815073967
0.20016729831695557
0.048199187964200974
0.04697442054748535
0.04787812381982803
0.04463132098317146
0.045111071318387985
0.04507387802004814
0.04560507461428642
0.046827688813209534
0.04312369227409363
0.046690933406353
0.046692680567502975
0.047264598309993744
0.047315459698438644
0.2190588265657425
0.04781153053045273
0.046680863946676254
0.04574240744113922
0.04802621901035309
0.30726516246795654
0.04566304013133049
0.04339994117617607
0.04600696638226509
0.04682377725839615
0.044503845274448395
0.04789355769753456
0.04511521756649017
0.234049454331398
0.045065853744745255
0.04512485861778259
0.0478961318731308
0.04643843322992325
0.23132547736167908
0.28325873613357544
0.04699014127254486
0.04700968787074089
0.2106337994337082
0.024390902370214462
0.04618636518716812
0.04764537513256073
0.04711981862783432
0.02434992417693138
0.046976905316114426
0.046685826033353806
0.20202390849590302
0.04546206444501877
0.02513628639280796
0.2195860892534256
0.02509383298456669
0.30441048741340637
0.048169806599617004
0.04710109159350395
0.04825128987431526
0.04668336361646652
0.025181729346513748
0.04795742407441139
0.21710200607776642
0.028568729758262634
0.047024697065353394
0.022870954126119614
0.046691227704286575
0.04822917282581329
0.24647900462150574
0.04798594489693642
0.046667907387018204
0.04705245792865753
0.2584552466869354
0.023172542452812195
0.04420836642384529
0.032165393233299255
0.025462506338953972
0.04665178060531616
0.045998163521289825
0.026362799108028412
0.21748290956020355
0.047956425696611404
0.23746135830879211
0.025688059628009796
0.04832969233393669
0.04611584544181824
0.04827677458524704
0.046019747853279114
0.04674670472741127
0.2282135784626007
0.04712064191699028
0.04810122400522232
0.046663444489240646
0.04684964939951897
0.04668799787759781
0.04683961346745491
0.04842175170779228
0.37037691473960876
0.04776528477668762
0.028632279485464096
0.04747476428747177
0.26009872555732727
0.046687740832567215
0.04742936044931412
0.04667704924941063
0.01962769590318203
0.04768221825361252
0.046026747673749924

True MRRs
------------------------------------------
0.024421753361821175
0.040611956268548965
0.2679971158504486
0.05212536081671715
0.04418471083045006
0.2767186462879181
0.22048406302928925
0.28721752762794495
0.05223089084029198
0.05306162312626839
0.04563980922102928
0.04022475704550743
0.05053471028804779
0.028979113325476646
0.20017242431640625
0.0510750338435173
0.04871068894863129
0.05112357810139656
0.022336235269904137
0.04657765105366707
0.022041138261556625
0.04669781029224396
0.025308234617114067
0.05634297803044319
0.051288798451423645
0.045312363654375076
0.1836642175912857
0.022630177438259125
0.2853279411792755
0.04315338283777237
0.27424508333206177
0.05280361324548721
0.046172138303518295
0.05079720541834831
0.2948368489742279
0.04793421924114227
0.527546763420105
0.18888519704341888
0.04690057039260864
0.053239855915308
0.02301979809999466
0.024823836982250214
0.04240609332919121
0.05019450932741165
0.03973282128572464
0.40128597617149353
0.020450986921787262
0.046501316130161285
0.035824958235025406
0.3863733112812042
0.037442646920681
0.04658975079655647
0.04466140270233154
0.04720115661621094
0.023695843294262886
0.04595748335123062
0.048142366111278534
0.28033921122550964
0.33485135436058044
0.05115450546145439
0.05082206428050995
0.04955441504716873
0.0440806970000267
0.23015402257442474
0.02608742006123066
0.03636784851551056
0.049725379794836044
0.025708824396133423
0.026334170252084732
0.04558807611465454
0.2479293793439865
0.04712634161114693
0.040464747697114944
0.04882826283574104
0.04723963886499405
0.22773411870002747
0.0244813933968544
0.04258407652378082
0.056084226816892624
0.05319948121905327
0.3022296130657196
0.04110518842935562
0.26948943734169006
0.05067909508943558
0.04224381595849991
0.0344768762588501
0.05653548985719681
0.049590449780225754
0.04402928054332733
0.2644907534122467
0.046916596591472626
0.04364536330103874
0.042520198971033096
0.036633286625146866
0.1829189509153366
0.05245602875947952
0.046704404056072235
0.044600438326597214
0.04878751188516617
0.1921292245388031
0.2184889167547226
0.3020302951335907
0.28487512469291687
0.03500189259648323
0.04417920857667923
0.04369112104177475
0.025355754420161247
0.046175919473171234
0.04695047810673714
0.05438936874270439
0.040812112390995026
0.05566876381635666
0.04574545472860336
0.04642236605286598
0.04651501402258873
0.053789809346199036
0.2733866274356842
0.042412299662828445
0.2161019891500473
0.041785866022109985
0.04549406096339226
0.04712012782692909
0.044846948236227036
0.041892558336257935
0.04077114164829254
0.19106347858905792
0.02659224160015583
0.2326705902814865
0.055132899433374405
0.02398771420121193
0.257141649723053
0.04661177843809128
0.04513619840145111
0.047497618943452835
0.020540304481983185
0.31931763887405396
0.21460142731666565
0.04949665442109108
0.043665289878845215
0.05038877949118614
0.04434331879019737
0.0625285878777504
0.04761948809027672
0.04560064896941185
0.04289785400032997
0.21029964089393616
0.03937029093503952
0.05035090073943138
0.04887067526578903
0.045300744473934174
0.04703718051314354
0.048190899193286896
0.2038814276456833
0.21342837810516357
0.04747121408581734
0.18913963437080383
0.05108555778861046
0.04985865205526352
0.019401853904128075
0.02426147647202015
0.04386865347623825
0.047009244561195374
0.3191469609737396
0.0501236766576767
0.02403700351715088
0.04713285341858864
0.025692986324429512
0.05560091882944107
0.04322371259331703
0.049534499645233154
0.024325493723154068
0.03444935008883476
0.042769789695739746
0.04507102817296982
0.053450532257556915
0.048478659242391586
0.054389588534832
0.04955955222249031
0.044545359909534454
0.04860858991742134
0.050046052783727646
0.04503839462995529
0.04805624857544899
0.042269133031368256
0.2736468017101288
0.18969745934009552
0.043019380420446396
0.04187805578112602
0.04608198255300522
0.050533365458250046
0.0517842099070549
0.04908036068081856
0.049056701362133026
0.17155535519123077
0.05153404921293259
0.04880017042160034
0.024883754551410675
0.051359981298446655
0.04060589522123337
0.047532711178064346
0.24110831320285797
0.2757151126861572
0.04730156809091568
0.04566335678100586
0.03843742609024048
0.032100025564432144
0.04725067690014839
0.04970249533653259
0.04906530678272247
0.04797698184847832
0.04460151121020317
0.19750961661338806
0.1896548718214035
0.04045284911990166
0.020513031631708145
0.04786063730716705
0.04818395897746086
0.04734625294804573
0.20219972729682922
0.01934351585805416
0.2913946211338043
0.24572013318538666
0.22162023186683655
0.040517717599868774
0.04414947330951691
0.052420713007450104
0.024798264726996422
0.0435338020324707
0.048338912427425385
0.044794000685214996
0.024865852668881416
0.044878922402858734
0.23919646441936493
0.04898383468389511
0.5602197647094727
0.2105584591627121
0.04920205846428871
0.02421092614531517
0.04785943403840065
0.042082831263542175
0.04207504913210869
0.02485971711575985
0.03978830575942993
0.22230181097984314
0.033027999103069305
0.04515625536441803
0.2626383304595947
0.21250703930854797
0.04535385221242905
0.03238007426261902
0.04401993378996849
0.048866163939237595
0.049575623124837875
0.031288545578718185
0.05846671760082245
0.17705316841602325
0.23405039310455322
0.049988165497779846
0.047820158302783966
0.29858797788619995
0.04478355869650841
0.03733805567026138
0.0508250817656517
0.2505630850791931
0.3190251290798187
0.05430309846997261
0.3127554655075073
0.050930652767419815
0.05450863018631935
0.05162355303764343
0.23369307816028595
0.0531732514500618
0.04480220377445221
0.049185823649168015
0.024183055385947227
0.04071365296840668
0.03566517308354378
0.04787789657711983
0.049477774649858475
0.3050260543823242
0.21868804097175598
0.04244374856352806
0.036997824907302856
0.045153453946113586
0.029200032353401184
0.04347711801528931
0.05071068927645683
0.046009257435798645
0.3013472855091095
0.2202305644750595
0.04249117895960808
0.25488752126693726
0.022353703156113625
0.3855242431163788
0.0466637909412384
0.2780642807483673
0.05608109012246132
0.20262204110622406
0.02654014341533184
0.029790503904223442
0.044636040925979614
0.05125124007463455
0.24062614142894745
0.051547639071941376
0.2337988317012787
0.051067762076854706
0.27478739619255066
0.049478355795145035
0.01991152949631214
0.043791670352220535
0.04810402914881706
0.04397089406847954
0.26408398151397705
0.02640743926167488
0.05192345753312111
0.042579930275678635
0.04946838319301605
0.045790281146764755
0.04213999584317207
0.040611304342746735
0.052033353596925735
0.026832304894924164
0.05297798663377762
0.0422302670776844
0.048724692314863205
0.04800698161125183
0.04827018827199936
0.04539962857961655
0.05274462327361107
0.02614029124379158
0.05319271236658096
0.042487043887376785
0.048115167766809464
0.044078730046749115
0.04069843515753746
0.04834916442632675
0.04630925506353378
0.23726779222488403
0.051867786794900894
0.05287028104066849
0.04021022468805313
0.019861681386828423
0.05025887116789818
0.04123224318027496
0.040559154003858566
0.0422552190721035
0.033059585839509964
0.04915664345026016
0.25031790137290955
0.051255419850349426
0.0497303307056427
0.04302064701914787
0.19302205741405487
0.04350697994232178
0.03117412142455578
0.04827515408396721
0.043603021651506424
0.053982388228178024
0.022925255820155144
0.047289978712797165
0.023285143077373505
0.2114821821451187
0.23118235170841217
0.023495716974139214
0.2682235836982727
0.046504776924848557
0.04016425088047981
0.023664096370339394
0.024514099583029747
0.05522778630256653
0.02779652737081051
0.04133186861872673
0.0480370931327343
0.04507250711321831
0.050911661237478256
0.025021124631166458
0.05102074518799782
0.24480316042900085
0.03806536644697189
0.050381142646074295
0.23918980360031128
0.056644439697265625
0.046999700367450714
0.03916798159480095
0.05127035081386566
0.05439584329724312
0.2030325084924698
0.047273751348257065
0.042119793593883514
0.047489237040281296
0.04196649417281151
0.05479292944073677
0.048049621284008026
0.04806503653526306
0.05261324718594551
0.03899736329913139
0.042528484016656876
0.047544319182634354
0.0458199717104435
0.04482138156890869
0.2688230574131012
0.0538853295147419
0.053283173590898514
0.050001852214336395
0.04686715453863144
0.3149104118347168
0.038145262748003006
0.03321397677063942
0.04110361263155937
0.04956366866827011
0.02964176796376705
0.046684905886650085
0.04906773194670677
0.21872417628765106
0.035455115139484406
0.04126609489321709
0.04594307765364647
0.05194870010018349
0.20304986834526062
0.2884472608566284
0.04389704763889313
0.05259912833571434
0.2063712626695633
0.027109788730740547
0.04465942084789276
0.046785857528448105
0.04414379224181175
0.025343526154756546
0.04883458465337753
0.032708827406167984
0.210621178150177
0.03498902916908264
0.028989793732762337
0.2443627119064331
0.024981852620840073
0.29226770997047424
0.04205162450671196
0.05009705573320389
0.050801727920770645
0.055416952818632126
0.025101356208324432
0.04365615174174309
0.23227831721305847
0.02025243267416954
0.04346780851483345
0.027189644053578377
0.047783251851797104
0.04890083894133568
0.23694628477096558
0.04704683646559715
0.060318365693092346
0.04360857605934143
0.31947681307792664
0.02437218278646469
0.03563481941819191
0.05441431328654289
0.025683920830488205
0.04656463488936424
0.03615206480026245
0.027236703783273697
0.23446635901927948
0.04614027589559555
0.2586989402770996
0.025526531040668488
0.04222304746508598
0.04046820476651192
0.04704149439930916
0.041279878467321396
0.0466274730861187
0.24165078997612
0.049526646733284
0.04907853156328201
0.05562041327357292
0.04631710425019264
0.036487091332674026
0.044986605644226074
0.04397793114185333
0.515143096446991
0.05072994902729988
0.021167363971471786
0.046446990221738815
0.3001837432384491
0.0502328984439373
0.04836077243089676
0.044561851769685745
0.02108783833682537
0.05100202187895775
0.0473867692053318

r_mrr = tensor([[1.0000, 0.9835],
        [0.9835, 1.0000]])
r2_mrr = 0.9668240547180176
test_loss: 0.0028989110111874877
Done Testing!
done with training and eval
Experiments took 0 seconds
